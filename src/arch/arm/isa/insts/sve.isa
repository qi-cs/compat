// Copyright (c) 2017-2020, 2025 ARM Limited
// All rights reserved
//
// The license below extends only to copyright in the software and shall
// not be construed as granting a license to any other intellectual
// property including but not limited to intellectual property relating
// to a hardware implementation of the functionality of the software
// licensed hereunder.  You may use the software subject to the license
// terms below provided that you ensure that this notice is replicated
// unmodified and in its entirety in all distributions of the software,
// modified or unmodified, in source code or in binary form.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met: redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer;
// redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution;
// neither the name of the copyright holders nor the names of its
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

// @file Definition of SVE instructions.

output header {{

    // Decodes unary, constructive, predicated (merging) SVE instructions,
    // handling signed and unsigned variants.
    template <template <typename T> class BaseS,
              template <typename T> class BaseU>
    StaticInstPtr
    decodeSveUnaryPred(unsigned size, unsigned u, ExtMachInst machInst,
                       RegIndex dest, RegIndex op1, RegIndex gp)
    {
        switch (size) {
          case 0:
            if (u) {
                return new BaseU<uint8_t>(machInst, dest, op1, gp);
            } else {
                return new BaseS<int8_t>(machInst, dest, op1, gp);
            }
          case 1:
            if (u) {
                return new BaseU<uint16_t>(machInst, dest, op1, gp);
            } else {
                return new BaseS<int16_t>(machInst, dest, op1, gp);
            }
          case 2:
            if (u) {
                return new BaseU<uint32_t>(machInst, dest, op1, gp);
            } else {
                return new BaseS<int32_t>(machInst, dest, op1, gp);
            }
          case 3:
            if (u) {
                return new BaseU<uint64_t>(machInst, dest, op1, gp);
            } else {
                return new BaseS<int64_t>(machInst, dest, op1, gp);
            }
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes SVE widening reductions.
    // handling signed and unsigned variants.
    template <template <typename T1, typename T2> class BaseS,
              template <typename T1, typename T2> class BaseU>
    StaticInstPtr
    decodeSveWideningReduc(unsigned size, unsigned u, ExtMachInst machInst,
                           RegIndex dest, RegIndex op1, RegIndex gp)
    {
        switch (size) {
          case 0:
            if (u) {
                return new BaseU<uint8_t, uint64_t>(machInst, dest, op1, gp);
            } else {
                return new BaseS<int8_t, int64_t>(machInst, dest, op1, gp);
            }
          case 1:
            if (u) {
                return new BaseU<uint16_t, uint64_t>(machInst, dest, op1, gp);
            } else {
                return new BaseS<int16_t, int64_t>(machInst, dest, op1, gp);
            }
          case 2:
            if (u) {
                return new BaseU<uint32_t, uint64_t>(machInst, dest, op1, gp);
            } else {
                return new BaseS<int32_t, int64_t>(machInst, dest, op1, gp);
            }
          case 3:
            assert(u);
            return new BaseU<uint64_t, uint64_t>(machInst, dest, op1, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes unary, constructive, predicated (merging) SVE instructions,
    // handling signed variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveUnaryPredS(unsigned size, ExtMachInst machInst,
                        RegIndex dest, RegIndex op1, RegIndex gp)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, op1, gp);
          case 1:
            return new Base<int16_t>(machInst, dest, op1, gp);
          case 2:
            return new Base<int32_t>(machInst, dest, op1, gp);
          case 3:
            return new Base<int64_t>(machInst, dest, op1, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes unary, constructive, predicated (merging) SVE instructions,
    // handling unsigned variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveUnaryPredU(unsigned size, ExtMachInst machInst,
                        RegIndex dest, RegIndex op1, RegIndex gp)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, op1, gp);
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, gp);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, gp);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes unary, constructive, predicated (merging) SVE instructions,
    // handling signed and unsigned variants, for small element sizes (8- to
    // 32-bit).
    template <template <typename T> class BaseS,
              template <typename T> class BaseU>
    StaticInstPtr
    decodeSveUnaryPredSmall(unsigned size, unsigned u, ExtMachInst machInst,
                            RegIndex dest, RegIndex op1, RegIndex gp)
    {
        switch (size) {
          case 0:
            if (u) {
                return new BaseU<uint8_t>(machInst, dest, op1, gp);
            } else {
                return new BaseS<int8_t>(machInst, dest, op1, gp);
            }
          case 1:
            if (u) {
                return new BaseU<uint16_t>(machInst, dest, op1, gp);
            } else {
                return new BaseS<int16_t>(machInst, dest, op1, gp);
            }
          case 2:
            if (u) {
                return new BaseU<uint32_t>(machInst, dest, op1, gp);
            } else {
                return new BaseS<int32_t>(machInst, dest, op1, gp);
            }
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes unary, constructive, predicated (merging) SVE instructions,
    // handling floating point variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveUnaryPredF(unsigned size, ExtMachInst machInst,
                        RegIndex dest, RegIndex op1, RegIndex gp)
    {
        switch (size) {
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, gp);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, gp);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes unary, constructive, unpredicated SVE instructions, handling
    // unsigned variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveUnaryUnpredU(unsigned size, ExtMachInst machInst,
                          RegIndex dest, RegIndex op1)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, op1);
          case 1:
            return new Base<uint16_t>(machInst, dest, op1);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes unary, constructive, unpredicated SVE instructions, handling
    // unsigned variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveUnaryUnpredNarrowU(unsigned size, ExtMachInst machInst,
                                RegIndex dest, RegIndex op1)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, op1);
          case 1:
            return new Base<uint16_t>(machInst, dest, op1);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes unary, constructive, unpredicated SVE instructions, handling
    // unsigned variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveUnaryUnpredNarrowS(unsigned size, ExtMachInst machInst,
                                RegIndex dest, RegIndex op1)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, op1);
          case 1:
            return new Base<int16_t>(machInst, dest, op1);
          case 2:
            return new Base<int32_t>(machInst, dest, op1);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes unary, constructive, unpredicated SVE instructions, handling
    // floating-point variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveUnaryUnpredF(unsigned size, ExtMachInst machInst,
                          RegIndex dest, RegIndex op1)
    {
        switch (size) {
          case 1:
            return new Base<uint16_t>(machInst, dest, op1);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, destructive, predicated (merging) SVE instructions,
    // handling signed and unsigned variants.
    template <template <typename T> class BaseS,
              template <typename T> class BaseU>
    StaticInstPtr
    decodeSveBinDestrPred(unsigned size, unsigned u, ExtMachInst machInst,
                          RegIndex dest, RegIndex op2, RegIndex gp)
    {
        switch (size) {
          case 0:
            if (u) {
                return new BaseU<uint8_t>(machInst, dest, op2, gp);
            } else {
                return new BaseS<int8_t>(machInst, dest, op2, gp);
            }
          case 1:
            if (u) {
                return new BaseU<uint16_t>(machInst, dest, op2, gp);
            } else {
                return new BaseS<int16_t>(machInst, dest, op2, gp);
            }
          case 2:
            if (u) {
                return new BaseU<uint32_t>(machInst, dest, op2, gp);
            } else {
                return new BaseS<int32_t>(machInst, dest, op2, gp);
            }
          case 3:
            if (u) {
                return new BaseU<uint64_t>(machInst, dest, op2, gp);
            } else {
                return new BaseS<int64_t>(machInst, dest, op2, gp);
            }
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // unsigned limited variants
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinImmUnpredUnsigned(unsigned size, ExtMachInst machInst,
                               RegIndex dest, RegIndex op1, unsigned immediate)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, op1, immediate);
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, immediate);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, immediate);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // signed limited variants
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinImmUnpredSigned(unsigned size, ExtMachInst machInst,
                             RegIndex dest, RegIndex op1, unsigned immediate)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, op1, immediate);
          case 1:
            return new Base<int16_t>(machInst, dest, op1, immediate);
          case 2:
            return new Base<int32_t>(machInst, dest, op1, immediate);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary with immediate operand, constructive, unpredicated
    // SVE instructions, handling signed variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinImmUnpredS(unsigned size, ExtMachInst machInst,
            RegIndex dest, RegIndex op1, unsigned immediate)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, op1, immediate);
          case 1:
            return new Base<int16_t>(machInst, dest, op1, immediate);
          case 2:
            return new Base<int32_t>(machInst, dest, op1, immediate);
          case 3:
            return new Base<int64_t>(machInst, dest, op1, immediate);
          default:
            return new Unknown64(machInst);
        }
    }


    // Decodes binary with immediate operand, constructive, unpredicated
    // SVE instructions, handling unsigned variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinImmUnpredU(unsigned size, ExtMachInst machInst,
            RegIndex dest, RegIndex op1, unsigned immediate)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, op1, immediate);
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, immediate);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, immediate);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1, immediate);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary with immediate operand, destructive, predicated (merging)
    // SVE instructions, handling unsigned variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinImmPredU(unsigned size, ExtMachInst machInst, RegIndex dest,
            unsigned immediate, RegIndex gp)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, immediate, gp);
          case 1:
            return new Base<uint16_t>(machInst, dest, immediate, gp);
          case 2:
            return new Base<uint32_t>(machInst, dest, immediate, gp);
          case 3:
            return new Base<uint64_t>(machInst, dest, immediate, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary with immediate operand, destructive, predicated (merging)
    // SVE instructions, handling signed variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinImmPredS(unsigned size, ExtMachInst machInst, RegIndex dest,
            unsigned immediate, RegIndex gp)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, immediate, gp);
          case 1:
            return new Base<int16_t>(machInst, dest, immediate, gp);
          case 2:
            return new Base<int32_t>(machInst, dest, immediate, gp);
          case 3:
            return new Base<int64_t>(machInst, dest, immediate, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary with immediate operand, destructive, predicated (merging)
    // SVE instructions, handling floating-point variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinImmPredF(unsigned size, ExtMachInst machInst, RegIndex dest,
            uint64_t immediate, RegIndex gp)
    {
        switch (size) {
          case 1:
            return new Base<uint16_t>(machInst, dest, immediate, gp);
          case 2:
            return new Base<uint32_t>(machInst, dest, immediate, gp);
          case 3:
            return new Base<uint64_t>(machInst, dest, immediate, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes unary/binary with wide immediate operand, destructive,
    // unpredicated SVE instructions, handling unsigned variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveWideImmUnpredU(unsigned size, ExtMachInst machInst,
            RegIndex dest, uint64_t immediate)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, immediate);
          case 1:
            return new Base<uint16_t>(machInst, dest, immediate);
          case 2:
            return new Base<uint32_t>(machInst, dest, immediate);
          case 3:
            return new Base<uint64_t>(machInst, dest, immediate);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes unary/binary with wide immediate operand, destructive,
    // unpredicated SVE instructions, handling signed variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveWideImmUnpredS(unsigned size, ExtMachInst machInst,
            RegIndex dest, uint64_t immediate)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, immediate);
          case 1:
            return new Base<int16_t>(machInst, dest, immediate);
          case 2:
            return new Base<int32_t>(machInst, dest, immediate);
          case 3:
            return new Base<int64_t>(machInst, dest, immediate);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes unary/binary with wide immediate operand, destructive,
    // unpredicated SVE instructions, handling floating-point variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveWideImmUnpredF(unsigned size, ExtMachInst machInst,
            RegIndex dest, uint64_t immediate)
    {
        switch (size) {
          case 1:
            return new Base<uint16_t>(machInst, dest, immediate);
          case 2:
            return new Base<uint32_t>(machInst, dest, immediate);
          case 3:
            return new Base<uint64_t>(machInst, dest, immediate);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes unary/binary with wide immediate operand, destructive,
    // predicated SVE instructions, handling unsigned variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveWideImmPredU(unsigned size, ExtMachInst machInst,
            RegIndex dest, uint64_t immediate, RegIndex gp,
            bool isMerging = true)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, immediate, gp,
                isMerging);
          case 1:
            return new Base<uint16_t>(machInst, dest, immediate, gp,
                isMerging);
          case 2:
            return new Base<uint32_t>(machInst, dest, immediate, gp,
                isMerging);
          case 3:
            return new Base<uint64_t>(machInst, dest, immediate, gp,
                isMerging);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes unary/binary with wide immediate operand, destructive,
    // predicated SVE instructions, handling floating-point variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveWideImmPredF(unsigned size, ExtMachInst machInst,
            RegIndex dest, uint64_t immediate, RegIndex gp)
    {
        switch (size) {
          case 1:
            return new Base<uint16_t>(machInst, dest, immediate, gp);
          case 2:
            return new Base<uint32_t>(machInst, dest, immediate, gp);
          case 3:
            return new Base<uint64_t>(machInst, dest, immediate, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, destructive, predicated (merging) SVE instructions,
    // handling unsigned variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinDestrPredU(unsigned size, ExtMachInst machInst,
                           RegIndex dest, RegIndex op2, RegIndex gp)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, op2, gp);
          case 1:
            return new Base<uint16_t>(machInst, dest, op2, gp);
          case 2:
            return new Base<uint32_t>(machInst, dest, op2, gp);
          case 3:
            return new Base<uint64_t>(machInst, dest, op2, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, destructive, predicated (merging) SVE instructions,
    // handling signed variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinDestrPredS(unsigned size, ExtMachInst machInst,
                           RegIndex dest, RegIndex op2, RegIndex gp)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, op2, gp);
          case 1:
            return new Base<int16_t>(machInst, dest, op2, gp);
          case 2:
            return new Base<int32_t>(machInst, dest, op2, gp);
          case 3:
            return new Base<int64_t>(machInst, dest, op2, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, destructive, predicated (merging) SVE instructions,
    // handling unsigned variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinPredPairLongU(unsigned size, ExtMachInst machInst,
                              RegIndex dest, RegIndex op2, RegIndex gp)
    {
        switch (size) {
          case 1:
            return new Base<uint8_t>(machInst, dest, op2, gp);
          case 2:
            return new Base<uint16_t>(machInst, dest, op2, gp);
          case 3:
            return new Base<uint32_t>(machInst, dest, op2, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, destructive, predicated (merging) SVE instructions,
    // handling signed variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinPredPairLongS(unsigned size, ExtMachInst machInst,
                              RegIndex dest, RegIndex op2, RegIndex gp)
    {
        switch (size) {
          case 1:
            return new Base<int8_t>(machInst, dest, op2, gp);
          case 2:
            return new Base<int16_t>(machInst, dest, op2, gp);
          case 3:
            return new Base<int32_t>(machInst, dest, op2, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, destructive, predicated (merging) SVE instructions,
    // handling floating-point variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinDestrPredF(unsigned size, ExtMachInst machInst,
                           RegIndex dest, RegIndex op2, RegIndex gp)
    {
        switch (size) {
          case 1:
            return new Base<uint16_t>(machInst, dest, op2, gp);
          case 2:
            return new Base<uint32_t>(machInst, dest, op2, gp);
          case 3:
            return new Base<uint64_t>(machInst, dest, op2, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, predicated SVE instructions, handling
    // unsigned variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinConstrPredU(unsigned size, ExtMachInst machInst,
                            RegIndex dest, RegIndex op1, RegIndex op2,
                            RegIndex gp, SvePredType predType)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, op1, op2, gp, predType);
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, op2, gp, predType);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, op2, gp, predType);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1, op2, gp, predType);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinUnpred(unsigned size, unsigned u, ExtMachInst machInst,
                       RegIndex dest, RegIndex op1, RegIndex op2)
    {
        switch (size) {
          case 0:
            if (u) {
                return new Base<uint8_t>(machInst, dest, op1, op2);
            } else {
                return new Base<int8_t>(machInst, dest, op1, op2);
            }
          case 1:
            if (u) {
                return new Base<uint16_t>(machInst, dest, op1, op2);
            } else {
                return new Base<int16_t>(machInst, dest, op1, op2);
            }
          case 2:
            if (u) {
                return new Base<uint32_t>(machInst, dest, op1, op2);
            } else {
                return new Base<int32_t>(machInst, dest, op1, op2);
            }
          case 3:
            if (u) {
                return new Base<uint64_t>(machInst, dest, op1, op2);
            } else {
                return new Base<int64_t>(machInst, dest, op1, op2);
            }
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // unsigned limited variants
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinUnpredUnequalU(unsigned size, ExtMachInst machInst,
                               RegIndex dest, RegIndex op1, RegIndex op2)
    {
        switch (size) {
          case 1:
            return new Base<uint8_t>(machInst, dest, op1, op2);
          case 2:
            return new Base<uint16_t>(machInst, dest, op1, op2);
          case 3:
            return new Base<uint32_t>(machInst, dest, op1, op2);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // signed limited variants
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinUnpredUnequalS(unsigned size, ExtMachInst machInst,
                               RegIndex dest, RegIndex op1, RegIndex op2)
    {
        switch (size) {
          case 1:
            return new Base<int8_t>(machInst, dest, op1, op2);
          case 2:
            return new Base<int16_t>(machInst, dest, op1, op2);
          case 3:
            return new Base<int32_t>(machInst, dest, op1, op2);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // Unsigned instructions only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinUnpredU(unsigned size, ExtMachInst machInst, RegIndex dest,
            RegIndex op1, RegIndex op2)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, op1, op2);
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, op2);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, op2);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1, op2);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // Unsigned instructions only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinUnpred3SrcU(unsigned size, ExtMachInst machInst, RegIndex dest,
            RegIndex op1, RegIndex op2, RegIndex op3)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, op1, op2, op3);
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, op2, op3);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, op2, op3);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1, op2, op3);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // Signed instructions only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinUnpredS(unsigned size, ExtMachInst machInst, RegIndex dest,
            RegIndex op1, RegIndex op2)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, op1, op2);
          case 1:
            return new Base<int16_t>(machInst, dest, op1, op2);
          case 2:
            return new Base<int32_t>(machInst, dest, op1, op2);
          case 3:
            return new Base<int64_t>(machInst, dest, op1, op2);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // unsigned instructions only, limited variants.
    template <template <typename T> class Base,
              template <typename T> class Base128>
    StaticInstPtr
    decodeSveBinUnpredS2(unsigned size, ExtMachInst machInst, RegIndex dest,
            RegIndex op1, RegIndex op2)
    {
        switch (size) {
          case 0:
            return new Base128<uint64_t>(machInst, dest, op1, op2);
          case 1:
            return new Base<uint8_t>(machInst, dest, op1, op2);
          case 3:
            return new Base<uint32_t>(machInst, dest, op1, op2);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // unsigned limited variants
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinImmUnpredNarrowU(unsigned size, ExtMachInst machInst,
                                 RegIndex dest, RegIndex op1, unsigned imm)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, op1, imm);
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, imm);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, imm);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // signed limited variants
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinImmUnpredNarrowS(unsigned size, ExtMachInst machInst,
                                 RegIndex dest, RegIndex op1, unsigned imm)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, op1, imm);
          case 1:
            return new Base<int16_t>(machInst, dest, op1, imm);
          case 2:
            return new Base<int32_t>(machInst, dest, op1, imm);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // unsigned limited variants
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinIdxUnpredULong(unsigned size, ExtMachInst machInst,
            RegIndex dest, RegIndex op1, RegIndex op2, unsigned imm)
    {
        switch (size) {
          case 2:
            return new Base<uint16_t>(machInst, dest, op1, op2, imm);
          case 3:
            return new Base<uint32_t>(machInst, dest, op1, op2, imm);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // signed limited variants
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinIdxUnpredSLong(unsigned size, ExtMachInst machInst,
            RegIndex dest, RegIndex op1, RegIndex op2, unsigned imm)
    {
        switch (size) {
          case 2:
            return new Base<int16_t>(machInst, dest, op1, op2, imm);
          case 3:
            return new Base<int32_t>(machInst, dest, op1, op2, imm);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // Unsigned instructions only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveWhileUnpredU(unsigned size, ExtMachInst machInst,
            RegIndex dest, RegIndex dest2, RegIndex op1, RegIndex op2)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, dest2, op1, op2);
          case 1:
            return new Base<uint16_t>(machInst, dest, dest2, op1, op2);
          case 2:
            return new Base<uint32_t>(machInst, dest, dest2, op1, op2);
          case 3:
            return new Base<uint64_t>(machInst, dest, dest2, op1, op2);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // Signed instructions only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveWhileUnpredS(unsigned size, ExtMachInst machInst,
            RegIndex dest, RegIndex dest2, RegIndex op1, RegIndex op2)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, dest2, op1, op2);
          case 1:
            return new Base<int16_t>(machInst, dest, dest2, op1, op2);
          case 2:
            return new Base<int32_t>(machInst, dest, dest2, op1, op2);
          case 3:
            return new Base<int64_t>(machInst, dest, dest2, op1, op2);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // Unsigned instructions only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveWhilePngUnpredU(unsigned size, ExtMachInst machInst,
            RegIndex dest, RegIndex op1, RegIndex op2, uint64_t imm)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, op1, op2, imm);
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, op2, imm);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, op2, imm);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1, op2, imm);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, constructive, unpredicated SVE instructions.
    // Signed instructions only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveWhilePngUnpredS(unsigned size, ExtMachInst machInst,
            RegIndex dest, RegIndex op1, RegIndex op2, uint64_t imm)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, op1, op2, imm);
          case 1:
            return new Base<int16_t>(machInst, dest, op1, op2, imm);
          case 2:
            return new Base<int32_t>(machInst, dest, op1, op2, imm);
          case 3:
            return new Base<int64_t>(machInst, dest, op1, op2, imm);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes binary, costructive, unpredicated SVE instructions, handling
    // floating-point variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveBinUnpredF(unsigned size, ExtMachInst machInst, RegIndex dest,
            RegIndex op1, RegIndex op2)
    {
        switch (size) {
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, op2);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, op2);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1, op2);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes SVE compare instructions - binary, predicated (zeroing),
    // generating a predicate - handling floating-point variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveCmpF(unsigned size, ExtMachInst machInst,
                  RegIndex dest, RegIndex op1, RegIndex op2,
                  RegIndex gp)
    {
        switch (size) {
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, op2, gp);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, op2, gp);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1, op2, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes SVE compare-with-immediate instructions - binary, predicated
    // (zeroing), generating a predicate - handling floating-point variants
    // only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveCmpImmF(unsigned size, ExtMachInst machInst,
                     RegIndex dest, RegIndex op1, uint64_t imm,
                     RegIndex gp)
    {
        switch (size) {
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, imm, gp);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, imm, gp);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1, imm, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes ternary, destructive, predicated (merging) SVE instructions.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveTerPred(unsigned size, unsigned u, ExtMachInst machInst,
                     RegIndex dest, RegIndex op1, RegIndex op2,
                     RegIndex gp)
    {
        switch (size) {
          case 0:
            if (u) {
                return new Base<uint8_t>(machInst, dest, op1, op2, gp);
            } else {
                return new Base<int8_t>(machInst, dest, op1, op2, gp);
            }
          case 1:
            if (u) {
                return new Base<uint16_t>(machInst, dest, op1, op2, gp);
            } else {
                return new Base<int16_t>(machInst, dest, op1, op2, gp);
            }
          case 2:
            if (u) {
                return new Base<uint32_t>(machInst, dest, op1, op2, gp);
            } else {
                return new Base<int32_t>(machInst, dest, op1, op2, gp);
            }
          case 3:
            if (u) {
                return new Base<uint64_t>(machInst, dest, op1, op2, gp);
            } else {
                return new Base<int64_t>(machInst, dest, op1, op2, gp);
            }
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes ternary, destructive, predicated (merging) SVE instructions,
    // handling wide signed variants only. XXX: zeroing for CMP instructions.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveTerPredWS(unsigned size, ExtMachInst machInst,
                      RegIndex dest, RegIndex op1, RegIndex op2,
                      RegIndex gp)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, op1, op2, gp);
          case 1:
            return new Base<int16_t>(machInst, dest, op1, op2, gp);
          case 2:
            return new Base<int32_t>(machInst, dest, op1, op2, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes ternary, destructive, predicated (merging) SVE instructions,
    // handling wide unsigned variants only. XXX: zeroing for CMP instructions.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveTerPredWU(unsigned size, ExtMachInst machInst,
                      RegIndex dest, RegIndex op1, RegIndex op2,
                      RegIndex gp)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, op1, op2, gp);
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, op2, gp);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, op2, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes ternary, destructive, predicated (merging) SVE instructions,
    // handling signed variants only. XXX: zeroing for CMP instructions.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveTerPredS(unsigned size, ExtMachInst machInst,
                      RegIndex dest, RegIndex op1, RegIndex op2,
                      RegIndex gp)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, op1, op2, gp);
          case 1:
            return new Base<int16_t>(machInst, dest, op1, op2, gp);
          case 2:
            return new Base<int32_t>(machInst, dest, op1, op2, gp);
          case 3:
            return new Base<int64_t>(machInst, dest, op1, op2, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes ternary, destructive, predicated (merging) SVE instructions,
    // handling unsigned variants only. XXX: zeroing for CMP instructions.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveTerPredU(unsigned size, ExtMachInst machInst,
                      RegIndex dest, RegIndex op1, RegIndex op2,
                      RegIndex gp)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, op1, op2, gp);
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, op2, gp);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, op2, gp);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1, op2, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes SVE signed unary extension instructions (8-bit source element
    // size)
    template <template <typename TS, typename TD> class Base>
    StaticInstPtr
    decodeSveUnaryExtendFromBPredS(unsigned dsize, ExtMachInst machInst,
                                   RegIndex dest, RegIndex op1,
                                   RegIndex gp)
    {
        switch (dsize) {
          case 1:
            return new Base<int8_t, int16_t>(machInst, dest, op1, gp);
          case 2:
            return new Base<int8_t, int32_t>(machInst, dest, op1, gp);
          case 3:
            return new Base<int8_t, int64_t>(machInst, dest, op1, gp);
        }
        return new Unknown64(machInst);
    }

    // Decodes SVE unsigned unary extension instructions (8-bit source element
    // size)
    template <template <typename TS, typename TD> class Base>
    StaticInstPtr
    decodeSveUnaryExtendFromBPredU(unsigned dsize, ExtMachInst machInst,
                                   RegIndex dest, RegIndex op1,
                                   RegIndex gp)
    {
        switch (dsize) {
          case 1:
            return new Base<uint8_t, uint16_t>(machInst, dest, op1, gp);
          case 2:
            return new Base<uint8_t, uint32_t>(machInst, dest, op1, gp);
          case 3:
            return new Base<uint8_t, uint64_t>(machInst, dest, op1, gp);
        }
        return new Unknown64(machInst);
    }

    // Decodes SVE signed unary extension instructions (16-bit source element
    // size)
    template <template <typename TS, typename TD> class Base>
    StaticInstPtr
    decodeSveUnaryExtendFromHPredS(unsigned dsize, ExtMachInst machInst,
                                   RegIndex dest, RegIndex op1,
                                   RegIndex gp)
    {
        switch (dsize) {
          case 2:
            return new Base<int16_t, int32_t>(machInst, dest, op1, gp);
          case 3:
            return new Base<int16_t, int64_t>(machInst, dest, op1, gp);
        }
        return new Unknown64(machInst);
    }

    // Decodes SVE unsigned unary extension instructions (16-bit source element
    // size)
    template <template <typename TS, typename TD> class Base>
    StaticInstPtr
    decodeSveUnaryExtendFromHPredU(unsigned dsize, ExtMachInst machInst,
                                   RegIndex dest, RegIndex op1,
                                   RegIndex gp)
    {
        switch (dsize) {
          case 2:
            return new Base<uint16_t, uint32_t>(machInst, dest, op1, gp);
          case 3:
            return new Base<uint16_t, uint64_t>(machInst, dest, op1, gp);
        }
        return new Unknown64(machInst);
    }

    // Decodes ternary, destructive, predicated (merging) SVE instructions,
    // handling floating-point variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveTerPredF(unsigned size, ExtMachInst machInst,
                      RegIndex dest, RegIndex op1, RegIndex op2,
                      RegIndex gp)
    {
        switch (size) {
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, op2, gp);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, op2, gp);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1, op2, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes ternary, unpredicated SVE2 instructions
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveTerUnpred(unsigned size, ExtMachInst machInst,
                      RegIndex dest, RegIndex op1, RegIndex op2)
    {
        if (bits(size, 0) == 0) {
            return new Base<uint32_t>(machInst, dest, op1, op2);
        } else {
            return new Base<uint64_t>(machInst, dest, op1, op2);
        }
    }

    // Decodes ternary with immediate operand, destructive, unpredicated SVE
    // instructions handling floating-point variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveTerImmUnpredF(unsigned size, ExtMachInst machInst,
                           RegIndex dest, RegIndex op2, uint8_t imm)
    {
        switch (size) {
          case 1:
            return new Base<uint16_t>(machInst, dest, op2, imm);
          case 2:
            return new Base<uint32_t>(machInst, dest, op2, imm);
          case 3:
            return new Base<uint64_t>(machInst, dest, op2, imm);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes SVE PTRUE(S) instructions.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSvePtrue(unsigned size, ExtMachInst machInst,
                   RegIndex dest, uint8_t imm)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, imm);
          case 1:
            return new Base<uint16_t>(machInst, dest, imm);
          case 2:
            return new Base<uint32_t>(machInst, dest, imm);
          case 3:
            return new Base<uint64_t>(machInst, dest, imm);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes SVE predicate count instructions, scalar signed variant only
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSvePredCountS(unsigned size, ExtMachInst machInst,
            RegIndex dest, RegIndex op1)
    {
        switch (size) {
            case 0:
                return new Base<int8_t>(machInst, dest, op1);
            case 1:
                return new Base<int16_t>(machInst, dest, op1);
            case 2:
                return new Base<int32_t>(machInst, dest, op1);
            case 3:
                return new Base<int64_t>(machInst, dest, op1);
            default:
                return new Unknown64(machInst);
        }
    }

    // Decodes SVE predicate count instructions, scalar unsigned variant only
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSvePredCountU(unsigned size, ExtMachInst machInst,
            RegIndex dest, RegIndex op1)
    {
        switch (size) {
            case 0:
                return new Base<uint8_t>(machInst, dest, op1);
            case 1:
                return new Base<uint16_t>(machInst, dest, op1);
            case 2:
                return new Base<uint32_t>(machInst, dest, op1);
            case 3:
                return new Base<uint64_t>(machInst, dest, op1);
            default:
                return new Unknown64(machInst);
        }
    }

    // Decodes SVE predicate count instructions, vector signed variant only
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSvePredCountVS(unsigned size, ExtMachInst machInst,
            RegIndex dest, RegIndex op1)
    {
        switch (size) {
            case 1:
                return new Base<int16_t>(machInst, dest, op1);
            case 2:
                return new Base<int32_t>(machInst, dest, op1);
            case 3:
                return new Base<int64_t>(machInst, dest, op1);
            default:
                return new Unknown64(machInst);
        }
    }

    // Decodes SVE predicate count instructions, vector unsigned variant only
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSvePredCountVU(unsigned size, ExtMachInst machInst,
            RegIndex dest, RegIndex op1)
    {
        switch (size) {
            case 1:
                return new Base<uint16_t>(machInst, dest, op1);
            case 2:
                return new Base<uint32_t>(machInst, dest, op1);
            case 3:
                return new Base<uint64_t>(machInst, dest, op1);
            default:
                return new Unknown64(machInst);
        }
    }

    // Decodes ternary with immediate operand, predicated SVE
    // instructions handling unsigned variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveTerImmPredU(unsigned size, ExtMachInst machInst,
            RegIndex dest, RegIndex op1, int64_t imm, RegIndex gp)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, op1, imm, gp);
          case 1:
            return new Base<uint16_t>(machInst, dest, op1, imm, gp);
          case 2:
            return new Base<uint32_t>(machInst, dest, op1, imm, gp);
          case 3:
            return new Base<uint64_t>(machInst, dest, op1, imm, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes ternary with immediate operand, predicated SVE
    // instructions handling signed variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveTerImmPredS(unsigned size, ExtMachInst machInst,
            RegIndex dest, RegIndex op1, int64_t imm, RegIndex gp)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, op1, imm, gp);
          case 1:
            return new Base<int16_t>(machInst, dest, op1, imm, gp);
          case 2:
            return new Base<int32_t>(machInst, dest, op1, imm, gp);
          case 3:
            return new Base<int64_t>(machInst, dest, op1, imm, gp);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes integer element count SVE instructions, handling
    // signed variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveElemIntCountS(unsigned size, ExtMachInst machInst,
            RegIndex dest, uint8_t pattern, uint8_t imm4)
    {
        switch (size) {
          case 0:
            return new Base<int8_t>(machInst, dest, pattern, imm4);
          case 1:
            return new Base<int16_t>(machInst, dest, pattern, imm4);
          case 2:
            return new Base<int32_t>(machInst, dest, pattern, imm4);
          case 3:
            return new Base<int64_t>(machInst, dest, pattern, imm4);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes integer element count SVE instructions, handling
    // unsigned variants only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveElemIntCountU(unsigned size, ExtMachInst machInst,
            RegIndex dest, uint8_t pattern, uint8_t imm4)
    {
        switch (size) {
          case 0:
            return new Base<uint8_t>(machInst, dest, pattern, imm4);
          case 1:
            return new Base<uint16_t>(machInst, dest, pattern, imm4);
          case 2:
            return new Base<uint32_t>(machInst, dest, pattern, imm4);
          case 3:
            return new Base<uint64_t>(machInst, dest, pattern, imm4);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes integer element count SVE instructions, handling
    // signed variants from 16 to 64 bits only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveElemIntCountLS(unsigned size, ExtMachInst machInst,
            RegIndex dest, uint8_t pattern, uint8_t imm4)
    {
        switch (size) {
          case 1:
            return new Base<int16_t>(machInst, dest, pattern, imm4);
          case 2:
            return new Base<int32_t>(machInst, dest, pattern, imm4);
          case 3:
            return new Base<int64_t>(machInst, dest, pattern, imm4);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes integer element count SVE instructions, handling
    // unsigned variants from 16 to 64 bits only.
    template <template <typename T> class Base>
    StaticInstPtr
    decodeSveElemIntCountLU(unsigned size, ExtMachInst machInst,
            RegIndex dest, uint8_t pattern, uint8_t imm4)
    {
        switch (size) {
          case 1:
            return new Base<uint16_t>(machInst, dest, pattern, imm4);
          case 2:
            return new Base<uint32_t>(machInst, dest, pattern, imm4);
          case 3:
            return new Base<uint64_t>(machInst, dest, pattern, imm4);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes SVE unpack instructions. Handling signed variants.
    template <template <typename T1, typename T2> class Base>
    StaticInstPtr
    decodeSveUnpackS(unsigned size, ExtMachInst machInst,
                    RegIndex dest, RegIndex op1)
    {
        switch (size) {
          case 1:
            return new Base<int8_t, int16_t>(machInst, dest, op1);
          case 2:
            return new Base<int16_t, int32_t>(machInst, dest, op1);
          case 3:
            return new Base<int32_t, int64_t>(machInst, dest, op1);
          default:
            return new Unknown64(machInst);
        }
    }

    // Decodes SVE unpack instructions. Handling unsigned variants.
    template <template <typename T1, typename T2> class Base>
    StaticInstPtr
    decodeSveUnpackU(unsigned size, ExtMachInst machInst,
                    RegIndex dest, RegIndex op1)
    {
        switch (size) {
          case 1:
            return new Base<uint8_t, uint16_t>(machInst, dest, op1);
          case 2:
            return new Base<uint16_t, uint32_t>(machInst, dest, op1);
          case 3:
            return new Base<uint32_t, uint64_t>(machInst, dest, op1);
          default:
            return new Unknown64(machInst);
        }
    }
}};

let {{

    header_output = ''
    exec_output = ''
    decoders = { 'Generic': {} }

    class PredType:
        NONE = 0
        MERGE = 1
        ZERO = 2
        SELECT = 3

    class CvtDir:
        Narrow = 0
        Widen = 1

    class IndexFormat(object):
        ImmImm = 'II'
        ImmReg = 'IR'
        RegImm = 'RI'
        RegReg = 'RR'

    class SrcRegType(object):
        Vector = 0
        Scalar = 1
        SimdFpScalar = 2
        Predicate = 3

    class DstRegType(object):
        Vector = 0
        Scalar = 1
        SimdFpScalar = 2
        Predicate = 3

    class DestType(object):
        Scalar = 'false'
        Vector = 'true'

    class SrcSize(object):
        Src32bit = 'true'
        Src64bit = 'false'

    class Break(object):
        Before = 0
        After = 1

    class Unpack(object):
        High = 0
        Low = 1

    exec_output += '''
    template <class Element>
    Element
    do_sint_sat(__int128_t elem, int width) {
        if (elem > (Element)mask(width - 1)) {
            return (Element)mask(width - 1);
        } else if (elem < ~(__int128_t)mask(width - 1)) {
            return static_cast<Element>((Element)1 << (width - 1));
        } else {
            return (Element)elem;
        }
    }
    '''

    # Generates definitions for SVE ADR instructions
    def sveAdrInst(name, Name, opClass, types, op):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        for (unsigned i = 0; i < eCount; i++) {
            const Element& srcElem1 = AA64FpOp1_x[i];
            Element srcElem2 = AA64FpOp2_x[i];
            Element destElem = 0;
            %(op)s
            AA64FpDest_x[i] = destElem;
        }''' % {'op': op}
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveAdrOp',
                               {'code': code, 'op_class': opClass}, [])
        header_output += SveAdrOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definition for SVE while predicate generation instructions
    def sveWhileInst(name, Name, opClass, types, op,
                    srcSize=SrcSize.Src64bit, toDown=False, isPair=False):
        global header_output, exec_output, decoders
        extraPrologCode = '''
        auto& destPred = PDest;'''
        if isPair:
            extraPrologCode += '''
        auto& destPred2 = PDest2;'''
        if 'int32_t' in types:
            srcType = 'int64_t' if srcSize == SrcSize.Src64bit else 'int32_t'
        else:
            srcType = 'uint64_t' if srcSize == SrcSize.Src64bit else 'uint32_t'
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        %(stype)s srcElem1 = static_cast<%(stype)s>(XOp1);
        %(stype)s srcElem2 = static_cast<%(stype)s>(XOp2);
        bool cond, none = true, last = true;
        bool last_active = false, first_active = false;
        destPred.reset();'''%{'stype': srcType}
        if isPair:
            code += '''
        destPred2.reset();'''
        if isPair:
            code += '''
        unsigned length = 2 * eCount;'''
        else:
            code += '''
        unsigned length = 1 * eCount;'''
        code += '''
        bool mask[length];'''
        if toDown:
            code += '''
        for (signed i = length - 1; i >= 0; i--) {'''
        else:
            code += '''
        for (signed i = 0; i < length; i++) {'''
        code += '''
            %(op)s;
            last = last && cond;
            none = none && !last;
            first_active = first_active || (i == 0 && last);
            last_active = last_active || (i == (length - 1) && last);
            mask[i] = last;'''%{'op': op}
        if toDown:
            code += '''
            srcElem1--;'''
        else:
            code += '''
            srcElem1++;'''
        code += '''
        }
        CondCodesNZ = (first_active << 1) | none;
        CondCodesC = !last_active;
        CondCodesV = false;
        '''
        if isPair:
            code += '''
        for (signed i = 0; i < eCount; i ++) {
            PDest_x[i] = mask[i];
        }
        for (signed i = 0; i < eCount; i ++) {
            PDest2_x[i] = mask[eCount + i];
        }'''
        else:
            code += '''
        for (signed i = 0; i < eCount; i ++) {
            PDest_x[i] = mask[i];
        }'''
        iop = ArmInstObjParams(name, 'Sve' + Name,
                'SveWhilePairOp' if isPair else 'SveWhileOp',
                {'code': code, 'op_class': opClass, 'srcIs32b': srcSize}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        if isPair:
            header_output += SveWhilePairOpDeclare.subst(iop)
        else:
            header_output += SveWhileOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type, 'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict);

    # Generates definition for SVE while predicate generation instructions
    def sveWhilePngInst(name, Name, opClass, types, op,
        srcSize = SrcSize.Src64bit, toDown = False):
        global header_output, exec_output, decoders
        extraPrologCode = '''
        auto& destPred = PDest;'''
        if 'int32_t' in types:
            srcType = 'int64_t' if srcSize == SrcSize.Src64bit else 'int32_t'
        else:
            srcType = 'uint64_t' if srcSize == SrcSize.Src64bit else 'uint32_t'
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        %(stype)s srcElem1 = static_cast<%(stype)s>(XOp1);
        %(stype)s srcElem2 = static_cast<%(stype)s>(XOp2);
        bool cond, none = true, last = true;
        bool last_active = false, first_active = false;
        unsigned count = 0;
        unsigned vl = 2 << imm;
        destPred.reset();'''%{'stype': srcType}
        if toDown:
            code += '''
        for (signed i = vl * eCount - 1; i >= 0; i--) {'''
        else:
            code += '''
        for (signed i = 0; i < vl * eCount; i++) {'''
        code += '''
            %(op)s;
            last = last && cond;
            none = none && !last;
            first_active = first_active || (i == 0 && last);
            last_active = last_active || (i == (vl * eCount - 1) && last);
            if (last) count = count + 1;'''%{'op': op}
        if toDown:
            code += '''
            srcElem1--;'''
        else:
            code += '''
            srcElem1++;'''
        code += '''
        }
        CondCodesNZ = (first_active << 1) | none;
        CondCodesC = !last_active;
        CondCodesV = false;
        '''
        code += '''
        uint16_t png = sveEncodePredCount(
            sizeof(Element), eCount * vl, count, %(invert)s);
        for (unsigned i = 0; i < 16; i ++) {
            PDest_ub[i] = (png >> i) & 0x1;
        }''' % {'invert': 'true' if toDown else 'false'}
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveWhilePngOp',
                {'code': code, 'op_class': opClass, 'srcIs32b': srcSize}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SveWhilePngOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type, 'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict);

    # Generates definition for SVE while predicate generation instructions
    def sveWhileRWInst(name, Name, opClass, types,
                       srcSize = SrcSize.Src64bit, absdiff = False):
        global header_output, exec_output, decoders
        extraPrologCode = '''
        auto& destPred = PDest;'''
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        uint64_t srcElem1 = static_cast<uint64_t>(XOp1);
        uint64_t srcElem2 = static_cast<uint64_t>(XOp2);
        bool cond, none = true, last = true;
        bool last_active = false, first_active = false;
        destPred.reset();
        '''
        if absdiff:
            code += '''
        int diff = (srcElem1 >= srcElem2 ? srcElem1 - srcElem2 :
                                           srcElem2 - srcElem1) /
                    sizeof(Element);'''
        else:
            code += '''
        int diff = (srcElem2 - srcElem1) / sizeof(Element);'''
        code += '''
        for (signed i = 0; i < eCount; i++) {
            cond = diff <= 0 || i < diff;
            last = last && cond;
            none = none && !last;
            first_active = first_active || (i == 0 && last);
            last_active = last_active || (i == (eCount - 1) && last);
            PDest_x[i] = cond;
        }
        CondCodesNZ = (first_active << 1) | none;
        CondCodesC = !last_active;
        CondCodesV = false;
        '''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveWhileOp',
                {'code': code, 'op_class': opClass, 'srcIs32b': srcSize}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SveWhileOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type, 'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict);

    # Generates definition for SVE psel predicate selection instructions
    def svePselInst(name, Name, opClass, types):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<TPElem>(
                xc->tcBase());
        unsigned pred_width = sizeof(TPElem) * eCount;

        unsigned index = ((uint32_t)XOp2 + imm) % eCount;
        bool copy = POp1_x[index];
        if (copy) {
            for (int i = 0; i < pred_width; ++i) {
                PDest_ub[i] = GpOp_ub[i];
            }
        } else {
            for (int i = 0; i < pred_width; ++i) {
                PDest_ub[i] = false;
            }
        }
        '''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SvePselOp',
                {'code': code, 'op_class': opClass}, [])
        header_output += SvePselOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type, 'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict);

    # Generate definition for SVE compare & terminate instructions
    def sveCompTermInst(name, Name, opClass, types, op):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        bool destElem;
        Element srcElem1 = static_cast<Element>(XOp1);
        Element srcElem2 = static_cast<Element>(XOp2);
        %(op)s;
        if (destElem) {
            CondCodesNZ = CondCodesNZ | 0x2;
            CondCodesV = 0;
        } else {
            CondCodesNZ = CondCodesNZ & ~0x2;
            CondCodesV = !CondCodesC;
        }
        ''' % {'op': op}
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveCompTermOp',
                {'code': code, 'op_class': opClass}, [])
        header_output += SveCompTermOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type, 'class_name': 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict);

    # Generates definition for SVE predicate count instructions
    def svePredCountInst(name, Name, opClass, types, op,
                         destType=DestType.Vector,
                         srcSize=SrcSize.Src64bit):
        global header_output, exec_output, decoders
        assert not (destType == DestType.Vector and
                srcSize != SrcSize.Src64bit)
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        int count = 0;
        for (unsigned i = 0; i < eCount; i++) {
            if (GpOp_x[i]) {
                count++;
            }
        }'''
        if destType == DestType.Vector:
            code += '''
        for (unsigned i = 0; i < eCount; i++) {
            Element destElem = 0;
            const Element& srcElem = AA64FpDestMerge_x[i];
            %(op)s
            AA64FpDest_x[i] = destElem;
        }''' % {'op': op}
        else:
            code += '''
        %(op)s''' % {'op': op}
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SvePredCountOp',
                {'code': code, 'op_class': opClass, 'srcIs32b': srcSize,
                 'destIsVec': destType}, [])
        header_output += SvePredCountOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type, 'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict);

    # Generates definition for SVE predicate count instructions (predicated)
    def svePredCountPredInst(name, Name, opClass, types):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        int count = 0;
        for (unsigned i = 0; i < eCount; i++) {
            if (POp1_x[i] && GpOp_x[i]) {
                count++;
            }
        }
        XDest = count;
        '''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SvePredCountPredOp',
                               {'code': code, 'op_class': opClass}, [])
        header_output += SvePredCountPredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type, 'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definition for SVE predicate count instructions
    # (predicate as counter)
    def svePredCountPngInst(name, Name, opClass, types):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        unsigned pred_width = sizeof(Element) * eCount;

        uint16_t png = 0;
        for (unsigned b = 0; b < 16; b ++) {
            png = png | ((uint16_t)POp1_ub[b] << b);
        }
        unsigned vl = 2 << imm;

        int count = 0;
        for (unsigned r = 0; r < vl; r ++) {
            ArmISA::VecPredRegContainer pred_mask_reg;
            sveCounterToPredicate(pred_mask_reg, png, pred_width, vl, r);
            auto pred_mask = pred_mask_reg.as<Element>();
            for (unsigned i = 0; i < eCount; i++) {
                if (pred_mask[i]) {
                    count++;
                }
            }
        }
        XDest = count;
        '''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SvePredCountPngOp',
                               {'code': code, 'op_class': opClass}, [])
        header_output += SvePredCountPngOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type, 'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definition for SVE Index generation instructions
    def sveIndex(fmt):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());'''
        if fmt == IndexFormat.ImmReg or fmt == IndexFormat.ImmImm:
            code += '''
        const Element& srcElem1 = imm1;'''
        if fmt == IndexFormat.RegImm or fmt == IndexFormat.RegReg:
            code += '''
        const Element& srcElem1 = XOp1;'''
        if fmt == IndexFormat.RegImm or fmt == IndexFormat.ImmImm:
            code += '''
        const Element& srcElem2 = imm2;'''
        if fmt == IndexFormat.ImmReg or fmt == IndexFormat.RegReg:
            code += '''
        const Element& srcElem2 = XOp2;'''
        code +='''
        for (unsigned i = 0; i < eCount; i++) {
            AA64FpDest_x[i] = srcElem1 + i * srcElem2;
        }'''
        iop = ArmInstObjParams('index', 'SveIndex'+fmt, 'SveIndex'+fmt+'Op',
            {'code': code, 'op_class': 'SimdAluOp'})
        if fmt == IndexFormat.ImmImm:
            header_output += SveIndexIIOpDeclare.subst(iop)
        elif fmt == IndexFormat.ImmReg:
            header_output += SveIndexIROpDeclare.subst(iop)
        elif fmt == IndexFormat.RegImm:
            header_output += SveIndexRIOpDeclare.subst(iop)
        elif fmt == IndexFormat.RegReg:
            header_output += SveIndexRROpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in ['int8_t', 'int16_t', 'int32_t', 'int64_t']:
            substDict = {'targs': type, 'class_name': 'SveIndex'+fmt}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for widening unary SVE instructions
    # (always constructive)
    def sveWidenUnaryInst(name, Name, opClass, types, op,
                          predType=PredType.NONE, decoder='Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<DElement>(
                xc->tcBase());
        for (unsigned i = 0; i < eCount; i++) {
            SElement srcElem1 = AA64FpOp1_xd[i];
            DElement destElem = 0;'''
        if predType != PredType.NONE:
            code += '''
            if (GpOp_xd[i]) {
                %(op)s
            } else {
                destElem = %(dest_elem)s;
            }''' % {'op': op,
                    'dest_elem': 'AA64FpDestMerge_xd[i]'
                                 if predType == PredType.MERGE
                                 else '0'}
        else:
            code += '''
            %(op)s''' % {'op': op}
        code += '''
            AA64FpDest_xd[i] = destElem;
        }'''
        iop = ArmInstObjParams(name, 'Sve' + Name,
                               'SveUnaryPredOp' if predType != PredType.NONE
                               else 'SveUnaryUnpredOp',
                               {'code': code, 'op_class': opClass}, [])
        if predType != PredType.NONE:
            header_output += SveWideningUnaryPredOpDeclare.subst(iop)
        else:
            header_output += SveWideningUnaryUnpredOpDeclare.subst(iop)
        exec_output += SveWideningOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for unary SVE instructions (always constructive)
    def sveUnaryInst(name, Name, opClass, types, op, predType=PredType.NONE,
                     srcRegType=SrcRegType.Vector, decoder='Generic'):
        global header_output, exec_output, decoders
        op1 = ('AA64FpOp1_x[i]' if srcRegType == SrcRegType.Vector
               else 'XOp1' if srcRegType == SrcRegType.Scalar
               else 'AA64FpOp1_x[0]')
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        for (unsigned i = 0; i < eCount; i++) {
            Element srcElem1 = %s;
            Element destElem = 0;''' % op1
        if predType != PredType.NONE:
            code += '''
            if (GpOp_x[i]) {
                %(op)s
            } else {
                destElem = %(dest_elem)s;
            }''' % {'op': op,
                    'dest_elem': 'AA64FpDestMerge_x[i]'
                                 if predType == PredType.MERGE
                                 else '0'}
        else:
            code += '''
            %(op)s''' % {'op': op}
        code += '''
            AA64FpDest_x[i] = destElem;
        }'''
        iop = ArmInstObjParams(name, 'Sve' + Name,
                               'SveUnaryPredOp' if predType != PredType.NONE
                               else 'SveUnaryUnpredOp',
                               {'code': code, 'op_class': opClass}, [])
        if predType != PredType.NONE:
            header_output += SveUnaryPredOpDeclare.subst(iop)
        else:
            header_output += SveUnaryUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for binary SVE instructions with immediate operand
    def sveUnaryNarrowInst(name, Name, opClass, types, op, uptTop = False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        typedef typename bigger_type_t<Element>::type BigElement;
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());

        union RegElem
        {
            Element elements[2];
            BigElement bigElements[1];
        };
        RegElem regElem;

        for (unsigned i = 0; i < eCount / 2; i++) {
            regElem.elements[0] = AA64FpOp1_x[2 * i + 0];
            regElem.elements[1] = AA64FpOp1_x[2 * i + 1];
            BigElement srcElem1 = regElem.bigElements[0];
            Element destElem = 0;
            %(op)s''' % {'op': op}
        if uptTop:
            code += '''
            AA64FpDest_x[2 * i + 0] = AA64FpDestMerge_x[2 * i + 0];
            AA64FpDest_x[2 * i + 1] = destElem;'''
        else:
            code += '''
            AA64FpDest_x[2 * i + 0] = destElem;
            AA64FpDest_x[2 * i + 1] = 0;'''
        code += '''
        }'''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveUnaryUnpredOp',
                {'code': code, 'op_class': opClass}, [])
        header_output += SveUnaryUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for SVE floating-point conversions (always
    # unary, constructive, merging
    def sveCvtInst(name, Name, opClass, types, op, direction=CvtDir.Narrow,
                   decoder='Generic', signed=False, uptTop=False):
        global header_output, exec_output, decoders

        if signed:
            mask = "SElement msk = mask(sizeof(DElement)*8);"
            source_code = '''
                SElement srcElem1 = AA64FpOp1_x%(bigElemSuffix)s[i] &
                        mask(sizeof(SElement) * 8);
                        ''' % {
                'bigElemSuffix': 's' if direction == CvtDir.Narrow else 'd'
                }
            assign_code = '''
                int sign_bit = bits(destElem, sizeof(DElement)*8 -1);
                AA64FpDest_x%(bigElemSuffix)s[i] =
                                    sign_bit? (destElem|~msk): destElem;
                          '''  % {
               'bigElemSuffix': 's' if direction == CvtDir.Narrow else 'd'
               }
        elif not uptTop:
            mask = "";
            source_code = '''
                SElement srcElem1 = AA64FpOp1_x%(bigElemSuffix)s[i] &
                        mask(sizeof(SElement) * 8);
                        ''' % {
                'bigElemSuffix': 's' if direction == CvtDir.Narrow else 'd'
                }
            assign_code = '''
                AA64FpDest_x%(bigElemSuffix)s[i] = destElem;
            '''  % {
               'bigElemSuffix': 's' if direction == CvtDir.Narrow else 'd'
                   }
        elif direction == CvtDir.Narrow:
            mask = "";
            source_code = '''
                SElement srcElem1 = AA64FpOp1_x%(bigElemSuffix)s[i] &
                        mask(sizeof(SElement) * 8);
                        ''' % {
                'bigElemSuffix': 's' if direction == CvtDir.Narrow else 'd'
                }
            assign_code = '''
                SElement merge_data = AA64FpDestMerge_x%(bigElemSuffix)s[i] &
                    (((SElement)1 << (sizeof(DElement) * 8)) - 1);
                AA64FpDest_x%(bigElemSuffix)s[i] = merge_data |
                    ((SElement)destElem << (sizeof(DElement) * 8));
            '''  % {
               'bigElemSuffix': 's' if direction == CvtDir.Narrow else 'd'
                   }
        else:
            mask = "";
            source_code = '''
                SElement srcElem1 = (AA64FpOp1_x%(bigElemSuffix)s[i] >>
                                    (sizeof(SElement) * 8)) &
                        mask(sizeof(SElement) * 8);
                        ''' % {
                'bigElemSuffix': 's' if direction == CvtDir.Narrow else 'd'
                }
            assign_code = '''
                AA64FpDest_x%(bigElemSuffix)s[i] = destElem;
            '''  % {
               'bigElemSuffix': 's' if direction == CvtDir.Narrow else 'd'
                   }

        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<%(bigElemType)s>(
                xc->tcBase());
        %(mask)s
        for (unsigned i = 0; i < eCount; i++) {
            %(source)s;
            DElement destElem = 0;
            if (GpOp_x%(bigElemSuffix)s[i]) {
                %(op)s
                %(assign)s;
            } else {
                AA64FpDest_x%(bigElemSuffix)s[i] =
                        AA64FpDestMerge_x%(bigElemSuffix)s[i];
            }
        }
        ''' % {'bigElemType': 'SElement' if direction == CvtDir.Narrow
                                         else 'DElement',
               'op': op, 'mask': mask,
               'bigElemSuffix': 's' if direction == CvtDir.Narrow else 'd',
               'source': source_code,
               'assign': assign_code
               }

        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveUnaryPredOp',
                               {'code': code, 'op_class': opClass}, [])
        header_output += SveWideningUnaryPredOpDeclare.subst(iop)
        exec_output += SveWideningOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for associative SVE reductions
    def sveAssocReducInst(name, Name, opClass, types, op, identity,
                          decoder='Generic', isHvla=False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        ArmISA::VecRegContainer tmpVecC;
        auto auxOp1 = tmpVecC.as<Element>();
        for (unsigned i = 0; i < eCount; ++i) {
            auxOp1[i] = AA64FpOp1_x[i];
        }'''
        if isHvla:
            code += '''
        constexpr unsigned ePerSegment = 16 / sizeof(Element);
        for (unsigned i = 0; i < ePerSegment; i++) {
            Element destElem = %(identity)s;
            for (unsigned s = 0; s < eCount / ePerSegment; s ++) {
                unsigned index = s * ePerSegment + i;
                if (GpOp_x[index]) {
                    const Element& srcElem1 = auxOp1[index];
                    %(op)s
                }
            }
            AA64FpDest_x[i] = destElem;
        }
        // zero upper part
        for (unsigned i = ePerSegment; i < eCount; i ++) {
            AA64FpDest_x[i] = 0;
        }
        ''' % {'op': op, 'identity': identity}
        else:
            code += '''
        Element destElem = %(identity)s;
        for (unsigned i = 0; i < eCount; i++) {
            AA64FpDest_x[i] = 0;  // zero upper part
            if (GpOp_x[i]) {
                const Element& srcElem1 = auxOp1[i];
                %(op)s
            }
        }
        AA64FpDest_x[0] = destElem;
        ''' % {'op': op, 'identity': identity}
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveReducOp',
                               {'code': code, 'op_class': opClass}, [])
        header_output += SveReducOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for widening associative SVE reductions
    def sveWideningAssocReducInst(name, Name, opClass, types, op, identity,
                                  decoder='Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<SElement>(
                xc->tcBase());
        unsigned eWideCount = ArmStaticInst::getCurSveVecLen<DElement>(
                xc->tcBase());
        DElement destElem = %(identity)s;
        for (unsigned i = 0; i < eCount; i++) {
            if (GpOp_xs[i]) {
                DElement srcElem1 = AA64FpOp1_xs[i];
                %(op)s
            }
        }
        AA64FpDest_xd[0] = destElem;
        for (int i = 1; i < eWideCount; i++) {
            AA64FpDest_xd[i] = 0;
        }
        ''' % {'op': op, 'identity': identity}
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveReducOp',
                               {'code': code, 'op_class': opClass}, [])
        header_output += SveWideningReducOpDeclare.subst(iop)
        exec_output += SveWideningOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for non-associative SVE reductions
    def sveNonAssocReducInst(name, Name, opClass, types, op, identity,
                             decoder='Generic', isHvla=False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        ArmISA::VecRegContainer tmpVecC;
        auto tmpVec = tmpVecC.as<Element>();
        int ePow2Count = 1;
        while (ePow2Count < eCount) {
            ePow2Count *= 2;
        }

        for (unsigned i = 0; i < ePow2Count; i++) {
            if (i < eCount && GpOp_x[i]) {
                tmpVec[i] = AA64FpOp1_x[i];
            } else {
                tmpVec[i] = %(identity)s;
            }
        }
        ''' % {'identity': identity}
        if isHvla:
            code += '''
        constexpr unsigned ePerSegment = 16 / sizeof(Element);
        for (unsigned i = 0; i < ePerSegment; i++) {
            unsigned n = ePow2Count / ePerSegment;
            while (n > 1) {
                unsigned max = n;
                n = 0;
                for (unsigned s = 0; s < max; s += 2) {
                    Element srcElem1 = tmpVec[(s + 0) * ePerSegment + i];
                    Element srcElem2 = tmpVec[(s + 1) * ePerSegment + i];
                    Element destElem = 0;
                    %(op)s
                    tmpVec[n * ePerSegment + i] = destElem;
                    n++;
                }
            }
        }
        for (unsigned i = 0; i < ePerSegment; i ++) {
            AA64FpDest_x[i] = tmpVec[i];
        }
        // zero upper part
        for (unsigned i = ePerSegment; i < eCount; i ++) {
            AA64FpDest_x[i] = 0;
        }
        ''' % {'op': op}
        else:
            code += '''
        unsigned n = ePow2Count;
        while (n > 1) {
            unsigned max = n;
            n = 0;
            for (unsigned i = 0; i < max; i += 2) {
                Element srcElem1 = tmpVec[i];
                Element srcElem2 = tmpVec[i + 1];
                Element destElem = 0;
                %(op)s
                tmpVec[n] = destElem;
                n++;
            }
        }
        AA64FpDest_x[0] = tmpVec[0];
        for (unsigned i = 1; i < eCount; i++) {
            AA64FpDest_x[i] = 0;  // zero upper part
        }
        ''' % {'op': op}
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveReducOp',
                               {'code': code, 'op_class': opClass}, [])
        header_output += SveReducOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for binary SVE instructions with immediate operand
    def sveBinImmInst(name, Name, opClass, types, op, predType=PredType.NONE,
                      decoder='Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        for (unsigned i = 0; i < eCount; i++) {'''
        if predType != PredType.NONE:
            code += '''
            const Element& srcElem1 = %s;''' % (
                'AA64FpDestMerge_x[i]' if predType == PredType.MERGE else '0')
        else:
            code += '''
            const Element& srcElem1 = AA64FpOp1_x[i];'''
        code += '''
            Element srcElem2 = imm;
            Element destElem = 0;'''
        if predType != PredType.NONE:
            code += '''
            if (GpOp_x[i]) {
                %(op)s
            } else {
                destElem = %(dest_elem)s;
            }''' % {'op': op,
                    'dest_elem': 'AA64FpDestMerge_x[i]'
                                 if predType == PredType.MERGE else '0'}
        else:
            code += '''
            %(op)s''' % {'op': op}
        code += '''
            AA64FpDest_x[i] = destElem;
        }'''
        iop = ArmInstObjParams(name, 'Sve' + Name,
                'SveBinImmPredOp' if predType != PredType.NONE
                else 'SveBinImmUnpredConstrOp',
                {'code': code, 'op_class': opClass}, [])
        if predType != PredType.NONE:
            header_output += SveBinImmPredOpDeclare.subst(iop)
        else:
            header_output += SveBinImmUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for unary and binary SVE instructions with wide
    # immediate operand
    def sveWideImmInst(name, Name, opClass, types, op, predType=PredType.NONE,
                       isUnary=False, decoder='Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        for (unsigned i = 0; i < eCount; i++) {'''
        # TODO: handle unsigned-to-signed conversion properly...
        if isUnary:
            code += '''
            Element srcElem1 = imm;'''
        else:
            code += '''
            const Element& srcElem1 = AA64FpDestMerge_x[i];
            Element srcElem2 = imm;'''
        code += '''
            Element destElem = 0;'''
        if predType != PredType.NONE:
            code += '''
            if (GpOp_x[i]) {
                %(op)s
            } else {
                destElem = %(dest_elem)s;
            }''' % {'op': op,
                    'dest_elem': 'AA64FpDestMerge_x[i]'
                                 if predType == PredType.MERGE else '0'}
        else:
            code += '''
            %(op)s''' % {'op': op}
        code += '''
            AA64FpDest_x[i] = destElem;
        }'''
        iop = ArmInstObjParams(name, 'Sve' + Name,
                'Sve%sWideImm%sOp' % (
                    'Unary' if isUnary else 'Bin',
                    'Unpred' if predType == PredType.NONE else 'Pred'),
                {'code': code, 'op_class': opClass}, [])
        if predType == PredType.NONE:
            header_output += SveWideImmUnpredOpDeclare.subst(iop)
        else:
            header_output += SveWideImmPredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for shift SVE instructions with wide elements
    def sveBinWideElemInst(name, Name, opClass, types, op,
                            predType=PredType.NONE, decoder='Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        ArmISA::VecRegContainer tmpVecC;
        auto auxOp2 = tmpVecC.as<Element>();
        for (unsigned i = 0; i < eCount; i++) {
            auxOp2[i] = AA64FpOp2_ud[i];
        }
        for (unsigned i = 0; i < eCount; i++) {'''
        if predType != PredType.NONE:
            code += '''
            const Element& srcElem1 = AA64FpDestMerge_x[i];'''
        else:
            code += '''
            const Element& srcElem1 = AA64FpOp1_x[i];'''
        code += '''
            const auto& srcElem2 = AA64FpOp2_ud[
                    (i * sizeof(Element) * 8) / 64];
            Element destElem = 0;'''
        if predType != PredType.NONE:
            code += '''
            if (GpOp_x[i]) {
                %(op)s
            } else {
                destElem = %(dest_elem)s;
            }''' % {'op': op,
                    'dest_elem': 'AA64FpDestMerge_x[i]'
                                 if predType == PredType.MERGE else '0'}
        else:
            code += '''
            %(op)s''' % {'op': op}
        code += '''
            AA64FpDest_x[i] = destElem;
        }'''
        iop = ArmInstObjParams(name, 'Sve' + Name,
                               'SveBinDestrPredOp' if predType != PredType.NONE
                               else 'SveBinUnpredOp',
                               {'code': code, 'op_class': opClass}, [])
        if predType != PredType.NONE:
            header_output += SveBinDestrPredOpDeclare.subst(iop)
        else:
            header_output += SveBinUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for binary indexed SVE instructions
    # (always unpredicated)
    def sveBinIdxInst(name, Name, opClass, types, op, decoder='Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());

        // Number of elements in a 128 bit segment
        constexpr unsigned ePerSegment = 16 / sizeof(Element);

        ArmISA::VecRegContainer tmpC;
        auto auxDest = tmpC.as<TPElem>();
        for (unsigned i = 0; i < eCount; i++) {
            const auto segmentBase = i - i %% ePerSegment;
            const auto segmentIdx = segmentBase + index;

            const Element& srcElem1 = AA64FpOp1_x[i];
            const Element& srcElem2 = AA64FpOp2_x[segmentIdx];
            Element destElem = 0;

            %(op)s
            auxDest[i] = destElem;
        }

        for (unsigned i = 0; i < eCount; i++) {
            AA64FpDest_x[i] = auxDest[i];
        }''' % {'op':op}

        baseClass = 'SveBinIdxUnpredOp'

        iop = ArmInstObjParams(name, 'Sve' + Name, baseClass,
                               {'code': code, 'op_class': opClass}, [])
        header_output += SveBinIdxUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for binary SVE instructions
    def sveBinInst(name, Name, opClass, types, op, predType=PredType.NONE,
                   isDestructive=False, customIterCode=None,
                   decoder='Generic'):
        assert not ((predType == PredType.SELECT) and isDestructive)
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());'''
        if customIterCode is None:
            code += '''
        for (unsigned i = 0; i < eCount; i++) {'''
            if predType == PredType.MERGE:
                code += '''
            const Element& srcElem1 = AA64FpDestMerge_x[i];'''
            else:
                code += '''
            const Element& srcElem1 = AA64FpOp1_x[i];'''
            code += '''
            const Element& srcElem2 = AA64FpOp2_x[i];'''
            if (predType == PredType.NONE) and isDestructive:
                code += '''
            Element destElem = AA64FpDestMerge_x[i];'''
            else:
                code += '''
            Element destElem = 0;'''
            if predType != PredType.NONE:
                code += '''
            if (GpOp_x[i]) {
                %(op)s
            } else {
                destElem = %(dest_elem)s;
            }''' % {'op': op,
                    'dest_elem':
                        'AA64FpDestMerge_x[i]' if predType == PredType.MERGE
                        else '0' if predType == PredType.ZERO
                        else 'srcElem2'}
            else:
                code += '''
            %(op)s''' % {'op': op}
            code += '''
            AA64FpDest_x[i] = destElem;
        }'''
        else:
            code += customIterCode
        if predType == PredType.NONE:
            baseClass = 'SveBinUnpredOp'
        elif isDestructive:
            baseClass = 'SveBinDestrPredOp'
        else:
            baseClass = 'SveBinConstrPredOp'
        iop = ArmInstObjParams(name, 'Sve' + Name, baseClass,
                               {'code': code, 'op_class': opClass}, [])
        if predType == PredType.NONE:
            header_output += SveBinUnpredOpDeclare.subst(iop)
        elif isDestructive:
            header_output += SveBinDestrPredOpDeclare.subst(iop)
        else:
            header_output += SveBinConstrPredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for binary SVE instructions
    def sveBinInterInst(name, Name, opClass, types, op, tb = False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());

        for (unsigned i = 0; i < eCount / 2; i++) {
            const Element& srcElem1 = AA64FpOp1_x[2 * i + %(sel1)s];
            const Element& srcElem2 = AA64FpOp2_x[2 * i + %(sel2)s];
            Element destElem = AA64FpDestMerge_x[2 * i + %(sel1)s];
            %(op)s
            AA64FpDest_x[2 * i + %(sel1)s] = destElem;
            AA64FpDest_x[2 * i + %(sel2)s] =
                AA64FpDestMerge_x[2 * i + %(sel2)s];
        }
        ''' % {'op': op, 'sel1': 1 if tb else 0, 'sel2': 0 if tb else 1}
        baseClass = 'SveBinUnpredOp'
        iop = ArmInstObjParams(name, 'Sve' + Name, baseClass,
                               {'code': code, 'op_class': opClass}, [])
        header_output += SveBinUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for binary paired SVE instructions
    def sveBinPairInst(name, Name, opClass, types, op):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());

        for (unsigned i = 0; i < eCount; i++) {
            bool even = (i & 0x1) == 0;
            Element srcElem1 = even ? AA64FpDestMerge_x[i + 0] :
                                      AA64FpOp2_x[i - 1];
            Element srcElem2 = even ? AA64FpDestMerge_x[i + 1] :
                                      AA64FpOp2_x[i - 0];
            Element destElem = 0;

            if (GpOp_x[i]) {
                %(op)s
            } else {
                destElem = AA64FpDestMerge_x[i];
            }
            AA64FpDest_x[i] = destElem;
        }''' % {'op': op}
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveBinDestrPredOp',
                               {'code': code, 'op_class': opClass}, [])
        header_output += SveBinDestrPredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for binary paired SVE instructions
    def sveBinPairLongInst(name, Name, opClass, types, op):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        typedef typename bigger_type_t<Element>::type BigElement;
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());

        union RegElem
        {
            Element elements[2];
            BigElement bigElements[1];
        };
        RegElem regElem;

        for (unsigned i = 0; i < eCount / 2; i++) {
            Element srcElem1 = AA64FpOp2_x[2 * i + 0];
            Element srcElem2 = AA64FpOp2_x[2 * i + 1];
            regElem.elements[0] = AA64FpDestMerge_x[2 * i + 0];
            regElem.elements[1] = AA64FpDestMerge_x[2 * i + 1];
            BigElement destElem = regElem.bigElements[0];

            if (GpOp_x[2 * i]) {
                %(op)s
            }

            regElem.bigElements[0] = destElem;
            AA64FpDest_x[2 * i + 0] = regElem.elements[0];
            AA64FpDest_x[2 * i + 1] = regElem.elements[1];
        }''' % {'op': op}
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveBinDestrPredOp',
                               {'code': code, 'op_class': opClass}, [])
        header_output += SveBinDestrPredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for binary widen SVE instructions
    def sveBinWidenInst(name, Name, opClass, types, op, uptTop = False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        typedef typename bigger_type_t<Element>::type BigElement;
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());

        union RegElem
        {
            Element elements[2];
            BigElement bigElements[1];
        };
        RegElem regElem;

        for (int i = 0; i < eCount / 2; ++i) {
            regElem.elements[0] = AA64FpOp1_x[2 * i + 0];
            regElem.elements[1] = AA64FpOp1_x[2 * i + 1];
            BigElement srcElem1 = regElem.bigElements[0];
            Element srcElem2 = AA64FpOp2_x[2 * i + %(offset)s];
            BigElement destElem = 0;
            %(op)s
            regElem.bigElements[0] = destElem;
            AA64FpDest_x[2 * i + 0] = regElem.elements[0];
            AA64FpDest_x[2 * i + 1] = regElem.elements[1];
        }''' % {'op': op, 'offset': 1 if uptTop else 0}
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveDotProdOp',
                {'code': code, 'op_class': opClass}, [])
        header_output += SveBinUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs': type, 'class_name': 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for binary narrow SVE instructions
    def sveBinNarrowInst(name, Name, opClass, types, op,
                         isImm = False, uptTop = False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        typedef typename bigger_type_t<Element>::type BigElement;
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());

        union RegElem
        {
            Element elements[2];
            BigElement bigElements[1];
        };
        RegElem regElem;

        for (int i = 0; i < eCount / 2; ++i) {
            regElem.elements[0] = AA64FpOp1_x[2 * i + 0];
            regElem.elements[1] = AA64FpOp1_x[2 * i + 1];
            BigElement srcElem1 = regElem.bigElements[0];'''
        if not isImm:
            code += '''
            regElem.elements[0] = AA64FpOp2_x[2 * i + 0];
            regElem.elements[1] = AA64FpOp2_x[2 * i + 1];
            BigElement srcElem2 = regElem.bigElements[0];'''
        code += '''
            Element destElem;
            %(op)s
        ''' % {'op': op}
        if uptTop:
            code += '''
            AA64FpDest_x[2 * i + 0] = AA64FpDestMerge_x[2 * i + 0];
            AA64FpDest_x[2 * i + 1] = destElem;'''
        else:
            code += '''
            AA64FpDest_x[2 * i + 0] = destElem;
            AA64FpDest_x[2 * i + 1] = 0;'''
        code += '''
        }
        '''
        iop = ArmInstObjParams(name, 'Sve' + Name,
                    'SveBinImmUnpredConstrOp' if isImm else 'SveBinUnpredOp',
                    {'code': code, 'op_class': opClass}, [])
        if isImm:
            header_output += SveBinImmUnpredOpDeclare.subst(iop)
        else:
            header_output += SveBinUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definitions for long integer/poly multiplication instruction
    def sveBinLongInst(name, Name, opClass, types, op, decoder = 'Generic',
            isImm = False, isIndexed = False, uptTop = False,
            bt = False, tb = False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        typedef typename bigger_type_t<Element>::type BigElement;
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());

        union RegElem
        {
            Element elements[2];
            BigElement bigElements[1];
        };
        RegElem regElem;
        '''
        if isIndexed:
            code += '''
        constexpr unsigned ePerSegment = 16 / (2 * sizeof(Element));'''
        code += '''
        for (int i = 0; i < eCount/2; ++i) {
            const Element& srcElem1 = AA64FpOp1_x[2*i+%(offset)s];''' % {
                'offset': 1 if uptTop or tb else 0}
        if isImm:
            code += '''
            Element srcElem2 = imm;'''
        elif isIndexed:
            code += '''
            const auto segmentBase = i - i % ePerSegment;
            const auto segmentIdx = 2 * segmentBase + index;
            const Element& srcElem2 = AA64FpOp2_x[segmentIdx];
            '''
        else:
            code += '''
            const Element& srcElem2 = AA64FpOp2_x[2*i+%(offset)s];''' % {
                'offset': 1 if uptTop or bt else 0}
        code += '''
            BigElement destElem;
            %(op)s
            regElem.bigElements[0] = destElem;
            AA64FpDest_x[2 * i + 0] = regElem.elements[0];
            AA64FpDest_x[2 * i + 1] = regElem.elements[1];
        }
        ''' % {'op': op}
        iop = ArmInstObjParams(name, 'Sve' + Name,
                'SveBinImmUnpredConstrOp' if isImm else \
                'SveBinIdxUnpredOp' if isIndexed else \
                'SveBinUnpredOp',
                {'code': code, 'op_class': opClass}, [])
        if isImm:
            header_output += SveBinImmUnpredOpDeclare.subst(iop)
        elif isIndexed:
            header_output += SveBinIdxUnpredOpDeclare.subst(iop)
        else:
            header_output += SveBinUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for binary narrow SVE instructions
    def sveBinNarrowMultiInst(name, Name, opClass, types, op, hasImm=False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        typedef typename bigger_type_t<Element>::type BigElement;
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());

        union RegElem
        {
            Element elements[2];
            BigElement bigElements[1];
        };
        RegElem regElem;

        for (int i = 0; i < eCount / 2; ++i) {
            regElem.elements[0] = AA64FpOp1_x[2 * i + 0];
            regElem.elements[1] = AA64FpOp1_x[2 * i + 1];
            BigElement srcElem1 = regElem.bigElements[0];
            regElem.elements[0] = AA64FpOp2_x[2 * i + 0];
            regElem.elements[1] = AA64FpOp2_x[2 * i + 1];
            BigElement srcElem2 = regElem.bigElements[0];

            Element destElem;
            %(op)s
            AA64FpDest_x[2 * i + 0] = destElem;
            srcElem1 = srcElem2;
            %(op)s
            AA64FpDest_x[2 * i + 1] = destElem;
        }
        ''' % {'op': op}
        iop = ArmInstObjParams(name, 'Sve' + Name,
                    'SveMultiNarrowImmOp' if hasImm else 'SveMultiNarrowOp',
                    {'code': code, 'op_class': opClass}, [])
        if hasImm:
            header_output += SveMultiNarrowImmOpDeclare.subst(iop)
        else:
            header_output += SveMultiNarrowOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for predicate logical instructions
    def svePredLogicalInst(name, Name, opClass, types, op,
                           predType=PredType.ZERO, isFlagSetting=False,
                           decoder='Generic'):
        global header_output, exec_output, decoders
        assert predType in (PredType.ZERO, PredType.SELECT)
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        ArmISA::VecPredRegContainer tmpPredC;
        auto auxGpOp = tmpPredC.as<Element>();
        for (unsigned i = 0; i < eCount; i++) {
            auxGpOp[i] = GpOp_x[i];
        }
        for (unsigned i = 0; i < eCount; i++) {
            bool srcElem1 = POp1_x[i];
            bool srcElem2 = POp2_x[i];
            bool destElem = false;
            if (auxGpOp[i]) {
                %(op)s
            } else {
                destElem = %(dest_elem)s;
            }
            PDest_x[i] = destElem;
        }''' % {'op': op,
                'dest_elem': 'false' if predType == PredType.ZERO
                              else 'srcElem2'}
        extraPrologCode = ''
        if isFlagSetting:
            code += '''
        CondCodesNZ = (destPred.firstActive(auxGpOp, eCount) << 1) |
                      destPred.noneActive(auxGpOp, eCount);
        CondCodesC = !destPred.lastActive(auxGpOp, eCount);
        CondCodesV = 0;'''
            extraPrologCode += '''
        auto& destPred = PDest;'''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SvePredLogicalOp',
                               {'code': code, 'op_class': opClass}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SvePredLogicalOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for predicate permute instructions
    def svePredBinPermInst(name, Name, opClass, types, iterCode,
                           decoder='Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());'''
        code += iterCode
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SvePredBinPermOp',
                               {'code': code, 'op_class': opClass}, [])
        header_output += SveBinUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for SVE compare instructions
    # NOTE: compares are all predicated zeroing
    def sveCmpInst(name, Name, opClass, types, op, isImm=False,
                   decoder='Generic'):
        global header_output, exec_output, decoders
        extraPrologCode = '''
        auto& destPred = PDest;'''
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        ArmISA::VecPredRegContainer tmpPredC;
        auto tmpPred = tmpPredC.as<Element>();
        for (unsigned i = 0; i < eCount; ++i)
            tmpPred[i] = GpOp_x[i];
        destPred.reset();
        for (unsigned i = 0; i < eCount; i++) {
            const Element& srcElem1 = AA64FpOp1_x[i];
            [[maybe_unused]] %(src_elem_2_ty)s srcElem2 = %(src_elem_2)s;
            bool destElem = false;
            if (tmpPred[i]) {
                %(op)s
            } else {
                destElem = false;
            }
            PDest_x[i] = destElem;
        }''' % {'op': op,
                'src_elem_2_ty': 'Element' if isImm else 'const Element&',
                'src_elem_2': 'imm' if isImm else 'AA64FpOp2_x[i]'}
        iop = ArmInstObjParams(name, 'Sve' + Name,
                               'SveCmpImmOp' if isImm else 'SveCmpOp',
                               {'code': code, 'op_class': opClass}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        if isImm:
            header_output += SveCmpImmOpDeclare.subst(iop)
        else:
            header_output += SveCmpOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for SVE match instructions
    # NOTE: compares are all predicated zeroing
    def sveMatchInst(name, Name, opClass, types, isNeg=False,
                   decoder='Generic'):
        global header_output, exec_output, decoders
        extraPrologCode = '''
        auto& destPred = PDest;'''
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        uint32_t eltspersegment = 16 / sizeof(Element);

        ArmISA::VecPredRegContainer tmpPredC;
        auto tmpPred = tmpPredC.as<Element>();
        for (unsigned i = 0; i < eCount; ++i)
            tmpPred[i] = GpOp_x[i];
        destPred.reset();
        for (unsigned i = 0; i < eCount; i++) {
            const Element& srcElem1 = AA64FpOp1_x[i];
            bool destElem = false;
            if (tmpPred[i]) {
                uint32_t segmentbase = i - (i % eltspersegment);
                for (unsigned j = segmentbase;
                        j < segmentbase + eltspersegment; j ++) {
                    const Element& srcElem2 = AA64FpOp2_x[j];
                    if (srcElem1 == srcElem2) {
                        destElem = true;
                    }
                }
        '''
        if isNeg:
            code += '''
                destElem = !destElem;
        '''
        code += '''
            } else {
                destElem = false;
            }

            PDest_x[i] = destElem;
        }
        CondCodesNZ = (destPred.firstActive(tmpPred, eCount) << 1) |
                      destPred.noneActive(tmpPred, eCount);
        CondCodesC = !destPred.lastActive(tmpPred, eCount);
        CondCodesV = 0;
        '''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveCmpOp',
                               {'code': code, 'op_class': opClass}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SveCmpOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for ternary SVE intructions (always predicated -
    # merging)
    def sveTerInst(name, Name, opClass, types, op, predType=PredType.NONE,
                   decoder='Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        for (unsigned i = 0; i < eCount; i++) {
            const Element& srcElem1 = AA64FpOp1_x[i];
            const Element& srcElem2 = AA64FpOp2_x[i];
            Element destElem = AA64FpDestMerge_x[i];'''
        if predType != PredType.NONE:
            code += '''
            if (GpOp_x[i]) {
                %(op)s
            }''' % {'op': op}
        else:
            code += '''
            %(op)s''' % {'op': op}
        code += '''
            AA64FpDest_x[i] = destElem;
        }'''
        if predType == PredType.NONE:
            baseClass = 'SveTerUnpredOp'
        else:
            baseClass = 'SveTerPredOp'
        iop = ArmInstObjParams(name, 'Sve' + Name, baseClass,
                               {'code': code, 'op_class': opClass}, [])
        if predType == PredType.NONE:
            header_output += sveTerUnpredOpDeclare.subst(iop)
        else:
            header_output += SveTerPredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for ternary SVE2 intructions (unpredicated)
    def sveTerInstUnpred(name, Name, opClass, types, op,
                         isTop=False, isAdd=True, decoder='Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned const pairs = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase()) / 2;
        for (unsigned p = 0; p < pairs; p++) {
            const Element& srcElem1 = AA64FpDestMerge_x[2 * p + 0];
            const Element& srcElem2 = AA64FpOp1_x[%(src_top_elem)s];
            int carryIn = bits(AA64FpOp2_x[2 * p + 1], 0);
            Element %(op)s
            int carryOut = findCarry(
                                    sizeof(Element) * 8, res, srcElem1,
                                    %(src_elem2)s) & 1;
            AA64FpDest_x[2 * p + 0] = res;
            AA64FpDest_x[2 * p + 1] = (Element)0x0 + carryOut;
        }''' % {'op': op,
                'src_top_elem' : '2 * p + 1' if isTop else '2 * p + 0',
                'src_elem2' : 'srcElem2' if isAdd else '~(srcElem2)'}
        iop = ArmInstObjParams(name, 'Sve2' + Name, 'SveTerUnpredOp',
                               {'code': code, 'op_class': opClass}, [])
        header_output += sveTerUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve2' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for ternary SVE instructions with indexed operand
    def sveTerIdxInst(name, Name, opClass, types, op, decoder='Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());

        // Number of elements in a 128 bit segment
        constexpr unsigned ePerSegment = 16 / sizeof(Element);

        ArmISA::VecRegContainer tmpC;
        auto auxDest = tmpC.as<TPElem>();
        for (unsigned i = 0; i < eCount; i++) {
            const auto segmentBase = i - i % ePerSegment;
            const auto segmentIdx = segmentBase + index;

            const Element& srcElem1 = AA64FpOp1_x[i];
            const Element& srcElem2 = AA64FpOp2_x[segmentIdx];
            Element destElem = AA64FpDestMerge_x[i];
        '''
        code += '''
            %(op)s
            auxDest[i] = destElem;
        }

        for (unsigned i = 0; i < eCount; i++) {
            AA64FpDest_x[i] = auxDest[i];
        }''' % {'op': op}

        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveBinIdxUnpredOp',
                               {'code': code, 'op_class': opClass}, [])
        header_output += SveBinIdxUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for ternary SVE intructions with immediate operand
    # (always unpredicated)
    def sveTerImmInst(name, Name, opClass, types, op, decoder='Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        for (unsigned i = 0; i < eCount; i++) {
            const Element& srcElem2 = AA64FpOp2_x[i];
            Element srcElem3 = imm;
            Element destElem = AA64FpDestMerge_x[i];
            %(op)s
            AA64FpDest_x[i] = destElem;
        }''' % {'op': op}
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveTerImmUnpredOp',
                               {'code': code, 'op_class': opClass}, [])
        header_output += SveTerImmUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for DOT instructions
    def sveTerLongInst(name, Name, opClass, types, op,
                        isIndexed = False, uptTop = False,
                        interleaving = False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        typedef typename bigger_type_t<Element>::type BigElement;
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());'''
        if isIndexed:
            code += '''
        unsigned eltspersegment = 16 / (2 * sizeof(Element));'''
        code += '''
        union RegElem
        {
            Element elements[2];
            BigElement bigElements[1];
        };
        RegElem regElem;

        for (int i = 0; i < eCount / 2; ++i) {'''
        if isIndexed:
            code += '''
            int segbase = i - (i % eltspersegment);
            int s = 2 * segbase + index;'''
        code += '''
            regElem.elements[0] = AA64FpDestMerge_x[2 * i + 0];
            regElem.elements[1] = AA64FpDestMerge_x[2 * i + 1];
            BigElement destElem = regElem.bigElements[0];
            Element srcElem1 = (AA64FpOp1_x[2 * i + %(offset)s]);''' % {
                                        'offset': 1 if uptTop else 0}
        if isIndexed:
            code += '''
            Element srcElem2 = AA64FpOp2_x[s];'''
        else:
            code += '''
            Element srcElem2 = (AA64FpOp2_x[2 * i + %(offset)s]);''' % {
                                'offset': 1 if uptTop or interleaving else 0}
        code += '''
            %(op)s
            regElem.bigElements[0] = destElem;
            AA64FpDest_x[2 * i + 0] = regElem.elements[0];
            AA64FpDest_x[2 * i + 1] = regElem.elements[1];
        }''' % {'op': op}
        iop = ArmInstObjParams(name, 'Sve' + Name,
                'SveTerIdxUnpredOp' if isIndexed else 'SveTerUnpredOp',
                {'code': code, 'op_class': opClass}, [])
        if isIndexed:
            header_output += SveTerIdxUnpredOpDeclare.subst(iop)
        else:
            header_output += sveTerUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs': type,
                         'class_name': 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for ternary destructive SVE Matrix
    # Multiplication instructions (not predicated)
    #
    # `type_specs` can either be a sequence of types for cases where
    # the dest and source matrices have the same element types, or a
    # sequence of 3-tuples for case where the dest and source matrices
    # have differnet element types.
    #
    # The calculation Z = Z + A x B is performed for full matrices
    # Z (numDestRows x numDestCols), A (numDestRows x K), and
    # B(K x numDestCols), and remaining elemnts of Z are set to zero.
    # The vector length must be large enough for one full matrix or
    # an UndefinedInstruction Fault is generated.
    #
    def sveMatMulInst(name, Name, opClass, type_specs,
                      numDestRows, numDestCols, K,
                      elt_mul_op):
        global header_output, exec_output
        code = sveEnabledCheckCode + '''
        // Types of the extended versions of the source elements.
        // Required to make sure the itermediate calculations don't overflow.
        using ExtendedElementA = typename vector_element_traits::
                                   extend_element<DestElement,
                                                  SrcElementA>::type;
        using ExtendedElementB = typename vector_element_traits::
                                   extend_element<DestElement,
                                                  SrcElementB>::type;

        // Element count of destination vector
        unsigned eCount = ArmStaticInst::getCurSveVecLen<DestElement>(
                xc->tcBase());

        // SVE Matrix operations require that there are at least 4
        // elements (one full matrix). Further matrices may be partial,
        // in which case the trailing dest elements are filled with zeros.
        if (eCount < 4) {
            return std::make_shared<UndefinedInstruction>(machInst, false,
                                                          "%(mnemonic)s");
        }

        // Some properties of the source and dest matrix dimensions
        //   ( numDestRows x numDestCols ) <- (numDestRows x K) .
        //                                        (K x numDestCols)
        constexpr unsigned numDestRows = %(numDestRows)d;
        constexpr unsigned numDestCols = %(numDestCols)d;
        constexpr unsigned K = %(K)d;

        constexpr unsigned eltsPerDestMatrix = numDestRows * numDestCols;
        constexpr unsigned eltsPerSrcAMatrix = numDestRows * K;
        constexpr unsigned eltsPerSrcBMatrix = K * numDestCols;

        // Number of full matrices - there may be some elements left over
        const unsigned mCount = eCount / eltsPerDestMatrix;

        // Calculate z_ij = Sum[k=1..K](a_ik * b_kj)

        unsigned zEltIdx = 0; // Index of the result element being produced
        unsigned aMatIdx = 0; // Index of the first element of the A matrix
        unsigned bMatIdx = 0; // Index of the first element of the B matrix
        for (unsigned matIdx = 0; matIdx < mCount; ++matIdx) {
            for (unsigned rowIdx = 0; rowIdx < numDestRows; ++rowIdx) {
                for (unsigned colIdx = 0; colIdx < numDestCols; ++colIdx) {
                    DestElement destElem =
                        static_cast<DestElement>(AA64FpDestMerge_x[zEltIdx]);
                    [[maybe_unused]] DestElement prodSum = 0;
                    for (unsigned k = 0; k < K; ++k) {
                        const ExtendedElementA srcElemA =
                            static_cast<ExtendedElementA>
                                                (AA64FpOp1_srcA[aMatIdx + K * rowIdx + k]);
                        const ExtendedElementB srcElemB =
                            static_cast<ExtendedElementB>
                                                (AA64FpOp2_srcB[bMatIdx + K * colIdx + k]);

                        // Do the math operation. Should be of form:
                        //   destElem += f(destElem, srcElemA, srcElemB);
                        %(elt_mul_op)s;
                    }
                    AA64FpDest_x[zEltIdx++] = destElem;
                }
            }
            aMatIdx += eltsPerSrcAMatrix;
            bMatIdx += eltsPerSrcBMatrix;
        }

        // Zero-fill any trailing elements
        for (unsigned i = mCount * eltsPerDestMatrix; i < eCount; ++i) {
            AA64FpDest_x[i] = static_cast<DestElement>(0);
        }
        ''' % {'elt_mul_op': elt_mul_op, 'mnemonic': name,
               'numDestRows': numDestRows, 'numDestCols': numDestCols,
               'K': K}
        iop = InstObjParams(name, 'Sve' + Name, 'SveTerUnpredOp',
                            {'code': code, 'op_class': opClass}, [])
        header_output += SveMatMulOpDeclare.subst(iop)
        exec_output += SveMatMulOpExecute.subst(iop)
        for type_spec in type_specs:
            try:
                destEltType, srcEltAType, srcEltBType = type_spec
            except ValueError:
                destEltType, srcEltAType, srcEltBType = (type_spec,) * 3
            substDict = {'destEltType': destEltType,
                         'srcEltAType': srcEltAType,
                         'srcEltBType': srcEltBType,
                         'class_name': 'Sve' + Name}
            exec_output += SveMatMulOpExecDeclare.subst(substDict)

    # Generates definitions for PTRUE and PTRUES instructions.
    def svePtrueInst(name, Name, opClass, types, isFlagSetting=False,
                     decoder='Generic', isPng=False):
        global header_output, exec_output, decoders
        extraPrologCode = '''
        auto& destPred = PDest;'''
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());'''
        if isPng:
            code += '''
        uint16_t png = sveEncodePredCount(
            sizeof(Element), eCount, eCount, false);
        destPred.reset();
        for (unsigned i = 0; i < 16; i ++) {
            PDest_ub[i] = (png >> i) & 0x1;
        }
        '''
        else:
            code += '''
        unsigned predCount = sveDecodePredCount(imm, eCount);
        destPred.reset();
        for (unsigned i = 0; i < eCount; i++) {
            PDest_x[i] = (i < predCount);
        }'''
        if isFlagSetting:
            code += '''
        CondCodesNZ = (destPred.firstActive(destPred, eCount) << 1) |
                      destPred.noneActive(destPred, eCount);
        CondCodesC = !destPred.lastActive(destPred, eCount);
        CondCodesV = 0;'''
        iop = ArmInstObjParams(name, 'Sve' + Name,
                               'SvePtruePngOp' if isPng else 'SvePtrueOp',
                               {'code': code, 'op_class': opClass}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SvePtrueOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definitions for integer CMP<cc> instructions
    def sveIntCmpInst(name, Name, opClass, types, op, wideop = False,
            decoder = 'Generic'):
        global header_output, exec_output, decoders
        signed = 'int8_t' in types
        srcType = 'Element'
        op2Suffix = 'x'
        if wideop:
            srcType = 'int64_t' if signed else 'uint64_t'
            op2Suffix = 'sd' if signed else 'ud'
        extraPrologCode = '''
        auto& destPred = PDest;'''
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        ArmISA::VecPredRegContainer tmpPredC;
        auto tmpPred = tmpPredC.as<Element>();
        for (unsigned i = 0; i < eCount; ++i)
            tmpPred[i] = GpOp_x[i];
        destPred.reset();
        for (unsigned i = 0; i < eCount; ++i) {
            %(srcType)s srcElem1 = (%(srcType)s) AA64FpOp1_x[i];
            %(srcType)s srcElem2 = AA64FpOp2_%(op2Suffix)s[%(op2Index)s];
            bool destElem = false;
            if (tmpPred[i]) {
                %(op)s
            }
            PDest_x[i] = destElem;
        }
        CondCodesNZ = (destPred.firstActive(tmpPred, eCount) << 1) |
                      destPred.noneActive(tmpPred, eCount);
        CondCodesC = !destPred.lastActive(tmpPred, eCount);
        CondCodesV = 0;''' % {
                'op': op,
                'srcType': srcType,
                'op2Suffix': op2Suffix,
                'op2Index': '(i * sizeof(Element)) / 8' if wideop else 'i'
                }
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveIntCmpOp',
                               {
                                'code': code,
                                'op_class': opClass,
                                'op2IsWide': 'true' if wideop else 'false',
                                }, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SveIntCmpOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definitions for integer CMP<cc> instructions (with immediate)
    def sveIntCmpImmInst(name, Name, opClass, types, op, decoder = 'Generic'):
        global header_output, exec_output, decoders
        extraPrologCode = '''
        auto& destPred = PDest;'''
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        ArmISA::VecPredRegContainer tmpPredC;
        auto tmpPred = tmpPredC.as<Element>();
        for (unsigned i = 0; i < eCount; ++i)
            tmpPred[i] = GpOp_x[i];
        destPred.reset();
        for (unsigned i = 0; i < eCount; ++i) {
            Element srcElem1 = AA64FpOp1_x[i];
            Element srcElem2 = static_cast<Element>(imm);
            bool destElem = false;
            if (tmpPred[i]) {
                %(op)s
            }
            PDest_x[i] = destElem;
        }
        CondCodesNZ = (destPred.firstActive(tmpPred, eCount) << 1) |
                      destPred.noneActive(tmpPred, eCount);
        CondCodesC = !destPred.lastActive(tmpPred, eCount);
        CondCodesV = 0;'''%{'op': op}
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveIntCmpImmOp',
                               {'code': code, 'op_class': opClass,}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SveIntCmpImmOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definitions for SVE element count instructions
    def sveElemCountInst(name, Name, opClass, types, op,
            destType = DestType.Scalar, dstIs32b = False,
            dstAcc = True, decoder = 'Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        unsigned count = sveDecodePredCount(pattern, eCount);
        '''
        if destType == DestType.Vector:
            code += '''
        for (unsigned i = 0; i < eCount; ++i) {
            Element srcElem1 = AA64FpDestMerge_x[i];
            Element destElem = 0;
            %(op)s
            AA64FpDest_x[i] = destElem;
        }'''%{'op': op}
        else:
            if 'uint16_t' in types:
                if dstIs32b:
                    dstType = 'uint32_t'
                else:
                    dstType = 'uint64_t'
            else:
                if dstIs32b:
                    dstType = 'int32_t'
                else:
                    dstType = 'int64_t'
            if dstAcc:
                code += '''
        %(dstType)s srcElem1 = XDest;
                '''%{'dstType': dstType}
            code += '''
        %(dstType)s destElem = 0;
        %(op)s;
        XDest = destElem;
        '''%{'op': op, 'dstType': dstType}
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveElemCountOp',
                {'code': code, 'op_class': opClass, 'dstIsVec': destType,
                 'dstIs32b': 'true' if dstIs32b else 'false'}, [])
        header_output += SveElemCountOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                    'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict);

    def svePartBrkInst(name, Name, opClass, isFlagSetting, predType, whenBrk,
            decoder = 'Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<uint8_t>(
                xc->tcBase());
        bool dobreak = false;
        ArmISA::VecPredRegContainer tmpPredC;
        auto auxGpOp = tmpPredC.as<uint8_t>();
        for (unsigned i = 0; i < eCount; ++i) {
            auxGpOp[i] = GpOp_ub[i];
        }
        for (unsigned i = 0; i < eCount; ++i) {
            bool element = POp1_ub[i] == 1;
            if (auxGpOp[i]) {'''
        breakCode = '''
                dobreak = dobreak || element;'''
        if whenBrk == Break.Before:
            code += breakCode
        code += '''
                PDest_ub[i] = !dobreak;'''
        if whenBrk == Break.After:
            code += breakCode
        code += '''
            }'''
        if predType == PredType.ZERO:
            code += ''' else {
                PDest_ub[i] = 0;
            }'''
        elif predType == PredType.MERGE:
            code += ''' else {
                PDest_ub[i] = PDestMerge_ub[i];
            }'''
        code += '''
        }'''
        extraPrologCode = ''
        if isFlagSetting:
            code += '''
        CondCodesNZ = (destPred.firstActive(auxGpOp, eCount) << 1) |
                      destPred.noneActive(auxGpOp, eCount);
        CondCodesC = !destPred.lastActive(auxGpOp, eCount);
        CondCodesV = 0;'''
            extraPrologCode += '''
        auto& destPred = PDest;'''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SvePartBrkOp',
                               {'code': code, 'op_class': opClass,
                                'isMerging':
                                    'true' if predType == PredType.MERGE
                                           else 'false'}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SvePartBrkOpDeclare.subst(iop)
        exec_output += SveNonTemplatedOpExecute.subst(iop)

    def svePartBrkPropPrevInst(name, Name, opClass, isFlagSetting, whenBrk,
            decoder = 'Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<uint8_t>(
                xc->tcBase());
        bool last = POp1_ub.lastActive(GpOp_ub, eCount);
        ArmISA::VecPredRegContainer tmpPredC;
        auto auxGpOp = tmpPredC.as<uint8_t>();
        for (unsigned i = 0; i < eCount; ++i) {
            auxGpOp[i] = GpOp_ub[i];
        }
        for (unsigned i = 0; i < eCount; ++i) {
            if (auxGpOp[i]) {'''
        breakCode = '''
                last = last && (POp2_ub[i] == 0);'''
        if whenBrk == Break.Before:
            code += breakCode
        code += '''
                PDest_ub[i] = last;'''
        if whenBrk == Break.After:
            code += breakCode
        code += '''
            } else {
                PDest_ub[i] = 0;
            }
        }'''
        extraPrologCode = ''
        if isFlagSetting:
            code += '''
        CondCodesNZ = (destPred.firstActive(auxGpOp, eCount) << 1) |
                      destPred.noneActive(auxGpOp, eCount);
        CondCodesC = !destPred.lastActive(auxGpOp, eCount);
        CondCodesV = 0;'''
            extraPrologCode += '''
        auto& destPred = PDest;'''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SvePartBrkPropOp',
                               {'code': code, 'op_class': opClass}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SvePartBrkPropOpDeclare.subst(iop)
        exec_output += SveNonTemplatedOpExecute.subst(iop)

    def svePartBrkPropNextInst(name, Name, opClass, isFlagSetting,
            decoder = 'Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<uint8_t>(
                xc->tcBase());
        bool last = POp1_ub.lastActive(GpOp_ub, eCount);
        for (unsigned i = 0; i < eCount; i++) {
            if (!last) {
                PDest_ub[i] = 0;
            } else {
                PDest_ub[i] = PDestMerge_ub[i];
            }
        }'''
        extraPrologCode = ''
        if isFlagSetting:
            code += '''
        VecPredRegT<uint8_t, MaxSveVecLenInBytes, false, false>::Container c;
        VecPredRegT<uint8_t, MaxSveVecLenInBytes, false, false> predOnes(c);
        for (unsigned i = 0; i < eCount; i++) {
            predOnes[i] = 1;
        }
        CondCodesNZ = (destPred.firstActive(predOnes, eCount) << 1) |
                      destPred.noneActive(predOnes, eCount);
        CondCodesC = !destPred.lastActive(predOnes, eCount);
        CondCodesV = 0;'''
            extraPrologCode += '''
        auto& destPred = PDest;'''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SvePartBrkPropOp',
                               {'code': code, 'op_class': opClass}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SvePartBrkPropOpDeclare.subst(iop)
        exec_output += SveNonTemplatedOpExecute.subst(iop)

    # Generate definitions for scalar select instructions
    def sveSelectInst(name, Name, opClass, types, op, isCond,
            destType = DstRegType.Scalar, decoder = 'Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        int last;
        for (last = eCount - 1; last >= 0; --last) {
            if (GpOp_x[last]) {
                break;
            }
        }
        '''
        if isCond:
            code += '''
        if (last >= 0) {'''
        code += '''
            Element destElem;
            %(op)s'''%{'op': op}
        if destType == DstRegType.Vector:
            code += '''
            for (unsigned i = 0; i < eCount; ++i)
                AA64FpDest_x[i] = destElem;'''
        elif destType == DstRegType.Scalar:
            code += '''
            XDest = destElem;'''
        elif destType == DstRegType.SimdFpScalar:
            code += '''
            AA64FpDest_x[0] = destElem;'''
        if isCond:
            code += '''
        }'''
            if destType == DstRegType.Scalar:
                code += ''' else {
            XDest = (Element) XDest;
        }'''
            elif destType == DstRegType.Vector:
                code += ''' else {
            for (unsigned i = 0; i < eCount; ++i)
                AA64FpDest_x[i] = AA64FpDestMerge_x[i];
        }'''
            elif destType == DstRegType.SimdFpScalar:
                code += ''' else {
            AA64FpDest_x[0] = AA64FpDestMerge_x[0];
        }
        '''
        if destType == DstRegType.SimdFpScalar:
            # This section will extend zeros to the simdFP scalar
            # intructions for lasta/b and Clasta/b
            code += '''
                for (int i = 1; i < eCount; ++i) {
                    AA64FpDest_x[i] = (Element)0x0;
                }
                '''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveSelectOp',
                               {'code': code, 'op_class': opClass,
                                'isCond': 'true' if isCond else 'false',
                                'isScalar': 'true'
                                if destType == DstRegType.Scalar else 'false',
                                'isSimdFp': 'true'
                                if destType == DstRegType.SimdFpScalar
                                else 'false'},
                               [])
        header_output += SveSelectOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definitions for PNEXT (find next active predicate)
    # instructions
    def svePNextInst(name, Name, opClass, types, decoder = 'Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        ArmISA::VecPredRegContainer tmpPredC;
        auto auxGpOp = tmpPredC.as<Element>();
        for (unsigned i = 0; i < eCount; ++i) {
            auxGpOp[i] = GpOp_x[i];
        }
        int last;
        for (last = eCount - 1; last >= 0; --last) {
            if (POp1_x[last]) {
                break;
            }
        }
        int next = last + 1;
        while (next < eCount && GpOp_x[next] == 0) {
            next++;
        }
        destPred.reset();
        if (next < eCount) {
            PDest_x[next] = 1;
        }
        CondCodesNZ = (destPred.firstActive(auxGpOp, eCount) << 1) |
                       destPred.noneActive(auxGpOp, eCount);
        CondCodesC = !destPred.lastActive(auxGpOp, eCount);
        CondCodesV = 0;'''
        extraPrologCode = '''
        auto& destPred = PDest;'''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveUnaryPredPredOp',
                {'code': code, 'op_class': opClass}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SveUnaryPredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definitions for PFIRST (set first active predicate)
    # instructions
    def svePFirstInst(name, Name, opClass, decoder = 'Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        ArmISA::VecPredRegContainer tmpPredC;
        auto auxGpOp = tmpPredC.as<Element>();
        for (unsigned i = 0; i < eCount; ++i)
            auxGpOp[i] = GpOp_x[i];
        int first = -1;
        for (int i = 0; i < eCount; ++i) {
            if (auxGpOp[i] && first == -1) {
                first = i;
            }
        }
        for (int i = 0; i < eCount; ++i) {
            PDest_x[i] = PDestMerge_x[i];
        }
        if (first >= 0) {
            PDest_x[first] = 1;
        }
        CondCodesNZ = (destPred.firstActive(auxGpOp, eCount) << 1) |
                       destPred.noneActive(auxGpOp, eCount);
        CondCodesC = !destPred.lastActive(auxGpOp, eCount);
        CondCodesV = 0;'''
        extraPrologCode = '''
        auto& destPred = PDest;'''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveUnaryPredPredOp',
                {'code': code, 'op_class': opClass}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SveUnaryPredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        substDict = {'targs' : 'uint8_t',
                     'class_name' : 'Sve' + Name}
        exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definitions for SVE table lookup instructions with 2 sources
    def sveTblInst(name, Name, opClass, decoder = 'Generic',
                   merging = False, doubleTable = False, isSeg = False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());'''
        if isSeg:
            code += '''
        constexpr unsigned ePerSegment = 16 / sizeof(Element);
        '''
        code += '''
        for (int i = 0; i < eCount; ++i) {'''
        if doubleTable:
            code += '''
            Element idx = AA64FpOp3_x[i];'''
        else:
            code += '''
            Element idx = AA64FpOp2_x[i];'''
        if isSeg:
            code += '''
            auto segmentBase = i - i % ePerSegment;
            Element val;
            if (idx < ePerSegment) {
                val = AA64FpOp1_x[segmentBase + idx];'''
        else:
            code += '''
            Element val;
            if (idx < eCount) {
                val = AA64FpOp1_x[idx];'''
        if doubleTable:
            code += '''
            } else if (idx < eCount * 2) {
                val = AA64FpOp2_x[idx - eCount];'''
        code += '''
            } else {
                val = %(dest_elem)s;;
            }
            AA64FpDest_x[i] = val;
        }''' % {'dest_elem': 'AA64FpDestMerge_x[i]' if merging else '0'}
        iop = ArmInstObjParams(name, 'Sve' + Name,
                'SveTblThreeSrcOp' if doubleTable else 'SveTblOp',
                {'code': code, 'op_class': opClass}, [])
        if doubleTable:
            header_output += SveBinUnpred3SrcOpDeclare.subst(iop)
        else:
            header_output += SveBinUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in unsignedTypes:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definitions for integer add/subtract long with carry
    def sveLongCarryInst(name, Name, opClass, decoder = 'Generic',
            uptTop = False, subtract = False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        for (int i = 0; i < eCount/2; ++i) {
            const Element& srcElem1 = AA64FpOp1_x[2*i+%(offset)s];
            const Element& srcElem2 = AA64FpOp2_x[2*i+1];
            const Element& srcElem3 = AA64FpDestMerge_x[2*i];
            __uint128_t unsigned_sum = (__uint128_t)srcElem3 +
                                       (%(op)ssrcElem1) +
                                       (srcElem2 & 0x1);
            AA64FpDest_x[2*i] = (Element)unsigned_sum;
            AA64FpDest_x[2*i+1] = (Element)unsigned_sum !=
                                  (__uint128_t)unsigned_sum;
        }
        ''' % {'offset': 1 if uptTop else 0,
               'op': '~' if subtract else '',
              }
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveBinUnpredOp',
                               {'code': code, 'op_class': opClass}, [])
        header_output += SveBinUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in ('uint32_t', 'uint64_t'):
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definitions for SVE Unpack instructions
    def sveUnpackInst(name, Name, opClass, sdtypes, unpackHalf,
                      regType, decoder = 'Generic'):
        global header_output, exec_output, decoders
        extraPrologCode = '''
        auto& destPred = PDest;'''
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<DElement>(
                xc->tcBase());'''
        if unpackHalf == Unpack.Low:
            if regType == SrcRegType.Predicate:
                code += '''
        ArmISA::VecPredRegContainer tmpPredC;
        auto auxPOp1 = tmpPredC.as<SElement>();
        for (int i = 0; i < eCount; ++i) {
            auxPOp1[i] = POp1_xs[i];
        }'''
            else:
                code += '''
        ArmISA::VecRegContainer tmpVecC;
        auto auxOp1 = tmpVecC.as<SElement>();
        for (int i = 0; i < eCount; ++i) {
            auxOp1[i] = AA64FpOp1_xs[i];
        }'''
        code += '''
        for (int i = 0; i < eCount; ++i) {'''
        if regType == SrcRegType.Predicate:
            if unpackHalf == Unpack.High:
                code +='''
            const SElement& srcElem1 = POp1_xs[i + eCount];'''
            else:
                code +='''
            const SElement& srcElem1 = auxPOp1[i];'''
            code += '''
            destPred.setRaw(i, 0);
            PDest_xd[i] = srcElem1;'''
        else:
            if unpackHalf == Unpack.High:
                code +='''
            const SElement& srcElem1 = AA64FpOp1_xs[i + eCount];'''
            else:
                code +='''
            const SElement& srcElem1 = auxOp1[i];'''
            code += '''
            AA64FpDest_xd[i] = static_cast<DElement>(srcElem1);'''
        code += '''
        }
        '''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveUnpackOp',
                {'code': code, 'op_class': opClass}, [])
        if regType == SrcRegType.Predicate:
            iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SveUnpackOpDeclare.subst(iop)
        exec_output += SveWideningOpExecute.subst(iop)
        for srcType, dstType in sdtypes:
            substDict = {'targs': srcType + ', ' + dstType,
                         'class_name': 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for SVE predicate test instructions
    def svePredTestInst(name, Name, opClass, decoder = 'Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<uint8_t>(
                xc->tcBase());
        CondCodesNZ = (POp1_ub.firstActive(GpOp_ub, eCount) << 1) |
                       POp1_ub.noneActive(GpOp_ub, eCount);
        CondCodesC = !POp1_ub.lastActive(GpOp_ub, eCount);
        CondCodesV = 0;'''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SvePredTestOp',
                {'code': code, 'op_class': opClass}, [])
        header_output += SvePredicateTestOpDeclare.subst(iop)
        exec_output += SveNonTemplatedOpExecute.subst(iop)

    # Generate definition for SVE predicate compact operations
    def sveCompactInst(name, Name, opClass, types, decoder = 'Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        ArmISA::VecRegContainer tmpVecC;
        auto auxOp1 = tmpVecC.as<Element>();
        for (unsigned i = 0; i < eCount; ++i) {
            auxOp1[i] = AA64FpOp1_x[i];
        }
        unsigned x = 0;
        for (unsigned i = 0; i < eCount; ++i) {
            AA64FpDest_x[i] = 0;
            if (GpOp_x[i]) {
                AA64FpDest_x[x] = auxOp1[i];
                x++;
            }
        }'''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveUnaryPredOp',
                {'code': code, 'op_class': opClass}, [])
        header_output += SveUnaryPredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs': type, 'class_name': 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for unary SVE predicate instructions with implicit
    # source operand (PFALSE, RDFFR(S))
    def svePredUnaryWImplicitSrcInst(name, Name, opClass, op,
            predType=PredType.NONE, isFlagSetting=False, decoder='Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + op
        if isFlagSetting:
            code += '''
        CondCodesNZ = (destPred.firstActive(GpOp, eCount) << 1) |
                      destPred.noneActive(GpOp, eCount);
        CondCodesC = !destPred.lastActive(GpOp, eCount);
        CondCodesV = 0;'''
        extraPrologCode = '''
        [[maybe_unused]] auto& destPred = PDest;'''
        baseClass = ('SvePredUnaryWImplicitSrcOp' if predType == PredType.NONE
                     else 'SvePredUnaryWImplicitSrcPredOp')
        iop = ArmInstObjParams(name, 'Sve' + Name, baseClass,
                {'code': code, 'op_class': opClass}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        if predType == PredType.NONE:
            header_output += SvePredUnaryOpWImplicitSrcDeclare.subst(iop)
        else:
            header_output += SvePredUnaryPredOpWImplicitSrcDeclare.subst(iop)
        exec_output += SveNonTemplatedOpExecute.subst(iop)

    # Generate definition for SVE instructions writing to the FFR (SETFFR,
    # WRFFR)
    def svePredWriteFfrInst(name, Name, opClass, op, isSetFfr,
            decoder='Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + op
        extraPrologCode = '''
        [[maybe_unused]] auto& destPred = Ffr;'''
        baseClass = ('SveWImplicitSrcDstOp' if isSetFfr
                     else 'SvePredUnaryWImplicitDstOp')
        iop = ArmInstObjParams(name, 'Sve' + Name, baseClass,
                {'code': code, 'op_class': opClass}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        if isSetFfr:
            header_output += SveOpWImplicitSrcDstDeclare.subst(iop)
        else:
            header_output += SvePredUnaryOpWImplicitDstDeclare.subst(iop)
        exec_output += SveNonTemplatedOpExecute.subst(iop)

    # Generate definition for SVE Ext instruction
    def sveExtInst(name, Name, opClass, types, decoder = 'Generic',
                isSeg=False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        ArmISA::VecRegContainer tmpVecC;
        auto auxOp1 = tmpVecC.as<Element>();
        for (unsigned i = 0; i < eCount; ++i) {
            auxOp1[i] = AA64FpOp1_x[i];
        }
        ArmISA::VecRegContainer tmpVecD;
        auto auxOp2 = tmpVecD.as<Element>();
        for (unsigned i = 0; i < eCount; ++i) {
            auxOp2[i] = AA64FpOp2_x[i];
        }
        '''
        if isSeg:
            code += '''
        const unsigned ePerSegment = 16 / sizeof(Element);
        for (int s = 0; s < eCount / ePerSegment; s ++) {
            uint64_t pos = index;
            if (pos >= ePerSegment)
                pos = 0;
            for (int i = 0; i < ePerSegment; ++i, ++pos) {
                if (pos < ePerSegment)
                    AA64FpDest_x[s * ePerSegment + i] =
                        auxOp1[s * ePerSegment + pos];
                else
                    AA64FpDest_x[s * ePerSegment + i] =
                        auxOp2[s * ePerSegment + pos - ePerSegment];
            }
        }
        '''
        else:
            code += '''
        uint64_t pos = index;
        if (pos >= eCount)
            pos = 0;
        for (int i = 0; i < eCount; ++i, ++pos) {
            if (pos < eCount)
                AA64FpDest_x[i] = auxOp1[pos];
            else
                AA64FpDest_x[i] = auxOp2[pos-eCount];
        }
        '''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveBinIdxUnpredOp',
                {'code': code, 'op_class': opClass}, [])
        header_output += SveBinIdxUnpredOpDeclare.subst(iop);
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs': type, 'class_name': 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for SVE Slice instruction
    def sveSpliceInst(name, Name, opClass, types, decoder = 'Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());

        ArmISA::VecRegContainer tmpVecC;
        auto auxDest = tmpVecC.as<Element>();
        ArmISA::VecRegContainer tmpVecD;
        auto auxOp1 = tmpVecD.as<Element>();
        for (unsigned i = 0; i < eCount; ++i) {
            auxOp1[i] = AA64FpOp1_x[i];
        }
        ArmISA::VecRegContainer tmpVecE;
        auto auxOp2 = tmpVecE.as<Element>();
        for (unsigned i = 0; i < eCount; ++i) {
            auxOp2[i] = AA64FpOp2_x[i];
        }

        int firstelem = -1, lastelem = -2;
        for (int i = 0; i < eCount; ++i) {
            if (GpOp_x[i]) {
                lastelem = i;
                if (firstelem < 0)
                    firstelem = i;
            }
        }
        int x = 0;
        for (int i = firstelem; i <= lastelem; ++i, ++x) {
            auxDest[x] = auxOp1[i];
        }
        int remaining = eCount - x;
        for (int i = 0; i < remaining; ++i, ++x) {
            auxDest[x] = auxOp2[i];
        }
        for (int i = 0; i < eCount; ++i) {
            AA64FpDest_x[i] = auxDest[i];
        }
        '''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveBinConstrPredOp',
                {'code': code, 'op_class': opClass}, [])
        header_output += SveBinConstrPredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs': type, 'class_name': 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for SVE DUP (index) instruction
    def sveDupIndexInst(name, Name, opClass, types, decoder = 'Generic',
                        isSeg = False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        '''
        if isSeg:
            code += '''
        const unsigned ePerSegment = 16 / sizeof(Element);
        for (int s = 0; s < eCount / ePerSegment; ++s) {
            Element srcElem1 = 0;
            if (imm < ePerSegment) {
                srcElem1 = AA64FpOp1_x[s * ePerSegment + imm];
            }
            for (int i = 0; i < ePerSegment; ++i) {
                AA64FpDest_x[s * ePerSegment + i] = srcElem1;
            }
        }'''
        else:
            code += '''
        Element srcElem1 = 0;
        if (imm < eCount) {
            srcElem1 = AA64FpOp1_x[imm];
        }
        for (int i = 0; i < eCount; ++i) {
            AA64FpDest_x[i] = srcElem1;
        }'''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveBinImmIdxUnpredOp',
                {'code': code, 'op_class': opClass}, [])
        header_output += SveBinImmUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs': type, 'class_name': 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for SVE reverse elements instructions
    def sveReverseElementsInst(name, Name, opClass, types,
            srcType = SrcRegType.Vector, decoder = 'Generic'):
        assert srcType in (SrcRegType.Vector, SrcRegType.Predicate)
        global header_output, exec_output, decoders
        extraPrologCode = '''
        auto& destPred = PDest;'''
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());'''
        if srcType == SrcRegType.Predicate:
            code += '''
        ArmISA::VecPredRegContainer tmpPredC;
        auto auxPOp1 = tmpPredC.as<Element>();
        for (unsigned i = 0; i < eCount; ++i) {
            uint8_t v = POp1_x.getRaw(i);
            auxPOp1.setRaw(i, v);
        }
        PDest_x[0] = 0;'''
        else:
            code += '''
        ArmISA::VecRegContainer tmpRegC;
        auto auxOp1 = tmpRegC.as<Element>();
        for (unsigned i = 0; i < eCount; ++i) {
            auxOp1[i] = AA64FpOp1_x[i];
        }'''
        code += '''
        for (int i = 0; i < eCount; ++i) {'''
        if srcType == SrcRegType.Vector:
            code += '''
            AA64FpDest_x[i] = auxOp1[eCount - i - 1];'''
        else:
            code += '''
            destPred.setRaw(i, auxPOp1.getRaw(eCount - i - 1));'''
        code += '''
        }'''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveUnaryUnpredOp',
                {'code': code, 'op_class': opClass}, [])
        if srcType == SrcRegType.Predicate:
            iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SveUnaryUnpredOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs': type, 'class_name': 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for shift & insert instructions
    def sveShiftAndInsertInst(name, Name, opClass, types,
            srcType = SrcRegType.Scalar, decoder = 'Generic'):
        assert srcType in (SrcRegType.SimdFpScalar, SrcRegType.Scalar)
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());'''
        if srcType == SrcRegType.Scalar:
            code += '''
            auto& srcElem1 = XOp1;'''
        elif srcType == SrcRegType.SimdFpScalar:
            code += '''
            auto& srcElem1 = AA64FpOp1_x[0];'''
        code += '''
        for (int i = eCount - 1; i > 0; --i) {
            AA64FpDest_x[i] = AA64FpDestMerge_x[i-1];
        }
        AA64FpDest_x[0] = srcElem1;'''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveUnarySca2VecUnpredOp',
                {'code': code, 'op_class': opClass,
                 'isSimdFp': 'true' if srcType == SrcRegType.SimdFpScalar
                                  else 'false'}, [])
        header_output += SveShiftAndInsertOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs': type, 'class_name': 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for DOT instructions
    def sveWideningMulAddInst(name, Name, opClass, types, op,
                              isIndexed = False, uptTop = False,
                              interleaving = False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        // Types of the extended versions of the source elements.
        // Required to make sure the intermediate calculations don't overflow.
        using ExtendedElementA = typename vector_element_traits::
                                   extend_element<DElement,
                                                  SElementA>::type;
        using ExtendedElementB = typename vector_element_traits::
                                   extend_element<DElement,
                                                  SElementB>::type;

        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        for (int i = 0; i < eCount; ++i) {'''
        if isIndexed:
            code += '''
            int segbase = i - i % (16 / sizeof(Element));
            int s = 2 * segbase + imm;'''
        code += '''
            DElement destElem = AA64FpDest_xd[i];
            ExtendedElementA srcElemA = static_cast<ExtendedElementA>
                                (AA64FpOp1_srcA[2 * i + %(offset)s]);''' % {
                                        'offset': 1 if uptTop else 0}
        if isIndexed:
            code += '''
            ExtendedElementB srcElemB = static_cast<ExtendedElementB>
                                    (AA64FpOp2_srcB[s]);'''
        else:
            code += '''
            ExtendedElementB srcElemB = static_cast<ExtendedElementB>
                                (AA64FpOp2_srcB[2 * i + %(offset)s]);''' % {
                                'offset': 1 if uptTop or interleaving else 0}
        code += '''
                %(op)s
            AA64FpDestMerge_xd[i] = destElem;
        }''' % {'op': op}
        iop = ArmInstObjParams(name, 'Sve' + Name,
                'SveDotProdIdxOp' if isIndexed else 'SveDotProdOp',
                {'code': code, 'op_class': opClass}, [])
        if isIndexed:
            header_output += SveWideningTerImmOpDeclare.subst(iop)
        else:
            header_output += SveWideningTerOpDeclare.subst(iop)
        exec_output += SveWideningTerOpExecute.subst(iop)
        for type in types:
            substDict = {'targs': type, 'class_name': 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for BFDOT instructions
    def sveBfDotInst(name, Name, opClass, types, op, isIndexed = False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        // Types of the extended versions of the source elements.
        // Required to make sure the intermediate calculations don't overflow.
        using ExtendedElementA = typename vector_element_traits::
                                   extend_element<DElement,
                                                  SElementA>::type;
        using ExtendedElementB = typename vector_element_traits::
                                   extend_element<DElement,
                                                  SElementB>::type;

        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        for (int i = 0; i < eCount; ++i) {'''
        if isIndexed:
            code += '''
            int segbase = i - i % (16 / sizeof(Element));
            int s = segbase + imm;'''
        code += '''
            DElement destElem = AA64FpDest_xd[i];
            ExtendedElementA srcElemA_0 = static_cast<ExtendedElementA>
                                          (AA64FpOp1_srcA[2 * i + 0]);
            ExtendedElementA srcElemA_1 = static_cast<ExtendedElementA>
                                          (AA64FpOp1_srcA[2 * i + 1]);
            '''
        if isIndexed:
            code += '''
            ExtendedElementB srcElemB_0 = static_cast<ExtendedElementB>
                                          (AA64FpOp2_srcB[2 * s + 0]);
            ExtendedElementB srcElemB_1 = static_cast<ExtendedElementB>
                                          (AA64FpOp2_srcB[2 * s + 1]);'''
        else:
            code += '''
            ExtendedElementB srcElemB_0 = static_cast<ExtendedElementB>
                                          (AA64FpOp2_srcB[2 * i + 0]);
            ExtendedElementB srcElemB_1 = static_cast<ExtendedElementB>
                                          (AA64FpOp2_srcB[2 * i + 1]);'''
        code += '''
                %(op)s
            AA64FpDestMerge_xd[i] = destElem;
        }''' % {'op': op}
        iop = ArmInstObjParams(name, 'Sve' + Name,
                'SveDotProdIdxOp' if isIndexed else 'SveDotProdOp',
                {'code': code, 'op_class': opClass}, [])
        if isIndexed:
            header_output += SveWideningTerImmOpDeclare.subst(iop)
        else:
            header_output += SveWideningTerOpDeclare.subst(iop)
        exec_output += SveWideningTerOpExecute.subst(iop)
        for type in types:
            substDict = {'targs': type, 'class_name': 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for DOT instructions
    def sveDotInst(name, Name, opClass, types, isIndexed=True):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        // Types of the extended versions of the source elements.
        // Required to make sure the intermediate calculations don't overflow.
        using ExtendedElementA = typename vector_element_traits::
                                   extend_element<DElement,
                                                  SElementA>::type;
        using ExtendedElementB = typename vector_element_traits::
                                   extend_element<DElement,
                                                  SElementB>::type;

        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        for (int i = 0; i < eCount; ++i) {'''
        if isIndexed:
            code += '''
            int segbase = i - i % (16 / sizeof(Element));
            int s = segbase + imm;'''
        code += '''
            DElement res = AA64FpDest_xd[i];
            ExtendedElementA srcElemA;
            ExtendedElementB srcElemB;
            for (int j = 0; j <= 3; ++j) {
                srcElemA = static_cast<ExtendedElementA>
                                          (AA64FpOp1_srcA[4 * i + j]);'''
        if isIndexed:
            code += '''
                srcElemB = static_cast<ExtendedElementB>
                                          (AA64FpOp2_srcB[4 * s + j]);'''
        else:
            code += '''
                srcElemB = static_cast<ExtendedElementB>
                                          (AA64FpOp2_srcB[4 * i + j]);'''
        code += '''
                res += srcElemA * srcElemB;
            }
            AA64FpDestMerge_xd[i] = res;
        }'''
        iop = ArmInstObjParams(name, 'Sve' + Name,
                'SveDotProdIdxOp' if isIndexed else
                'SveDotProdOp',
                {'code': code, 'op_class': opClass}, [])
        if isIndexed:
            header_output += SveWideningTerImmOpDeclare.subst(iop)
        else:
            header_output += SveWideningTerOpDeclare.subst(iop)
        exec_output += SveWideningTerOpExecute.subst(iop)
        for type in types:
            substDict = {'targs': type, 'class_name': 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for ordered reduction
    def sveOrderedReduction(name, Name, opClass, types, op,
                            decoder = 'Generic'):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());'''
        code += '''
        Element destElem = AA64FpDestMerge_x[0];
        for (int i = 0; i < eCount; ++i) {
            if (GpOp_x[i]) {
                Element srcElem1 = AA64FpOp1_x[i];
                %(op)s
            }
        }
        for (int i = 1; i < eCount; ++i) {
            AA64FpDest_x[i] = 0;
        }
        AA64FpDest_x[0] = destElem;'''%{'op': op}
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveOrdReducOp',
                {'code': code, 'op_class': opClass}, [])
        header_output += SveReducOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                    'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definitions for complex addition instructions
    def sveComplexAddInst(name, Name, opClass, types,
            decoder = 'Generic', predType=PredType.MERGE,
            isInt = False, isSq = False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());'''
        code += '''
        bool sub_i = (rot == 1);
        bool sub_r = (rot == 3);

        for (int i = 0; i < eCount / 2; ++i) {
            Element acc_r = AA64FpOp1_x[2 * i];
            Element acc_i = AA64FpOp1_x[2 * i + 1];
            Element elt2_r = AA64FpOp2_x[2 * i];
            Element elt2_i = AA64FpOp2_x[2 * i + 1];
        '''
        if not isInt:
            code += '''
            FPSCR fpscr;
            FPCR fpcr = (FPCR)Fpcr;'''
        if predType != PredType.NONE:
            code += '''
            if (GpOp_x[2 * i]) {'''
        if isInt and isSq:
            code += '''
                if (sub_i) {
                    __int128_t res = (__int128_t)acc_r - (__int128_t)elt2_i;
                    acc_r = do_sint_sat<Element>(res, sizeof(Element) * 8);
                } else {
                    __int128_t res = (__int128_t)acc_r + (__int128_t)elt2_i;
                    acc_r = do_sint_sat<Element>(res, sizeof(Element) * 8);
                }'''
        elif isInt and not isSq:
            code += '''
                if (sub_i) {
                    acc_r = acc_r - elt2_i;
                } else {
                    acc_r = acc_r + elt2_i;
                }'''
        else:
            code += '''
                if (sub_i) {
                    elt2_i = fplibNeg<Element>(elt2_i, fpcr);
                }
                fpscr = FpscrExc & ~FpscrAhpMask;
                acc_r = fplibAdd<Element>(acc_r, elt2_i, fpscr, fpcr);
                FpscrExc = fpscr;'''
        if predType != PredType.NONE:
            code += '''
            }
            if (GpOp_x[2 * i + 1]) {'''
        if isInt and isSq:
            code += '''
                if (sub_r) {
                    __int128_t res = (__int128_t)acc_i - (__int128_t)elt2_r;
                    acc_i = do_sint_sat<Element>(res, sizeof(Element) * 8);
                } else {
                    __int128_t res = (__int128_t)acc_i + (__int128_t)elt2_r;
                    acc_i = do_sint_sat<Element>(res, sizeof(Element) * 8);
                }'''
        elif isInt and not isSq:
            code += '''
                if (sub_r) {
                    acc_i = acc_i - elt2_r;
                } else {
                    acc_i = acc_i + elt2_r;
                }'''
        else:
            code += '''
                if (sub_r) {
                    elt2_r = fplibNeg<Element>(elt2_r, fpcr);
                }
                fpscr = FpscrExc & ~FpscrAhpMask;
                acc_i = fplibAdd<Element>(acc_i, elt2_r, fpscr, fpcr);
                FpscrExc = fpscr;'''
        if predType != PredType.NONE:
            code += '''
            }'''

        code += '''

            AA64FpDest_x[2 * i] = acc_r;
            AA64FpDest_x[2 * i + 1] = acc_i;
        }
        '''
        if predType == PredType.NONE:
            baseClass = 'SveComplexUnpredOp'
        else:
            baseClass = 'SveComplexOp'
        iop = ArmInstObjParams(name, 'Sve' + Name, baseClass,
                {'code': code, 'op_class': opClass}, [])
        if predType == PredType.NONE:
            header_output += SveComplexUnpredOpDeclare.subst(iop)
        else:
            header_output += SveComplexOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                    'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definitions for complex addition instructions
    def sveComplexDotInst(name, Name, opClass, types,
            decoder = 'Generic', isIndexed=False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        // Types of the extended versions of the source elements.
        // Required to make sure the intermediate calculations don't overflow.
        using ExtendedElementA = typename vector_element_traits::
                                   extend_element<DElement,
                                                  SElementA>::type;
        using ExtendedElementB = typename vector_element_traits::
                                   extend_element<DElement,
                                                  SElementB>::type;

        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());'''
        code += '''
        unsigned sel_a = rot == 0x1 || rot == 0x3;
        unsigned sel_b = rot == 0x0 || rot == 0x2;
        bool sub_i = rot == 0 || rot == 0x3;
        '''
        if isIndexed:
            code += '''
        uint32_t eltspersegment = 16 / sizeof(Element);'''
        code += '''
        for (int e = 0; e < eCount; ++e) {'''
        if isIndexed:
            code += '''
            int segmentbase = e - (e % eltspersegment);
            int s = segmentbase + imm;'''
        code += '''
            DElement destElem = AA64FpDestMerge_xd[e];
            for (int i = 0; i < 2; ++i) {
                ExtendedElementA elt1_r = static_cast<ExtendedElementA>
                                          (AA64FpOp1_srcA[4 * e + 2 * i + 0]);
                ExtendedElementA elt1_i = static_cast<ExtendedElementA>
                                          (AA64FpOp1_srcA[4 * e + 2 * i + 1]);
        '''
        if isIndexed:
            code += '''
                ExtendedElementB elt2_a = static_cast<ExtendedElementB>
                                    (AA64FpOp2_srcB[4 * s + 2 * i + sel_a]);
                ExtendedElementB elt2_b = static_cast<ExtendedElementB>
                                    (AA64FpOp2_srcB[4 * s + 2 * i + sel_b]);'''
        else:
            code += '''
                ExtendedElementB elt2_a = static_cast<ExtendedElementB>
                                    (AA64FpOp2_srcB[4 * e + 2 * i + sel_a]);
                ExtendedElementB elt2_b = static_cast<ExtendedElementB>
                                    (AA64FpOp2_srcB[4 * e + 2 * i + sel_b]);'''
        code += '''
                if (sub_i) {
                    destElem = (destElem + (elt1_r * elt2_a))
                                         - (elt1_i * elt2_b);
                } else {
                    destElem = destElem + (elt1_r * elt2_a)
                                        + (elt1_i * elt2_b);
                }
            }

            AA64FpDest_xd[e] = destElem;
        }
        '''
        if isIndexed:
            baseClass = 'SveComplexIdxOp'
        else:
            baseClass = 'SveComplexUnpredOp'
        iop = ArmInstObjParams(name, 'Sve' + Name, baseClass,
                {'code': code, 'op_class': opClass}, [])
        if isIndexed:
            header_output += SveComplexDotIndexOpDeclare.subst(iop)
        else:
            header_output += SveComplexDotOpDeclare.subst(iop)
        exec_output += SveWideningTerOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                    'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definitions for complex multiply and accumulate instructions
    def sveComplexMulAddInst(name, Name, opClass, types,
            predType=PredType.NONE, isIndexed=False, decoder='Generic',
            isInt=False, isIntHigh=False):
        assert predType in (PredType.NONE, PredType.MERGE)
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());'''
        code += '''
        uint32_t sel_a = bits(rot, 0);
        uint32_t sel_b = sel_a ? 0 : 1;
        bool neg_i = bits(rot, 1);
        bool neg_r = bits(rot, 0) != bits(rot, 1);'''
        if isIndexed:
            code += '''
        uint32_t eltspersegment = 16 / (2 * sizeof(Element));'''
        code += '''
        ArmISA::VecRegContainer tmpC;
        auto auxDest = tmpC.as<TPElem>();

        for (int i = 0; i < eCount / 2; ++i) {'''
        if isIndexed:
            code += '''
            uint32_t segmentbase = i - (i % eltspersegment);
            uint32_t s = segmentbase + imm;'''
        else:
            code += '''
            uint32_t s = i;'''
        code += '''
            Element addend_r = AA64FpDestMerge_x[2 * i];
            Element addend_i = AA64FpDestMerge_x[2 * i + 1];
            Element elt1_a = AA64FpOp1_x[2 * i + sel_a];
            Element elt2_a = AA64FpOp2_x[2 * s + sel_a];
            Element elt2_b = AA64FpOp2_x[2 * s + sel_b];
            '''
        if isIntHigh:
            code += '''
            unsigned int width = sizeof(Element) * 8;'''
        if not isInt and not isIntHigh:
            code += '''
            FPSCR fpscr;
            FPCR fpcr = (FPCR)Fpcr;
            '''
        if predType != PredType.NONE:
            code += '''
            if (GpOp_x[2 * i]) {'''
        if isIntHigh:
            code += '''
            __int128_t sum_r = 0;
            __int128_t prod_r = (__int128_t)elt1_a * (__int128_t)elt2_a;
            if (neg_r) {
                prod_r = ~prod_r + 1;
            }
            prod_r = prod_r >> (width - 2);
            sum_r = ((__int128_t)addend_r << 1) + prod_r;
            sum_r = (sum_r + 1) >> 1;
            addend_r = do_sint_sat<Element>(sum_r, width);
            '''
        elif isInt:
            code += '''
            if (neg_r) {
                addend_r = addend_r - elt1_a * elt2_a;
            } else {
                addend_r = addend_r + elt1_a * elt2_a;
            }'''
        else:
            code += '''
            if (neg_r) {
                elt2_a = fplibNeg<Element>(elt2_a, fpcr);
            }
            fpscr = FpscrExc & ~FpscrAhpMask;
            addend_r = fplibMulAdd<Element>(addend_r, elt1_a, elt2_a,
                                            fpscr, fpcr);
            FpscrExc = fpscr;'''
        if predType != PredType.NONE:
            code += '''
            }'''
        if predType != PredType.NONE:
            code += '''
            if (GpOp_x[2 * i + 1]) {'''
        if isIntHigh:
            code += '''
            __int128_t sum_i = 0;
            __int128_t prod_i = (__int128_t)elt1_a * (__int128_t)elt2_b;
            if (neg_i) {
                prod_i = ~prod_i + 1;
            }
            prod_i = prod_i >> (width - 2);
            sum_i = ((__int128_t)addend_i << 1) + prod_i;
            sum_i = (sum_i + 1) >> 1;
            addend_i = do_sint_sat<Element>(sum_i, width);
            '''
        elif isInt:
            code += '''
            if (neg_i) {
                addend_i = addend_i - elt1_a * elt2_b;
            } else {
                addend_i = addend_i + elt1_a * elt2_b;
            }'''
        else:
            code += '''
            if (neg_i) {
                elt2_b = fplibNeg<Element>(elt2_b, fpcr);
            }
            fpscr = FpscrExc & ~FpscrAhpMask;
            addend_i = fplibMulAdd<Element>(addend_i, elt1_a, elt2_b,
                                            fpscr, fpcr);
            FpscrExc = fpscr;'''
        if predType != PredType.NONE:
            code += '''
            }'''
        code += '''
            auxDest[2 * i] = addend_r;
            auxDest[2 * i + 1] = addend_i;
        }

        for (unsigned i = 0; i < eCount; i++) {
            AA64FpDest_x[i] = auxDest[i];
        }
        '''
        if isIndexed:
            baseClass = 'SveComplexIdxOp'
        elif predType == PredType.NONE:
            baseClass = 'SveComplexUnpredOp'
        else:
            baseClass = 'SveComplexOp'
        iop = ArmInstObjParams(name, 'Sve' + Name, baseClass,
                {'code': code, 'op_class': opClass}, [])
        if isIndexed:
            header_output += SveComplexIndexOpDeclare.subst(iop)
        elif predType == PredType.NONE:
            header_output += SveComplexUnpredOpDeclare.subst(iop)
        else:
            header_output += SveComplexOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                    'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definitions for clamp to min/max instructions
    def sveClampInst(name, Name, opClass, types,
            decoder = 'Generic', isFp = False, isBf = False):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<TPElem>(
                xc->tcBase());

        for (int i = 0 ; i < eCount ; ++i) {'''
        if isFp:
            code += '''
            FPSCR fpscr = FpscrExc & ~FpscrAhpMask;
            FPCR fpcr = (FPCR)Fpcr;
            AA64FpDest_x[i] = fplibMinNum(fplibMaxNum(
                AA64FpOp1_x[i], AA64FpDestMerge_x[i], fpscr, fpcr),
                AA64FpOp2_x[i], fpscr, fpcr);
            FpscrExc = fpscr;
            '''
        elif isBf:
            code += '''
            FPSCR fpscr = FpscrExc & ~FpscrAhpMask;
            FPCR fpcr = (FPCR)Fpcr;
            AA64FpDest_x[i] = fplibBfMinNum(fplibBfMaxNum(
                AA64FpOp1_x[i], AA64FpDestMerge_x[i], fpscr, fpcr),
                AA64FpOp2_x[i], fpscr, fpcr);
            FpscrExc = fpscr;
            '''
        else:
            code += '''
            TPElem mid = AA64FpDestMerge_x[i] >= AA64FpOp1_x[i] ?
                AA64FpDestMerge_x[i] : AA64FpOp1_x[i];
            AA64FpDest_x[i] = mid <= AA64FpOp2_x[i] ? mid : AA64FpOp2_x[i];
            '''
        code += '''
        }
        '''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SveClampOp',
                {'code': code, 'op_class': opClass}, [])
        header_output += SveClampOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for SVE predicate move instructions (PMOV)
    def svePredMovToPredInst(name, Name, opClass, types):
        global header_output, exec_output, decoders
        extraPrologCode = '''
        auto& destPred = PDest;'''
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());

        destPred.reset();
        for (int i = 0; i < eCount; i ++) {
            int bit_idx = imm * eCount + i;
            const Element& srcElem = AA64FpOp1_ub[bit_idx / 8];
            bool cond = (srcElem >> (bit_idx % 8)) & 0x1;
            PDest_x[i] = cond;
        }
        '''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SvePredMovePredOp',
                {'code': code, 'op_class': opClass}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        header_output += SvePredMovOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generate definition for SVE predicate move instructions (PMOV)
    def svePredMovToVectorInst(name, Name, opClass, types):
        global header_output, exec_output, decoders
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());

        ArmISA::VecRegContainer tmpVecC;
        auto auxDest = tmpVecC.as<uint8_t>();
        for (int i = 0; i < eCount * sizeof(Element); i ++) {
            auxDest[i] = (imm == 0) ? 0 : AA64FpDestMerge_ub[i];
        }

        for (int i = 0; i < eCount; i ++) {
            int bit_idx = imm * eCount + i;
            bool cond = POp1_x[i] > 0;
            if (cond) {
                auxDest[bit_idx / 8] = auxDest[bit_idx / 8] |
                    ((uint8_t)1 << (bit_idx % 8));
            } else {
                auxDest[bit_idx / 8] = auxDest[bit_idx / 8] &
                    ~((uint8_t)1 << (bit_idx % 8));
            }
        }

        for (int i = 0; i < eCount * sizeof(Element); i ++) {
            AA64FpDest_ub[i] = auxDest[i];
        }
        '''
        iop = ArmInstObjParams(name, 'Sve' + Name, 'SvePredMoveVecOp',
                {'code': code, 'op_class': opClass}, [])
        header_output += SvePredMovOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    # Generates definitions for PTRUE and PTRUES instructions.
    def svePextInst(name, Name, opClass, types, decoder='Generic',
                    isPair=False):
        global header_output, exec_output, decoders
        extraPrologCode = '''
        auto& destPred = PDest;'''
        if isPair:
            extraPrologCode += '''
        auto& destPred2 = PDest2;'''
        code = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<Element>(
                xc->tcBase());
        unsigned pred_width = sizeof(Element) * eCount;

        uint16_t png = 0;
        for (unsigned b = 0; b < 16; b ++) {
            png = png | ((uint16_t)POp1_ub[b] << b);
        }

        destPred.reset();'''
        if isPair:
            code += '''
        destPred2.reset();
        ArmISA::VecPredRegContainer tmpPredC;
        sveCounterToPredicate(tmpPredC, png, pred_width, 4, imm * 2);
        auto auxDest = tmpPredC.as<Element>();
        for (unsigned i = 0; i < eCount; i ++) {
            PDest_x[i] = auxDest[i];
        }
        ArmISA::VecPredRegContainer tmpPredD;
        sveCounterToPredicate(tmpPredD, png, pred_width, 4, imm * 2 + 1);
        auto auxDest2 = tmpPredD.as<Element>();
        for (unsigned i = 0; i < eCount; i ++) {
            PDest2_x[i] = auxDest2[i];
        }'''
        else:
            code += '''
        ArmISA::VecPredRegContainer tmpPredC;
        sveCounterToPredicate(tmpPredC, png, pred_width, 4, imm);
        auto auxDest = tmpPredC.as<Element>();
        for (unsigned i = 0; i < eCount; i ++) {
            PDest_x[i] = auxDest[i];
        }'''
        iop = ArmInstObjParams(name, 'Sve' + Name,
                               'SvePextPairOp' if isPair else 'SvePextOp',
                               {'code': code, 'op_class': opClass}, [])
        iop.snippets['code'] = extraPrologCode + iop.snippets['code']
        if isPair:
            header_output += SvePextPairOpDeclare.subst(iop)
        else:
            header_output += SvePextOpDeclare.subst(iop)
        exec_output += SveOpExecute.subst(iop)
        for type in types:
            substDict = {'targs' : type,
                         'class_name' : 'Sve' + Name}
            exec_output += SveOpExecDeclare.subst(substDict)

    fpTypes = ('uint16_t', 'uint32_t', 'uint64_t')
    signedTypes = ('int8_t', 'int16_t', 'int32_t', 'int64_t')
    unsignedTypes = ('uint8_t', 'uint16_t', 'uint32_t', 'uint64_t')
    extendedUnsignedTypes = ('uint8_t', 'uint16_t', 'uint32_t', 'uint64_t',
                             '__uint128_t')

    smallSignedTypes = ('int8_t', 'int16_t', 'int32_t')
    bigSignedTypes = ('int16_t', 'int32_t', 'int64_t')
    smallUnsignedTypes = ('uint8_t', 'uint16_t', 'uint32_t')
    bigUnsignedTypes = ('uint16_t', 'uint32_t', 'uint64_t')

    unsignedWideSDTypes = (('uint8_t', 'uint16_t'),
            ('uint16_t', 'uint32_t'), ('uint32_t', 'uint64_t'))
    signedWideSDTypes = (('int8_t', 'int16_t'),
            ('int16_t', 'int32_t'), ('int32_t', 'int64_t'))


    # ABS
    absCode = 'destElem = (Element) std::abs(srcElem1);'
    sveUnaryInst('abs', 'Abs', 'SimdAluOp', signedTypes, absCode,
                 PredType.MERGE)
    # ADCLB
    sveLongCarryInst('adclb', 'Adclb', 'SimdAluOp')
    # ADCLT
    sveLongCarryInst('adclt', 'Adclt', 'SimdAluOp', uptTop = True)
    # ADD (immediate)
    addCode = 'destElem = srcElem1 + srcElem2;'
    sveWideImmInst('add', 'AddImm', 'SimdAddOp', unsignedTypes, addCode, False)
    # ADD (vectors, predicated)
    sveBinInst('add', 'AddPred', 'SimdAddOp', unsignedTypes, addCode,
               PredType.MERGE, True)
    # ADD (vectors, unpredicated)
    sveBinInst('add', 'AddUnpred', 'SimdAddOp', unsignedTypes, addCode)
    # ADDHNB
    addhnCode = '''
            destElem = ((BigElement)srcElem1 + (BigElement)srcElem2) >>
                        (sizeof(Element) * 8);
    '''
    sveBinNarrowInst('addhnb', 'Addhnb', 'SimdAddOp',
                     smallUnsignedTypes, addhnCode)
    # ADDHNT
    sveBinNarrowInst('addhnt', 'Addhnt', 'SimdAddOp',
                     smallUnsignedTypes, addhnCode, uptTop = True)
    # ADDP
    sveBinPairInst('addp', 'Addp', 'SimdAddOp', unsignedTypes, addCode)
    # ADDPL
    addvlCode = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<uint%d_t>(
                xc->tcBase());
        XDest = XOp1 + eCount * (int64_t) imm;
    '''
    buildXImmDataInst('addpl', addvlCode % 64, buildCc=False)
    # ADDQV
    addvCode = 'destElem += srcElem1;'
    sveAssocReducInst('addqv', 'Addqv', 'SimdReduceAddOp', unsignedTypes,
                      addvCode, '0', isHvla = True)
    # ADDVL
    buildXImmDataInst('addvl', addvlCode % 8, buildCc=False)
    # ADR
    adrCode = '''
            if (offsetFormat == SveAdrOffsetUnpackedSigned) {
                srcElem2 = sext<32>(srcElem2 & mask(32));
            } else if (offsetFormat == SveAdrOffsetUnpackedUnsigned) {
                srcElem2 = srcElem2 & mask(32);
            }
            destElem = srcElem1 + srcElem2 * mult;
    '''
    sveAdrInst('adr', 'Adr', 'SimdAddOp', ('uint32_t', 'uint64_t'), adrCode)
    # AND (immediate)
    andCode = 'destElem = srcElem1 & srcElem2;'
    sveWideImmInst('and', 'AndImm', 'SimdAluOp', ('uint64_t',), andCode)
    # AND (predicates)
    svePredLogicalInst('and', 'PredAnd', 'SimdPredAluOp', ('uint8_t',),
                       andCode)
    # AND (vectors, predicated)
    sveBinInst('and', 'AndPred', 'SimdAluOp', unsignedTypes, andCode,
               PredType.MERGE, True)
    # AND (vectors, unpredicated)
    sveBinInst('and', 'AndUnpred', 'SimdAluOp', ('uint64_t',), andCode)
    # ANDQV
    andvCode = 'destElem &= srcElem1;'
    sveAssocReducInst('andqv', 'Andqv', 'SimdReduceAluOp', unsignedTypes,
                      andvCode, 'std::numeric_limits<Element>::max()',
                      isHvla=True)
    # ANDS
    svePredLogicalInst('ands', 'PredAnds', 'SimdPredAluOp', ('uint8_t',),
                       andCode, isFlagSetting=True)
    # ANDV
    sveAssocReducInst('andv', 'Andv', 'SimdReduceAluOp', unsignedTypes,
                      andvCode, 'std::numeric_limits<Element>::max()')
    # ASR (immediate, predicated)
    asrCode = '''
            int sign_bit = bits(srcElem1, sizeof(Element) * 8 - 1);
            if (srcElem2 == 0) {
                destElem = srcElem1;
            } else if (srcElem2 >= sizeof(Element) * 8) {
                destElem = sign_bit ? -1 : 0;
            } else {
                Element shift_res = srcElem1 >> srcElem2;
                if (sign_bit) {
                    shift_res |= ~mask(sizeof(Element) * 8 - srcElem2);
                }
                destElem = shift_res;
            }
    '''
    sveBinImmInst('asr', 'AsrImmPred', 'SimdShiftOp', unsignedTypes, asrCode,
                  PredType.MERGE)
    # ASR (immediate, unpredicated)
    sveBinImmInst('asr', 'AsrImmUnpred', 'SimdShiftOp', unsignedTypes, asrCode)
    # ASR (vectors)
    sveBinInst('asr', 'AsrPred', 'SimdShiftOp', unsignedTypes, asrCode,
               PredType.MERGE, True)
    # ASR (wide elements, predicated)
    sveBinWideElemInst('asr', 'AsrWidePred', 'SimdShiftOp', unsignedTypes,
                        asrCode, PredType.MERGE)
    # ASR (wide elements, unpredicated)
    sveBinWideElemInst('asr', 'AsrWideUnpred', 'SimdShiftOp', unsignedTypes,
                        asrCode)
    # ASRD
    asrdCode = '''
        Element element1 = srcElem1;
        Element shift = srcElem2;
        if (srcElem1 < 0) {
            Element tmp = ((1L << shift) - 1L);
            if (tmp == -1L) {
                element1 = 0;
            } else {
                element1 = element1 + tmp;
            }
        }

        if (shift >= sizeof(Element) * 8) {
            destElem = 0;
        } else {
            destElem = element1 >> shift;
        }
    '''
    sveBinImmInst('asrd', 'Asrd', 'SimdShiftOp', signedTypes, asrdCode,
                  PredType.MERGE)
    # ASRR
    asrrCode = '''
            int sign_bit = bits(srcElem2, sizeof(Element) * 8 - 1);
            if (srcElem1 == 0) {
                destElem = srcElem2;
            } else if (srcElem1 >= sizeof(Element) * 8) {
                destElem = sign_bit ? -1 : 0;
            } else {
                Element shift_res = srcElem2 >> srcElem1;
                if (sign_bit) {
                    shift_res |= ~mask(sizeof(Element) * 8 - srcElem1);
                }
                destElem = shift_res;
            }
    '''
    sveBinInst('asrr', 'Asrr', 'SimdShiftOp', unsignedTypes, asrrCode,
               PredType.MERGE, True)
    # BCAX
    bcaxCode = 'destElem ^= srcElem1 & (~srcElem2);'
    sveBinInst('bcax', 'Bcax', 'SimdShiftOp', ('uint64_t',), bcaxCode,
                isDestructive=True)
    # BDEP
    bdepCode = '''
            int k = 0;
            int len = sizeof(Element) * 8;
            for(int j = 0; j < len; j++) {
                if(((srcElem2>>j) & (Element)0x1) == ((Element)0x1)){
                    destElem |= (((srcElem1>>k) & (Element)0x1) << j);
                    k++;
                }
            }
    '''
    sveBinInst('bdep', 'Bdep', 'SimdAluOp', unsignedTypes, bdepCode)
    # BEXT
    bextCode = '''
            int k = 0;
            int len = sizeof(Element) * 8;
            for(int j = 0; j < len; j++) {
                if(((srcElem2>>j) & (Element)0x1) == ((Element)0x1)){
                    destElem |= (((srcElem1>>j) & (Element)0x1) << k);
                    k++;
                }
            }
    '''
    sveBinInst('bext', 'Bext', 'SimdAluOp', unsignedTypes, bextCode)
    # BFADD (predicated)
    bfOp = '''
            FPSCR fpscr = FpscrExc & ~FpscrAhpMask;
            [[maybe_unused]] FPCR fpcr = (FPCR)Fpcr;
            destElem = %s;
            FpscrExc = fpscr;
    '''
    bfBinOp = bfOp % 'fplibBf%s(srcElem1, srcElem2, fpscr, fpcr)'
    bfaddCode = bfBinOp % 'Add'
    sveBinInst('bfadd', 'BfaddPred', 'SimdBf16AddOp', ('uint16_t',),
               bfaddCode, PredType.MERGE, True)
    # BFADD (unpredicated)
    sveBinInst('bfadd', 'BfaddUnpred', 'SimdBf16AddOp', ('uint16_t',),
               bfaddCode)
    # BFCLAMP
    sveClampInst('bfclamp', 'Bfclamp', 'SimdBf16CmpOp', ('uint16_t',),
                 isBf = True)
    # BFCVT
    bfcvtCode = bfOp % ('fplibConvertBF'
                        '(srcElem1, FPCRRounding(fpscr), fpscr, fpcr)')
    sveCvtInst('bfcvt', 'BFcvtNarrow', 'SimdBf16CvtOp', ['uint32_t, uint16_t'],
               bfcvtCode, CvtDir.Narrow)
    # BFCVTNT
    sveCvtInst('bfcvtnt', 'BFcvtNarrowTop', 'SimdBf16CvtOp',
               ['uint32_t, uint16_t'], bfcvtCode, CvtDir.Narrow, uptTop = True)
    # BFDOT (indexed)
    bfdotCode = '''
            FPSCR fpscr = FpscrExc & ~FpscrAhpMask;
            FPCR fpcr = (FPCR)Fpcr;
            destElem = fplibBfdotAdd(destElem, srcElemA_0, srcElemA_1,
                        srcElemB_0, srcElemB_1, fpscr, fpcr);
    '''
    sveBfDotInst('bfdot', 'BFdotIdx', 'SimdBf16DotProdOp',
                 ['uint16_t, uint16_t, uint32_t'], bfdotCode, isIndexed=True)
    # BFDOT (vector)
    sveBfDotInst('bfdot', 'BFdot', 'SimdBf16DotProdOp',
                 ['uint16_t, uint16_t, uint32_t'], bfdotCode)
    # BFMAX
    bfmaxCode = bfBinOp % 'Max'
    sveBinInst('bfmax', 'Bfmax', 'SimdBf16CmpOp', ('uint16_t',),
               bfmaxCode, PredType.MERGE, True)
    # BFMAXNM
    bfmaxnmCode = bfBinOp % 'MaxNum'
    sveBinInst('bfmaxnm', 'Bfmaxnm', 'SimdBf16CmpOp', ('uint16_t',),
               bfmaxnmCode, PredType.MERGE, True)
    # BFMIN
    bfminCode = bfBinOp % 'Min'
    sveBinInst('bfmin', 'Bfmin', 'SimdBf16CmpOp', ('uint16_t',),
               bfminCode, PredType.MERGE, True)
    # BFMINNM
    bfminnmCode = bfBinOp % 'MinNum'
    sveBinInst('bfminnm', 'Bfminnm', 'SimdBf16CmpOp', ('uint16_t',),
               bfminnmCode, PredType.MERGE, True)
    # BFMLA (indexed)
    bfmlaCode = bfOp % ('fplibBfMulAdd('
                       'destElem, srcElem1, srcElem2, fpscr, fpcr)')
    sveTerIdxInst('bfmla', 'BfmlaIdx', 'SimdBf16MultAccOp', ('uint16_t',),
                  bfmlaCode, PredType.MERGE)
    # BFMLA (vector)
    sveTerInst('bfmla', 'Bfmla', 'SimdBf16MultAccOp', ('uint16_t',),
               bfmlaCode, PredType.MERGE)
    # BFMLALB (indexed)
    bfmlaCode = bfOp % ('fplibBfMulAddH(destElem, srcElemA, srcElemB, '
                        'fpscr, fpcr)')
    sveWideningMulAddInst('bfmlalb', 'BFmlalbIdx', 'SimdBf16MultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], bfmlaCode,
                          isIndexed=True)
    # BFMLALB (vector)
    sveWideningMulAddInst('bfmlalb', 'BFmlalb', 'SimdBf16MultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], bfmlaCode)
    # BFMLALT (indexed)
    sveWideningMulAddInst('bfmlalt', 'BFmlaltIdx', 'SimdBf16MultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], bfmlaCode,
                          isIndexed=True, uptTop=True)
    # BFMLALT (vector)
    sveWideningMulAddInst('bfmlalt', 'BFmlalt', 'SimdBf16MultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], bfmlaCode,
                          uptTop=True)
    # BFMLS (indexed)
    bfmlsCode = bfOp % ('fplibBfMulAdd(destElem, fplibBfNeg'
                        '(srcElem1, fpcr), srcElem2, fpscr, fpcr)')
    sveTerIdxInst('bfmls', 'BfmlsIdx', 'SimdBf16MultAccOp', ('uint16_t',),
                  bfmlsCode, PredType.MERGE)
    # BFMLS (vector)
    sveTerInst('bfmls', 'Bfmls', 'SimdBf16MultAccOp', ('uint16_t',),
               bfmlsCode, PredType.MERGE)
    # BFMLSLB (indexed)
    bfmlsCode = bfOp % ('fplibBfMulAddH(destElem, fplibBfNeg'
                        '(srcElemA, fpcr), srcElemB, fpscr, fpcr)')
    sveWideningMulAddInst('bfmlslb', 'BFmlslbIdx', 'SimdBf16MultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], bfmlsCode,
                          isIndexed=True)
    # BFMLSLB (vector)
    sveWideningMulAddInst('bfmlslb', 'BFmlslb', 'SimdBf16MultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], bfmlsCode)
    # BFMLSLT (indexed)
    sveWideningMulAddInst('bfmlslt', 'BFmlsltIdx', 'SimdBf16MultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], bfmlsCode,
                          isIndexed=True, uptTop=True)
    # BFMLSLT (vector)
    sveWideningMulAddInst('bfmlslt', 'BFmlslt', 'SimdBf16MultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], bfmlsCode,
                          uptTop=True)
    # BFMMLA (vectors)
    bfmmlaCode = '''
        FPSCR fpscr = FpscrExc & ~FpscrAhpMask;
        FPCR fpcr = (FPCR)Fpcr;

        uint16_t elt1_a = (srcElemA >> 0) & 0xFFFF;
        uint16_t elt1_b = (srcElemA >> 16) & 0xFFFF;
        uint16_t elt2_a = (srcElemB >> 0) & 0xFFFF;
        uint16_t elt2_b = (srcElemB >> 16) & 0xFFFF;

        destElem = fplibBfdotAdd(destElem, elt1_a, elt1_b, elt2_a, elt2_b,
                                 fpscr, fpcr);
    '''
    sveMatMulInst('bfmmla', 'BFmmla', 'SimdBf16MatMultAccOp', ["uint32_t"],
                  numDestRows=2, numDestCols=2, K=2, elt_mul_op=bfmmlaCode)
    # BFMUL (indexed)
    bfmulCode = bfBinOp % 'Mul'
    sveBinIdxInst('bfmul', 'BfmulIdx', 'SimdBf16MultOp', ('uint16_t',),
                  bfmulCode)
    # BFMUL (vectors, predicated)
    sveBinInst('bfmul', 'BfmulPred', 'SimdBf16MultOp', ('uint16_t',),
               bfmulCode, PredType.MERGE, True)
    # BFMUL (vectors, unpredicated)
    sveBinInst('bfmul', 'BfmulUnpred', 'SimdBf16MultOp', ('uint16_t',),
               bfmulCode)
    # BFSUB (predicated)
    bfsubCode = bfBinOp % 'Sub'
    sveBinInst('bfsub', 'BfsubPred', 'SimdBf16AddOp', ('uint16_t',),
               bfsubCode, PredType.MERGE, True)
    # BFSUB (unpredicated)
    sveBinInst('bfsub', 'BfsubUnpred', 'SimdBf16AddOp', ('uint16_t',),
               bfsubCode)
    # BGRP
    bgrpCode = '''
            int k = 0;
            int len = sizeof(Element) * 8;
            for(int j = 0; j < len; j++) {
                if(((srcElem2>>j) & (Element)0x1) == ((Element)0x1)){
                    destElem |= (((srcElem1>>j) & (Element)0x1) << k);
                    k++;
                }
            }
            k = len-1;
            for(int j = len-1; j >= 0; j--) {
                if(((srcElem2>>j) & ((Element)0x1)) == ((Element)0x0)){
                    destElem |= (((srcElem1>>j) & (Element)0x1) << k);
                    k--;
                }
            }
    '''
    sveBinInst('bgrp', 'Bgrp', 'SimdAluOp', unsignedTypes, bgrpCode)
    # BIC (predicates)
    predbicCode = 'destElem = srcElem1 && !srcElem2;'
    svePredLogicalInst('bic', 'PredBic', 'SimdPredAluOp', ('uint8_t',),
                       predbicCode)
    # BIC (vectors, predicated)
    bicCode = 'destElem = srcElem1 & ~srcElem2;'
    sveBinInst('bic', 'BicPred', 'SimdAluOp', unsignedTypes, bicCode,
               PredType.MERGE, True)
    # BIC (vectors, unpredicated)
    sveBinInst('bic', 'BicUnpred', 'SimdAluOp', unsignedTypes, bicCode)
    # BICS (predicates)
    svePredLogicalInst('bics', 'PredBics', 'SimdPredAluOp', ('uint8_t',),
                       predbicCode, isFlagSetting=True)
    # BRKA (merging)
    svePartBrkInst('brka', 'Brkam', 'SimdPredAluOp', isFlagSetting = False,
                   predType = PredType.MERGE, whenBrk = Break.After)
    # BRKA (zeroing)
    svePartBrkInst('brka', 'Brkaz', 'SimdPredAluOp', isFlagSetting = False,
                   predType = PredType.ZERO, whenBrk = Break.After)
    # BRKAS
    svePartBrkInst('brkas', 'Brkas', 'SimdPredAluOp', isFlagSetting = True,
                   predType = PredType.ZERO, whenBrk = Break.After)
    # BRKB (merging)
    svePartBrkInst('brkb', 'Brkbm', 'SimdPredAluOp', isFlagSetting = False,
                   predType = PredType.MERGE, whenBrk = Break.Before)
    # BRKB (zeroging)
    svePartBrkInst('brkb', 'Brkbz', 'SimdPredAluOp', isFlagSetting = False,
                   predType = PredType.ZERO, whenBrk = Break.Before)
    # BRKBS
    svePartBrkInst('brkbs', 'Brkbs', 'SimdPredAluOp', isFlagSetting = True,
                   predType = PredType.ZERO, whenBrk = Break.Before)
    # BRKN
    svePartBrkPropNextInst('brkn', 'Brkn', 'SimdPredAluOp',
                           isFlagSetting = False)
    # BRKNS
    svePartBrkPropNextInst('brkns', 'Brkns', 'SimdPredAluOp',
                           isFlagSetting = True)
    # BRKPA
    svePartBrkPropPrevInst('brkpa', 'Brkpa', 'SimdPredAluOp',
                           isFlagSetting = False, whenBrk = Break.After)
    # BRKPAS
    svePartBrkPropPrevInst('brkpas', 'Brkpas', 'SimdPredAluOp',
                           isFlagSetting = True, whenBrk = Break.After)
    # BRKPB
    svePartBrkPropPrevInst('brkpb', 'Brkpb', 'SimdPredAluOp',
                           isFlagSetting = False, whenBrk = Break.Before)
    # BRKPBS
    svePartBrkPropPrevInst('brkpbs', 'Brkpbs', 'SimdPredAluOp',
                           isFlagSetting = True, whenBrk = Break.Before)
    # BSL
    bslCode = 'destElem = (destElem & srcElem2) | (srcElem1 & ~srcElem2);'
    sveBinInst('bsl', 'Bsl', 'SimdAluOp', ('uint64_t',), bslCode,
               isDestructive=True)
    # BSL1N
    bsl1nCode = 'destElem = (~destElem & srcElem2) | (srcElem1 & ~srcElem2);'
    sveBinInst('bsl1n', 'Bsl1n', 'SimdAluOp', ('uint64_t',), bsl1nCode,
               isDestructive=True)
    # BSL2N
    bsl2nCode = 'destElem = (destElem & srcElem2) | (~srcElem1 & ~srcElem2);'
    sveBinInst('bsl2n', 'Bsl2n', 'SimdAluOp', ('uint64_t',), bsl2nCode,
               isDestructive=True)
    # CADD
    sveComplexAddInst('cadd','Cadd', 'SimdAddOp', signedTypes,
                      predType=PredType.NONE, isInt = True)
    # CDOT (indexed)
    sveComplexDotInst('cdot', 'Cdoti', 'SimdMultAccOp',
                      ['int8_t, int8_t, int32_t', 'int16_t, int16_t, int64_t'],
                      isIndexed = True)
    # CDOT (vectors)
    sveComplexDotInst('cdot', 'Cdotv', 'SimdMultAccOp',
                      ['int8_t, int8_t, int32_t', 'int16_t, int16_t, int64_t'],
                      isIndexed = False)
    # CLASTA (scalar)
    clastaCode = '''
        last++;
        if (last >= eCount)
            last = 0;
        destElem = AA64FpOp1_x[last];'''
    sveSelectInst('clasta', 'Clasta', 'SimdAluOp', unsignedTypes, clastaCode,
                  isCond = True, destType = DstRegType.Scalar)
    # CLASTA (SIMD&FP scalar)
    sveSelectInst('clasta', 'Clastaf', 'SimdAluOp', unsignedTypes, clastaCode,
                  isCond = True, destType = DstRegType.SimdFpScalar)
    # CLASTA (vector)
    sveSelectInst('clasta', 'Clastav', 'SimdAluOp', unsignedTypes, clastaCode,
                  isCond = True, destType = DstRegType.Vector)
    # CLASTB (scalar)
    clastbCode = '''
        destElem = AA64FpOp1_x[last];'''
    sveSelectInst('clastb', 'Clastb', 'SimdAluOp', unsignedTypes, clastbCode,
                  isCond = True, destType = DstRegType.Scalar)
    # CLASTB (SIMD&FP scalar)
    sveSelectInst('clastb', 'Clastbf', 'SimdAluOp', unsignedTypes, clastbCode,
                  isCond = True, destType = DstRegType.SimdFpScalar)
    # CLASTB (vectors)
    sveSelectInst('clastb', 'Clastbv', 'SimdAluOp', unsignedTypes, clastbCode,
                  isCond = True, destType = DstRegType.Vector)
    # CLS
    clsCode = '''
        destElem = 0;
        Element val = srcElem1;
        if (val < 0) {
            val <<= 1;
            while (val < 0) {
                destElem++;
                val <<= 1;
            }
        } else {
            val <<= 1;
            while (val >= 0 && destElem < sizeof(Element) * 8 - 1) {
                destElem++;
                val <<= 1;
            }
        }
    '''
    sveUnaryInst('cls', 'Cls', 'SimdAluOp', signedTypes, clsCode,
                 PredType.MERGE)
    # CLZ
    clzCode = '''
        destElem = 0;
        Element val = srcElem1;
        while (val >= 0 && destElem < sizeof(Element) * 8) {
            destElem++;
            val <<= 1;
        }
    '''
    sveUnaryInst('clz', 'Clz', 'SimdAluOp', signedTypes, clzCode,
                 PredType.MERGE)
    # CMLA (index)
    sveComplexMulAddInst('cmla', 'Cmlai', 'SimdMultAccOp',
                         ['int16_t', 'int32_t'],
                         predType = PredType.NONE, isInt = True,
                         isIndexed = True)
    # CMLA (vector)
    sveComplexMulAddInst('cmla', 'Cmlav', 'SimdMultAccOp', signedTypes,
                         predType = PredType.NONE, isInt = True)
    # CMPEQ (immediate)
    cmpeqCode = 'destElem = (srcElem1 == srcElem2);'
    sveIntCmpImmInst('cmpeq', 'Cmpeqi', 'SimdCmpOp', signedTypes, cmpeqCode)
    # CMPEQ (vectors)
    sveIntCmpInst('cmpeq', 'Cmpeq', 'SimdCmpOp', signedTypes, cmpeqCode)
    # CMPEQ (wide elements)
    sveIntCmpInst('cmpeq', 'Cmpeqw', 'SimdCmpOp', smallSignedTypes,
                  cmpeqCode, True)
    # CMPGE (immediate)
    cmpgeCode = 'destElem = (srcElem1 >= srcElem2);'
    sveIntCmpImmInst('cmpge', 'Cmpgei', 'SimdCmpOp', signedTypes, cmpgeCode)
    # CMPGE (vectors)
    sveIntCmpInst('cmpge', 'Cmpge', 'SimdCmpOp', signedTypes, cmpgeCode)
    # CMPGE (wide elements)
    sveIntCmpInst('cmpge', 'Cmpgew', 'SimdCmpOp', smallSignedTypes,
                  cmpgeCode, True)
    # CMPGT (immediate)
    cmpgtCode = 'destElem = (srcElem1 > srcElem2);'
    sveIntCmpImmInst('cmpge', 'Cmpgti', 'SimdCmpOp', signedTypes, cmpgtCode)
    # CMPGT (vectors)
    sveIntCmpInst('cmpge', 'Cmpgt', 'SimdCmpOp', signedTypes, cmpgtCode)
    # CMPGT (wide elements)
    sveIntCmpInst('cmpge', 'Cmpgtw', 'SimdCmpOp', smallSignedTypes,
                  cmpgtCode, True)
    # CMPHI (immediate)
    sveIntCmpImmInst('cmphi', 'Cmphii', 'SimdCmpOp', unsignedTypes, cmpgtCode)
    # CMPHI (vectors)
    sveIntCmpInst('cmphi', 'Cmphi', 'SimdCmpOp', unsignedTypes, cmpgtCode)
    # CMPHI (wide elements)
    sveIntCmpInst('cmphi', 'Cmphiw', 'SimdCmpOp', smallUnsignedTypes,
                  cmpgtCode, True)
    # CMPHS (immediate)
    sveIntCmpImmInst('cmphs', 'Cmphsi', 'SimdCmpOp', unsignedTypes, cmpgeCode)
    # CMPHS (vectors)
    sveIntCmpInst('cmphs', 'Cmphs', 'SimdCmpOp', unsignedTypes, cmpgeCode)
    # CMPHS (wide elements)
    sveIntCmpInst('cmphs', 'Cmphsw', 'SimdCmpOp', smallUnsignedTypes,
                  cmpgeCode, True)
    # CMPLE (immediate)
    cmpleCode = 'destElem = (srcElem1 <= srcElem2);'
    sveIntCmpImmInst('cmple', 'Cmplei', 'SimdCmpOp', signedTypes, cmpleCode)
    # CMPLE (wide elements)
    sveIntCmpInst('cmple', 'Cmplew', 'SimdCmpOp', smallSignedTypes,
                  cmpleCode, True)
    # CMPLO (immediate)
    cmpltCode = 'destElem = (srcElem1 < srcElem2);'
    sveIntCmpImmInst('cmplo', 'Cmploi', 'SimdCmpOp', unsignedTypes, cmpltCode)
    # CMPLO (wide elements)
    sveIntCmpInst('cmplo', 'Cmplow', 'SimdCmpOp', smallUnsignedTypes,
                  cmpltCode, True)
    # CMPLS (immediate)
    sveIntCmpImmInst('cmpls', 'Cmplsi', 'SimdCmpOp', unsignedTypes, cmpleCode)
    # CMPLS (wide elements)
    sveIntCmpInst('cmpls', 'Cmplsw', 'SimdCmpOp', smallUnsignedTypes,
                  cmpleCode, True)
    # CMPLT (immediate)
    sveIntCmpImmInst('cmplt', 'Cmplti', 'SimdCmpOp', signedTypes, cmpltCode)
    # CMPLT (wide elements)
    sveIntCmpInst('cmplt', 'Cmpltw', 'SimdCmpOp', smallSignedTypes,
                  cmpltCode, True)
    # CMPNE (immediate)
    cmpneCode = 'destElem = (srcElem1 != srcElem2);'
    sveIntCmpImmInst('cmpeq', 'Cmpnei', 'SimdCmpOp', signedTypes, cmpneCode)
    # CMPNE (vectors)
    sveIntCmpInst('cmpeq', 'Cmpne', 'SimdCmpOp', signedTypes, cmpneCode)
    # CMPNE (wide elements)
    sveIntCmpInst('cmpeq', 'Cmpnew', 'SimdCmpOp', smallSignedTypes,
                  cmpneCode, True)
    # CNOT
    cnotCode = 'destElem = srcElem1 ? 0 : 1;'
    sveUnaryInst('cnot', 'Cnot', 'SimdAluOp', unsignedTypes, cnotCode,
                 PredType.MERGE)
    # CNT
    cntCode = '''
        destElem = 0;
        Element val = srcElem1;
        while (val) {
            destElem += val & 0x1;
            val >>= 1;
        }
    '''
    sveUnaryInst('cnt', 'Cnt', 'SimdAluOp', unsignedTypes, cntCode,
                 PredType.MERGE)
    # CNTB, CNTD, CNTH, CNTW
    cntxCode = '''
        destElem = (count * imm);
    '''
    sveElemCountInst('cnt', 'Cntx', 'SimdAluOp', unsignedTypes, cntxCode,
                     destType = DestType.Scalar, dstIs32b = False,
                     dstAcc = False)
    # CNTP (predicate)
    svePredCountPredInst('cntp', 'Cntp', 'SimdAluOp', unsignedTypes)
    # CNTP (predicate as counter)
    svePredCountPngInst('cntp', 'CntpPng', 'SimdAluOp', unsignedTypes)
    # COMPACT
    sveCompactInst('compact', 'Compact', 'SimdPredAluOp',
                   ('uint32_t', 'uint64_t'))
    # CPY (immediate, merging)
    dupCode = 'destElem = srcElem1;'
    sveWideImmInst('cpy', 'CpyImmMerge', 'SimdAluOp', unsignedTypes, dupCode,
                   predType=PredType.MERGE, isUnary=True)
    # CPY (immediate, zeroing)
    sveWideImmInst('cpy', 'CpyImmZero', 'SimdAluOp', unsignedTypes, dupCode,
                   predType=PredType.ZERO, isUnary=True)
    # CPY (scalar)
    sveUnaryInst('cpy', 'CpyScalar', 'SimdAluOp', unsignedTypes, dupCode,
                 PredType.MERGE, srcRegType=SrcRegType.Scalar)
    # CPY (SIMD&FP scalar)
    sveUnaryInst('cpy', 'CpySimdFpScalar', 'SimdAluOp', unsignedTypes, dupCode,
                 PredType.MERGE, srcRegType=SrcRegType.SimdFpScalar)
    # CTERMEQ
    cteqCode = 'destElem = srcElem1 == srcElem2;'
    sveCompTermInst('ctermeq', 'Ctermeq', 'IntAluOp',
            ['uint32_t', 'uint64_t'], cteqCode)
    # CTERMNE
    ctneCode = 'destElem = srcElem1 != srcElem2;'
    sveCompTermInst('ctermne', 'Ctermne', 'IntAluOp',
            ['uint32_t', 'uint64_t'], ctneCode)
    # DECB, DECH, DECW, DECD (scalar)
    decxCode = 'destElem = srcElem1 - (count * imm);'
    sveElemCountInst('dec', 'Dec', 'SimdAluOp', unsignedTypes, decxCode,
                     destType = DestType.Scalar, dstIs32b = False)
    # DECH, DECW, DECD (vector)
    sveElemCountInst('dec', 'Decv', 'SimdAluOp', bigUnsignedTypes, decxCode,
                     destType = DestType.Vector, dstIs32b = False)
    # DECP (scalar)
    decpCode = 'XDest = XDest - count;'
    svePredCountInst('decp', 'Decp', 'SimdAluOp', unsignedTypes, decpCode,
                     DestType.Scalar, SrcSize.Src64bit)
    # DECP (vector)
    decpvCode = 'destElem = srcElem - count;'
    svePredCountInst('decp', 'Decpv', 'SimdAluOp', unsignedTypes, decpvCode,
                     DestType.Vector)
    # DUP (immediate)
    sveWideImmInst('dup', 'DupImm', 'SimdAluOp', unsignedTypes, dupCode,
                   isUnary=True)
    # DUP (indexed)
    sveDupIndexInst('mov', 'DupIdx', 'SimdAluOp',
                    list(unsignedTypes) + ['__uint128_t'])
    # DUP (scalar)
    sveUnaryInst('dup', 'DupScalar', 'SimdAluOp', unsignedTypes, dupCode,
                 PredType.NONE, srcRegType=SrcRegType.Scalar)
    # DUPM
    sveWideImmInst('dupm', 'Dupm', 'SimdAluOp', unsignedTypes, dupCode,
                   isUnary=True)
    # DUPQ
    sveDupIndexInst('dupq', 'DupqIdx', 'SimdAluOp', unsignedTypes, isSeg=True)
    # EOR (immediate)
    eorCode = 'destElem = srcElem1 ^ srcElem2;'
    sveWideImmInst('eor', 'EorImm', 'SimdAluOp', ('uint64_t',), eorCode)
    # EOR (predicates)
    svePredLogicalInst('eor', 'PredEor', 'SimdPredAluOp', ('uint8_t',),
                       eorCode)
    # EOR (vectors, predicated)
    sveBinInst('eor', 'EorPred', 'SimdAluOp', unsignedTypes, eorCode,
               PredType.MERGE, True)
    # EOR (vectors, unpredicated)
    sveBinInst('eor', 'EorUnpred', 'SimdAluOp', ('uint64_t',), eorCode)
    # EOR3
    eor3Code = 'destElem ^= srcElem1 ^ srcElem2;'
    sveBinInst('eor', 'Eor3', 'SimdAluOp', ('uint64_t',), eor3Code,
                isDestructive=True)
    # EORBT
    sveBinInterInst('eorbt', 'Eorbt', 'SimdAluOp', unsignedTypes, eorCode)
    # EORQV
    eorvCode = 'destElem ^= srcElem1;'
    sveAssocReducInst('eorqv', 'Eorqv', 'SimdReduceAluOp', unsignedTypes,
                      eorvCode, '0', isHvla=True)
    # EORS (predicates)
    svePredLogicalInst('eors', 'PredEors', 'SimdPredAluOp', ('uint8_t',),
                       eorCode, isFlagSetting=True)
    # EORTB
    sveBinInterInst('eortb', 'Eortb', 'SimdAluOp', unsignedTypes, eorCode,
                    tb = True)
    # EORV
    sveAssocReducInst('eorv', 'Eorv', 'SimdReduceAluOp', unsignedTypes,
                      eorvCode, '0')
    # EXT
    sveExtInst('ext', 'Ext', 'SimdAluOp', ('uint8_t',))
    # EXTQ
    sveExtInst('extq', 'Extq', 'SimdAluOp', ('uint8_t',), isSeg=True)
    # FABD
    fpOp = '''
            FPSCR fpscr = FpscrExc & ~FpscrAhpMask;
            [[maybe_unused]] FPCR fpcr = (FPCR)Fpcr;
            destElem = %s;
            FpscrExc = fpscr;
    '''
    fabdCode = fpOp % ('fplibAbs<Element>(fplibSub<Element>'
                       '(srcElem1, srcElem2, fpscr, fpcr), fpcr)')
    sveBinInst('fabd', 'Fabd', 'SimdFloatAddOp', floatTypes, fabdCode,
               PredType.MERGE, True)
    # FABS
    fabsCode = '''
            FPCR fpcr = (FPCR)Fpcr;
            destElem = fplibAbs<Element>(srcElem1, fpcr);
    '''
    sveUnaryInst('fabs', 'Fabs', 'SimdFloatAluOp', fpTypes, fabsCode,
                 PredType.MERGE)
    # FACGE
    fpCmpAbsOp = fpOp % ('fplibCompare%s<Element>('
                         'fplibAbs<Element>(srcElem1, fpcr), '
                         'fplibAbs<Element>(srcElem2, fpcr), fpscr, fpcr)')
    facgeCode = fpCmpAbsOp % 'GE'
    sveCmpInst('facge', 'Facge', 'SimdFloatCmpOp', fpTypes, facgeCode)
    # FACGT
    facgtCode = fpCmpAbsOp % 'GT'
    sveCmpInst('facgt', 'Facgt', 'SimdFloatCmpOp', fpTypes, facgtCode)
    # FADD (immediate)
    fpBinOp = fpOp % 'fplib%s<Element>(srcElem1, srcElem2, fpscr, fpcr)'
    faddCode = fpBinOp % 'Add'
    sveBinImmInst('fadd', 'FaddImm', 'SimdFloatAddOp', floatTypes, faddCode,
                  PredType.MERGE)
    # FADD (vectors, predicated)
    sveBinInst('fadd', 'FaddPred', 'SimdFloatAddOp', floatTypes, faddCode,
               PredType.MERGE, True)
    # FADD (vectors, unpredicated)
    sveBinInst('fadd', 'FaddUnpred', 'SimdFloatAddOp', floatTypes, faddCode)
    # FADDA
    fpAddaOp = '''
            FPSCR fpscr = FpscrExc & ~FpscrAhpMask;
            FPCR fpcr = (FPCR)Fpcr;
            destElem = fplibAdd<Element>(destElem, srcElem1, fpscr, fpcr);
            FpscrExc = FpscrExc | fpscr;
    '''
    sveOrderedReduction('fadda', 'Fadda', 'SimdFloatReduceAddOp', floatTypes,
                        fpAddaOp)
    # FADDP
    sveBinPairInst('faddp', 'Faddp', 'SimdFloatAddOp', floatTypes, faddCode)
    # FADDQV
    fpReduceOp = '''
            FPSCR fpscr = FpscrExc & ~FpscrAhpMask;
            FPCR fpcr = (FPCR)Fpcr;
            destElem = fplib%s<Element>(srcElem1, srcElem2, fpscr, fpcr);
            FpscrExc = FpscrExc | fpscr;
    '''
    faddvCode = fpReduceOp % 'Add'
    sveNonAssocReducInst('faddqv', 'Faddqv', 'SimdFloatReduceAddOp',
                         floatTypes, faddvCode, '0', isHvla = True)
    # FADDV
    sveNonAssocReducInst('faddv', 'Faddv', 'SimdFloatReduceAddOp', floatTypes,
                         faddvCode, '0')
    # FCADD
    sveComplexAddInst('fcadd','Fcadd', 'SimdFloatAddOp', fpTypes)
    # FCLAMP
    sveClampInst('fclamp', 'Fclamp', 'SimdFloatCmpOp', fpTypes, isFp = True)
    # FCMEQ (vectors)
    fpCmpOp = fpOp % ('fplibCompare%s<Element>'
                      '(srcElem1, srcElem2, fpscr, fpcr)')
    fcmeqCode = fpCmpOp % 'EQ'
    sveCmpInst('fcmeq', 'Fcmeq', 'SimdFloatCmpOp', fpTypes, fcmeqCode)
    # FCMEQ (zero)
    fpCmpZeroOp = fpOp % 'fplibCompare%s<Element>(srcElem1, 0, fpscr, fpcr)'
    fcmeqZeroCode = fpCmpZeroOp % 'EQ'
    sveCmpInst('fcmeq', 'FcmeqZero', 'SimdFloatCmpOp', fpTypes, fcmeqZeroCode,
               True)
    # FCMGE (vectors)
    fcmgeCode = fpCmpOp % 'GE'
    sveCmpInst('fcmge', 'Fcmge', 'SimdFloatCmpOp', fpTypes, fcmgeCode)
    # FCMGE (zero)
    fcmgeZeroCode = fpCmpZeroOp % 'GE'
    sveCmpInst('fcmge', 'FcmgeZero', 'SimdFloatCmpOp', fpTypes, fcmgeZeroCode,
               True)
    # FCMGT (vectors)
    fcmgtCode = fpCmpOp % 'GT'
    sveCmpInst('fcmgt', 'Fcmgt', 'SimdFloatCmpOp', fpTypes, fcmgtCode)
    # FCMGT (zero)
    fcmgtZeroCode = fpCmpZeroOp % 'GT'
    sveCmpInst('fcmgt', 'FcmgtZero', 'SimdFloatCmpOp', fpTypes, fcmgtZeroCode,
               True)
    # FCMLE (zero)
    fpCmpRevZeroOp = fpOp % ('fplibCompare%s<Element>'
                             '(0, srcElem1, fpscr, fpcr)')
    fcmleZeroCode = fpCmpRevZeroOp % 'GE'
    sveCmpInst('fcmle', 'FcmleZero', 'SimdFloatCmpOp', fpTypes, fcmleZeroCode,
               True)
    # FCMLT (zero)
    fcmltZeroCode = fpCmpRevZeroOp % 'GT'
    sveCmpInst('fcmlt', 'FcmltZero', 'SimdFloatCmpOp', fpTypes, fcmltZeroCode,
               True)
    # FCMNE (vectors)
    fcmneCode = fpOp % ('!fplibCompareEQ<Element>'
                        '(srcElem1, srcElem2, fpscr, fpcr)')
    sveCmpInst('fcmne', 'Fcmne', 'SimdFloatCmpOp', fpTypes, fcmneCode)
    # FCMNE (zero)
    fcmneZeroCode = fpOp % ('!fplibCompareEQ<Element>'
                            '(srcElem1, 0, fpscr, fpcr)')
    sveCmpInst('fcmne', 'FcmneZero', 'SimdFloatCmpOp', fpTypes, fcmneZeroCode,
               True)
    # FCMUO (vectors)
    fcmuoCode = fpCmpOp % 'UN'
    sveCmpInst('fcmuo', 'Fcmuo', 'SimdFloatCmpOp', fpTypes, fcmuoCode)
    # FCMLA (indexed)
    sveComplexMulAddInst('fcmla', 'Fcmlai', 'SimdFloatMultAccOp',
                         fpTypes[:2], predType = PredType.NONE,
                         isIndexed = True)
    # FCMLA (vectors)
    sveComplexMulAddInst('fcmla', 'Fcmlav', 'SimdFloatMultAccOp',
                         fpTypes, predType = PredType.MERGE)
    # FCPY
    sveWideImmInst('fcpy', 'Fcpy', 'SimdAluOp', unsignedTypes, dupCode,
                   predType=PredType.MERGE, isUnary=True)
    # FCVT
    fcvtCode = fpOp % ('fplibConvert<SElement, DElement>('
                       'srcElem1, FPCRRounding(fpscr), fpscr, fpcr)')
    sveCvtInst('fcvt', 'FcvtNarrow', 'SimdFloatCvtOp',
               ('uint32_t, uint16_t',
                'uint64_t, uint16_t',
                'uint64_t, uint32_t'),
               fcvtCode, CvtDir.Narrow)
    sveCvtInst('fcvt', 'FcvtWiden', 'SimdFloatCvtOp',
               ('uint16_t, uint32_t',
                'uint16_t, uint64_t',
                'uint32_t, uint64_t'),
               fcvtCode, CvtDir.Widen)
    # FCVTLT
    sveCvtInst('fcvt', 'Fcvtlt', 'SimdFloatCvtOp',
               ('uint16_t, uint32_t', 'uint32_t, uint64_t'),
               fcvtCode, CvtDir.Widen, uptTop=True)
    # FCVTNT
    sveCvtInst('fcvt', 'Fcvtnt', 'SimdFloatCvtOp',
               ('uint32_t, uint16_t', 'uint64_t, uint32_t'),
               fcvtCode, CvtDir.Narrow, uptTop=True)
    # FCVTX
    fcvtxCode = fpOp % ('fplibConvert<SElement, DElement>('
                       'srcElem1, FPRounding_ODD, fpscr, fpcr)')
    sveCvtInst('fcvtx', 'FcvtxNarrow', 'SimdFloatCvtOp',
               ('uint64_t, uint32_t',),
               fcvtxCode, CvtDir.Narrow)
    # FCVTXNT
    sveCvtInst('fcvtxnt', 'Fcvtxnt', 'SimdFloatCvtOp',
               ('uint64_t, uint32_t',),
               fcvtxCode, CvtDir.Narrow, uptTop=True)
    # FCVTZS
    fcvtIntCode = fpOp % ('fplibFPToFixed<SElement, DElement>('
                          'srcElem1, %s, %s, %s, fpscr, fpcr)')
    fcvtzsCode = fcvtIntCode % ('0', 'false', 'FPRounding_ZERO')
    sveCvtInst('fcvtzs', 'FcvtzsNarrow', 'SimdFloatCvtOp',
               ('uint16_t, uint16_t',
                'uint32_t, uint32_t',
                'uint64_t, uint32_t',
                'uint64_t, uint64_t'),
               fcvtzsCode, CvtDir.Narrow, signed=True)
    sveCvtInst('fcvtzs', 'FcvtzsWiden', 'SimdFloatCvtOp',
               ('uint16_t, uint32_t',
                'uint16_t, uint64_t',
                'uint32_t, uint64_t'),
               fcvtzsCode, CvtDir.Widen)
    # FCVTZU
    fcvtzuCode = fcvtIntCode % ('0', 'true', 'FPRounding_ZERO')
    sveCvtInst('fcvtzu', 'FcvtzuNarrow', 'SimdFloatCvtOp',
               ('uint16_t, uint16_t',
                'uint32_t, uint32_t',
                'uint64_t, uint32_t',
                'uint64_t, uint64_t'),
               fcvtzuCode, CvtDir.Narrow)
    sveCvtInst('fcvtzu', 'FcvtzuWiden', 'SimdFloatCvtOp',
               ('uint16_t, uint32_t',
                'uint16_t, uint64_t',
                'uint32_t, uint64_t'),
               fcvtzuCode, CvtDir.Widen)
    # FDIV
    fdivCode = fpBinOp % 'Div'
    sveBinInst('fdiv', 'Fdiv', 'SimdFloatDivOp', floatTypes, fdivCode,
               PredType.MERGE, True)
    # FDIVR
    fpBinRevOp = fpOp % 'fplib%s<Element>(srcElem2, srcElem1, fpscr, fpcr)'
    fdivrCode = fpBinRevOp % 'Div'
    sveBinInst('fdivr', 'Fdivr', 'SimdFloatDivOp', floatTypes, fdivrCode,
               PredType.MERGE, True)
    # FDOT (2-way, indexed, FP16 to FP32)
    fdotHpSpCode = '''
            FPSCR fpscr = FpscrExc & ~FpscrAhpMask;
            FPCR fpcr = (FPCR)Fpcr;

            DElement prod = fplibDot<SElementA, DElement>(
                srcElemA_0, srcElemA_1, srcElemB_0, srcElemB_1, fpscr, fpcr);
            destElem = fplibAdd(destElem, prod, fpscr, fpcr);

            FpscrExc = fpscr;
    '''
    sveBfDotInst('fdot', 'FdotHpSpIdx', 'SimdFloatMultAccOp',
                 ['uint16_t, uint16_t, uint32_t'], fdotHpSpCode,
                 isIndexed=True)
    # FDOT (2-way, vectors, FP16 to FP32)
    sveBfDotInst('fdot', 'FdotHpSp', 'SimdFloatMultAccOp',
                 ['uint16_t, uint16_t, uint32_t'], fdotHpSpCode)
    # FDUP
    sveWideImmInst('fdup', 'Fdup', 'SimdFloatAluOp', floatTypes, dupCode,
                   isUnary=True)
    # FEXPA
    fexpaCode = 'destElem = fplibExpA<Element>(srcElem1);'
    sveUnaryInst('fexpa', 'Fexpa', 'SimdFloatAluOp', fpTypes, fexpaCode)
    # FLOGB
    flogbCode = fpOp % 'fplibLogB<Element>(srcElem1, fpscr, fpcr)'
    sveUnaryInst('flogb', 'Flogb', 'SimdFloatAluOp', fpTypes, flogbCode,
                 PredType.MERGE)
    # FMAD
    fmadCode = fpOp % ('fplibMulAdd<Element>('
                       'srcElem1, destElem, srcElem2, fpscr, fpcr)')
    sveTerInst('fmad', 'Fmad', 'SimdFloatMultAccOp', floatTypes, fmadCode,
               PredType.MERGE)
    # FMAX (immediate)
    fmaxCode = fpBinOp % 'Max'
    sveBinImmInst('fmax', 'FmaxImm', 'SimdFloatCmpOp', floatTypes, fmaxCode,
                  PredType.MERGE)
    # FMAX (vectors)
    sveBinInst('fmax', 'Fmax', 'SimdFloatCmpOp', floatTypes, fmaxCode,
               PredType.MERGE, True)
    # FMAXNM (immediate)
    fmaxnmCode = fpBinOp % 'MaxNum'
    sveBinImmInst('fmaxnm', 'FmaxnmImm', 'SimdFloatCmpOp', floatTypes,
                  fmaxnmCode, PredType.MERGE)
    # FMAXNM (vectors)
    sveBinInst('fmaxnm', 'Fmaxnm', 'SimdFloatCmpOp', floatTypes, fmaxnmCode,
               PredType.MERGE, True)
    # FMAXNMP
    sveBinPairInst('fmaxnmp', 'Fmaxnmp', 'SimdFloatCmpOp', floatTypes,
                   fmaxnmCode)
    # FMAXNMQV
    fmaxnmvCode = fpReduceOp % 'MaxNum'
    sveNonAssocReducInst('fmaxnmqv', 'Fmaxnmqv', 'SimdFloatReduceCmpOp',
                         floatTypes, fmaxnmvCode,
                         'fplibDefaultNaN<Element>((FPCR)Fpcr)',
                         isHvla = True)
    # FMAXNMV
    sveNonAssocReducInst('fmaxnmv', 'Fmaxnmv', 'SimdFloatReduceCmpOp',
                         floatTypes, fmaxnmvCode,
                         'fplibDefaultNaN<Element>((FPCR)Fpcr)')
    # FMAXP
    sveBinPairInst('fmaxp', 'Fmaxp', 'SimdFloatCmpOp', floatTypes, fmaxCode)
    # FMAXQV
    fmaxvCode = fpReduceOp % 'Max'
    sveNonAssocReducInst('fmaxqv', 'Fmaxqv', 'SimdFloatReduceCmpOp',
                         floatTypes, fmaxvCode, 'fplibInfinity<Element>(1)',
                         isHvla = True)
    # FMAXV
    sveNonAssocReducInst('fmaxv', 'Fmaxv', 'SimdFloatReduceCmpOp', floatTypes,
                         fmaxvCode, 'fplibInfinity<Element>(1)')
    # FMIN (immediate)
    fminCode = fpBinOp % 'Min'
    sveBinImmInst('fmin', 'FminImm', 'SimdFloatCmpOp', floatTypes, fminCode,
                  PredType.MERGE)
    # FMIN (vectors)
    sveBinInst('fmin', 'Fmin', 'SimdFloatCmpOp', floatTypes, fminCode,
               PredType.MERGE, True)
    # FMINNM (immediate)
    fminnmCode = fpBinOp % 'MinNum'
    sveBinImmInst('fminnm', 'FminnmImm', 'SimdFloatCmpOp', floatTypes,
                  fminnmCode, PredType.MERGE)
    # FMINNM (vectors)
    sveBinInst('fminnm', 'Fminnm', 'SimdFloatCmpOp', floatTypes, fminnmCode,
               PredType.MERGE, True)
    # FMINNMP
    sveBinPairInst('fminnmp', 'Fminnmp', 'SimdFloatCmpOp', floatTypes,
                   fminnmCode)
    # FMINNMQV
    fminnmvCode = fpReduceOp % 'MinNum'
    sveNonAssocReducInst('fminnmqv', 'Fminnmqv', 'SimdFloatReduceCmpOp',
                         floatTypes, fminnmvCode,
                         'fplibDefaultNaN<Element>((FPCR)Fpcr)',
                         isHvla = True)
    # FMINNMV
    sveNonAssocReducInst('fminnmv', 'Fminnmv', 'SimdFloatReduceCmpOp',
                         floatTypes, fminnmvCode,
                         'fplibDefaultNaN<Element>((FPCR)Fpcr)')
    # FMINP
    sveBinPairInst('fminp', 'Fminp', 'SimdFloatCmpOp', floatTypes, fminCode)
    # FMINQV
    fminvCode = fpReduceOp % 'Min'
    sveNonAssocReducInst('fminqv', 'Fminqv', 'SimdFloatReduceCmpOp',
                         floatTypes, fminvCode, 'fplibInfinity<Element>(0)',
                         isHvla = True)
    # FMINV
    sveNonAssocReducInst('fminv', 'Fminv', 'SimdFloatReduceCmpOp', floatTypes,
                         fminvCode, 'fplibInfinity<Element>(0)')
    # FMLA (indexed)
    fmlaCode = fpOp % ('fplibMulAdd<Element>('
                       'destElem, srcElem1, srcElem2, fpscr, fpcr)')
    sveTerIdxInst('fmla', 'FmlaIdx', 'SimdFloatMultAccOp', floatTypes,
                  fmlaCode, PredType.MERGE)
    # FMLA (vectors)
    sveTerInst('fmla', 'Fmla', 'SimdFloatMultAccOp', floatTypes, fmlaCode,
               PredType.MERGE)
    # FMLALB (indexed)
    fmlalCode = fpOp % ("fplibMulAddH<TPSrcAElem, TPDElem>("
                       "destElem, srcElemA, srcElemB, fpscr, fpcr)")
    sveWideningMulAddInst('fmlalb', 'FmlalbIdx', 'SimdFloatMultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], fmlalCode,
                          isIndexed=True)
    # FMLALB (vectors)
    sveWideningMulAddInst('fmlalb', 'Fmlalb', 'SimdFloatMultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], fmlalCode)
    # FMLALT (indexed)
    sveWideningMulAddInst('fmlalb', 'FmlaltIdx', 'SimdFloatMultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], fmlalCode,
                          isIndexed=True, uptTop=True)
    # FMLALT (vectors)
    sveWideningMulAddInst('fmlalb', 'Fmlalt', 'SimdFloatMultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], fmlalCode,
                          uptTop=True)
    # FMLS (indexed)
    fmlsCode = fpOp % ('fplibMulAdd<Element>(destElem, fplibNeg<Element>'
                       '(srcElem1, fpcr), srcElem2, fpscr, fpcr)')
    sveTerIdxInst('fmls', 'FmlsIdx', 'SimdFloatMultAccOp', floatTypes,
                  fmlsCode, PredType.MERGE)
    # FMLS (vectors)
    sveTerInst('fmls', 'Fmls', 'SimdFloatMultAccOp', floatTypes, fmlsCode,
               PredType.MERGE)
    # FMLSLB (indexed)
    fmlslCode = fpOp % ("fplibMulAddH<TPSrcAElem, TPDElem>"
                        "(destElem, fplibNeg<TPSrcAElem>"
                        "(srcElemA, fpcr), srcElemB, fpscr, fpcr)")
    sveWideningMulAddInst('fmlslb', 'FmlslbIdx', 'SimdFloatMultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], fmlslCode,
                          isIndexed=True)
    # FMLSLB (vectors)
    sveWideningMulAddInst('fmlslb', 'Fmlslb', 'SimdFloatMultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], fmlslCode)
    # FMLSLT (indexed)
    sveWideningMulAddInst('fmlslb', 'FmlsltIdx', 'SimdFloatMultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], fmlslCode,
                          isIndexed=True, uptTop=True)
    # FMLSLT (vectors)
    sveWideningMulAddInst('fmlslb', 'Fmlslt', 'SimdFloatMultAccOp',
                          ['uint16_t, uint16_t, uint32_t'], fmlslCode,
                          uptTop=True)
    # FMMLA (vectors)
    fmmlaCode = '''
        FPSCR fpscr = FpscrExc & ~FpscrAhpMask;
        FPCR fpcr = (FPCR)Fpcr;

        if (k == 0) {
            prodSum = fplibMul<DestElement>(srcElemA, srcElemB, fpscr, fpcr);
        } else {
            prodSum = fplibAdd<DestElement>(prodSum, fplibMul<DestElement>(
                srcElemA, srcElemB, fpscr, fpcr), fpscr, fpcr);
        }
        if (k == K - 1) {
            destElem = fplibAdd<DestElement>(destElem, prodSum, fpscr, fpcr);
        }

        FpscrExc = fpscr;
    '''
    sveMatMulInst('fmmla', 'FmmlaSp', 'SimdFloatMatMultAccOp', ['uint32_t'],
                  numDestRows=2, numDestCols=2, K=2,
                  elt_mul_op=fmmlaCode)
    sveMatMulInst('fmmla', 'FmmlaDp', 'SimdFloatMatMultAccOp', ['uint64_t'],
                  numDestRows=2, numDestCols=2, K=2,
                  elt_mul_op=fmmlaCode)
    # FMSB
    fmsbCode = fpOp % ('fplibMulAdd<Element>(srcElem1, fplibNeg<Element>'
                       '(destElem, fpcr), srcElem2, fpscr, fpcr)')
    sveTerInst('fmsb', 'Fmsb', 'SimdFloatMultAccOp', floatTypes, fmsbCode,
               PredType.MERGE)
    # FMUL (immediate)
    fmulCode = fpBinOp % 'Mul'
    sveBinImmInst('fmul', 'FmulImm', 'SimdFloatMultOp', floatTypes, fmulCode,
                  PredType.MERGE)
    # FMUL (indexed)
    sveBinIdxInst('fmul', 'FmulIdx', 'SimdFloatMultOp', floatTypes, fmulCode)
    # FMUL (vectors, predicated)
    sveBinInst('fmul', 'FmulPred', 'SimdFloatMultOp', floatTypes, fmulCode,
               PredType.MERGE, True)
    # FMUL (vectors, unpredicated)
    sveBinInst('fmul', 'FmulUnpred', 'SimdFloatMultOp', floatTypes, fmulCode)
    # FMULX
    fmulxCode = fpBinOp % 'MulX'
    sveBinInst('fmulx', 'Fmulx', 'SimdFloatMultOp', floatTypes, fmulxCode,
               PredType.MERGE, True)
    # FNEG
    fnegCode = '''
            FPCR fpcr = (FPCR)Fpcr;
            destElem = fplibNeg<Element>(srcElem1, fpcr);
    '''
    sveUnaryInst('fneg', 'Fneg', 'SimdFloatAluOp', fpTypes, fnegCode,
                 PredType.MERGE)
    # FNMAD
    fnmadCode = fpOp % ('fplibMulAdd<Element>('
                        'fplibNeg<Element>(srcElem1, fpcr), '
                        'fplibNeg<Element>(destElem, fpcr), '
                        'srcElem2, fpscr, fpcr)')
    sveTerInst('fnmad', 'Fnmad', 'SimdFloatMultAccOp', floatTypes, fnmadCode,
               PredType.MERGE)
    # FNMLA
    fnmlaCode = fpOp % ('fplibMulAdd<Element>('
                        'fplibNeg<Element>(destElem, fpcr), '
                        'fplibNeg<Element>(srcElem1, fpcr), '
                        'srcElem2, fpscr, fpcr)')
    sveTerInst('fnmla', 'Fnmla', 'SimdFloatMultAccOp', floatTypes, fnmlaCode,
               PredType.MERGE)
    # FNMLS
    fnmlsCode = fpOp % ('fplibMulAdd<Element>(fplibNeg<Element>'
                        '(destElem, fpcr), srcElem1, srcElem2, fpscr, fpcr)')
    sveTerInst('fnmls', 'Fnmls', 'SimdFloatMultAccOp', floatTypes, fnmlsCode,
               PredType.MERGE)
    # FNMSB
    fnmsbCode = fpOp % ('fplibMulAdd<Element>(fplibNeg<Element>'
                        '(srcElem1, fpcr), destElem, srcElem2, fpscr, fpcr)')
    sveTerInst('fnmsb', 'Fnmsb', 'SimdFloatMultAccOp', floatTypes, fnmsbCode,
               PredType.MERGE)
    # FRECPE
    frecpeCode = fpOp % 'fplibRecipEstimate<Element>(srcElem1, fpscr, fpcr)'
    sveUnaryInst('frecpe', 'Frecpe', 'SimdFloatMultAccOp', floatTypes,
                 frecpeCode)
    # FRECPS
    frecpsCode = fpBinOp % 'RecipStepFused'
    sveBinInst('frecps', 'Frecps', 'SimdFloatMultAccOp', floatTypes,
               frecpsCode)
    # FRECPX
    frecpxCode = fpOp % "fplibRecpX<Element>(srcElem1, fpscr, fpcr)"
    sveUnaryInst('frecpx', 'Frecpx', 'SimdFloatMultAccOp', floatTypes,
                 frecpxCode, PredType.MERGE)
    # FRINTA
    frintCode = fpOp % ('fplibRoundInt<Element>'
                        '(srcElem1, %s, %s, fpscr, fpcr)')
    frintaCode = frintCode % ('FPRounding_TIEAWAY', 'false')
    sveUnaryInst('frinta', 'Frinta', 'SimdFloatCvtOp', floatTypes, frintaCode,
                 PredType.MERGE)
    # FRINTI
    frintiCode = frintCode % ('FPCRRounding(fpscr)', 'false')
    sveUnaryInst('frinti', 'Frinti', 'SimdFloatCvtOp', floatTypes, frintiCode,
                 PredType.MERGE)
    # FRINTM
    frintmCode = frintCode % ('FPRounding_NEGINF', 'false')
    sveUnaryInst('frintm', 'Frintm', 'SimdFloatCvtOp', floatTypes, frintmCode,
                 PredType.MERGE)
    # FRINTN
    frintnCode = frintCode % ('FPRounding_TIEEVEN', 'false')
    sveUnaryInst('frintn', 'Frintn', 'SimdFloatCvtOp', floatTypes, frintnCode,
                 PredType.MERGE)
    # FRINTP
    frintpCode = frintCode % ('FPRounding_POSINF', 'false')
    sveUnaryInst('frintp', 'Frintp', 'SimdFloatCvtOp', floatTypes, frintpCode,
                 PredType.MERGE)
    # FRINTX
    frintxCode = frintCode % ('FPCRRounding(fpscr)', 'true')
    sveUnaryInst('frintx', 'Frintx', 'SimdFloatCvtOp', floatTypes, frintxCode,
                 PredType.MERGE)
    # FRINTZ
    frintzCode = frintCode % ('FPRounding_ZERO', 'false')
    sveUnaryInst('frintz', 'Frintz', 'SimdFloatCvtOp', floatTypes, frintzCode,
                 PredType.MERGE)
    # FRSQRTE
    frsqrteCode = fpOp % 'fplibRSqrtEstimate<Element>(srcElem1, fpscr, fpcr)'
    sveUnaryInst('frsqrte', 'Frsqrte', 'SimdFloatSqrtOp', floatTypes,
                 frsqrteCode)
    # FRSQRTS
    frsqrtsCode = fpBinOp % 'RSqrtStepFused'
    sveBinInst('frsqrts', 'Frsqrts', 'SimdFloatAluOp', floatTypes,
               frsqrtsCode)
    # FSCALE
    fscaleCode = fpBinOp % 'Scale'
    sveBinInst('fscale', 'Fscale', 'SimdFloatAluOp', floatTypes, fscaleCode,
               PredType.MERGE, True)
    # FSQRT
    fsqrtCode = fpOp % "fplibSqrt<Element>(srcElem1, fpscr, fpcr)"
    sveUnaryInst('fsqrt', 'Fsqrt', 'SimdFloatSqrtOp', floatTypes, fsqrtCode,
                 PredType.MERGE)
    # FSUB (immediate)
    fsubCode = fpBinOp % 'Sub'
    sveBinImmInst('fsub', 'FsubImm', 'SimdFloatAddOp', floatTypes, fsubCode,
                  PredType.MERGE)
    # FSUB (vectors, predicated)
    sveBinInst('fsub', 'FsubPred', 'SimdFloatAddOp', floatTypes, fsubCode,
               PredType.MERGE, True)
    # FSUB (vectors, unpredicated)
    sveBinInst('fsub', 'FsubUnpred', 'SimdFloatAddOp', floatTypes, fsubCode)
    # FSUBR (immediate)
    fsubrCode = fpBinRevOp % 'Sub'
    sveBinImmInst('fsubr', 'FsubrImm', 'SimdFloatAddOp', floatTypes, fsubrCode,
                  PredType.MERGE)
    # FSUBR (vectors)
    sveBinInst('fsubr', 'Fsubr', 'SimdFloatAddOp', floatTypes, fsubrCode,
               PredType.MERGE, True)
    # FTMAD
    ftmadCode = fpOp % ('fplibTrigMulAdd<Element>('
                        'srcElem3, destElem, srcElem2, fpscr, fpcr)')
    sveTerImmInst('ftmad', 'Ftmad', 'SimdFloatMultAccOp', floatTypes,
                  ftmadCode)
    # FTSMUL
    ftsmulCode = fpBinOp % 'TrigSMul'
    sveBinInst('ftsmul', 'Ftsmul', 'SimdFloatAluOp', floatTypes, ftsmulCode)
    # FTSSEL
    ftsselCode = fpBinOp % 'TrigSSel'
    sveBinInst('ftssel', 'Ftssel', 'SimdFloatMultOp', floatTypes, ftsselCode)
    # HISTCNT
    histcntCode = '''
        for (unsigned i = 0; i < eCount; i ++) {
            Element destElem = 0;
            if (GpOp_x[i]) {
                const Element& srcElem1 = AA64FpOp1_x[i];
                for (unsigned j = 0; j <= i; j ++) {
                    if (GpOp_x[j]) {
                        const Element& srcElem2 = AA64FpOp2_x[j];
                        if (srcElem1 == srcElem2) {
                            destElem = destElem + 1;
                        }
                    }
                }
            }
            AA64FpDest_x[i] = destElem;
        }
    '''
    sveBinInst('histcnt', 'Histcnt', 'SimdAluOp', ('uint32_t', 'uint64_t'), '',
               predType=PredType.ZERO, customIterCode=histcntCode)
    # HISTSEG
    histsegCode = '''
        uint32_t eltspersegment = 16 / sizeof(Element);

        for (unsigned b = 0; b < eCount / eltspersegment; b ++) {
            for (unsigned s = 0; s < eltspersegment; s++) {
                Element destElem = 0;
                const Element& srcElem1 =
                        AA64FpOp1_x[eltspersegment * b + s];
                for (unsigned i = 0; i < eltspersegment; i ++) {
                    const Element& srcElem2 =
                            AA64FpOp2_x[eltspersegment * b + i];
                    if (srcElem1 == srcElem2) {
                        destElem = destElem + 1;
                    }
                }
                AA64FpDest_x[eltspersegment * b + s] = destElem;
            }
        }
    '''
    sveBinInst('histseg', 'Histseg', 'SimdAluOp', ('uint8_t',), '',
               customIterCode=histsegCode)
    # INCB, INCH, INCW, INCD (scalar)
    incxCode = 'destElem = srcElem1 + (count * imm);'
    sveElemCountInst('inc', 'Inc', 'SimdAluOp', unsignedTypes, incxCode,
            destType = DestType.Scalar, dstIs32b = False)
    # INCH, INCW, INCD (vector)
    sveElemCountInst('inc', 'Incv', 'SimdAluOp', bigUnsignedTypes, incxCode,
            destType = DestType.Vector, dstIs32b = False)
    # INCP (scalar)
    incpCode = 'XDest = XDest + count;'
    svePredCountInst('incp', 'Incp', 'SimdAluOp', unsignedTypes, incpCode,
                     DestType.Scalar, SrcSize.Src64bit)
    # INCP (vector)
    incpvCode = 'destElem = srcElem + count;'
    svePredCountInst('incp', 'Incpv', 'SimdAluOp', unsignedTypes, incpvCode,
                     DestType.Vector)
    # INDEX (immediate, scalar)
    sveIndex(IndexFormat.ImmReg)
    # INDEX (immediates)
    sveIndex(IndexFormat.ImmImm)
    # INDEX (scalar, immediate)
    sveIndex(IndexFormat.RegImm)
    # INDEX (scalars)
    sveIndex(IndexFormat.RegReg)
    # INSR (scalar)
    sveShiftAndInsertInst('insr', 'Insr', 'SimdAluOp', unsignedTypes,
            srcType = SrcRegType.Scalar)
    # INSR (SIMD&FP scalar)
    sveShiftAndInsertInst('insr', 'Insrf', 'SimdAluOp', unsignedTypes,
            srcType = SrcRegType.SimdFpScalar)
    # LASTA (scalar)
    lastaCode = '''
        last++;
        if (last >= eCount) {
            last = 0;
        }
        destElem = AA64FpOp1_x[last];'''
    sveSelectInst('lasta', 'Lasta', 'SimdAluOp', unsignedTypes, lastaCode,
                  isCond = False)
    # LASTA (SIMD&FP scalar)
    sveSelectInst('lasta', 'Lastaf', 'SimdAluOp', unsignedTypes, lastaCode,
                  isCond = False, destType = DstRegType.SimdFpScalar)
    # LASTB (scalar)
    lastbCode = '''
        if (last < 0) {
            last = eCount - 1;
        }
        destElem = AA64FpOp1_x[last];'''
    sveSelectInst('lastb', 'Lastb', 'SimdAluOp', unsignedTypes, lastbCode,
                  isCond = False)
    # LASTB (SIMD&FP scalar)
    sveSelectInst('lastb', 'Lastbf', 'SimdAluOp', unsignedTypes, lastbCode,
                  isCond = False, destType = DstRegType.SimdFpScalar)
    # LSL (immediate, predicated)
    lslCode = '''
            if (srcElem2 == 0) {
                destElem = srcElem1;
            } else if (srcElem2 >= sizeof(Element) * 8) {
                destElem = 0;
            } else {
                destElem = srcElem1 << srcElem2;
            }
    '''
    sveBinImmInst('lsl', 'LslImmPred', 'SimdAluOp', unsignedTypes, lslCode,
                  PredType.MERGE)
    # LSL (immediate, unpredicated)
    sveBinImmInst('lsl', 'LslImmUnpred', 'SimdAluOp', unsignedTypes, lslCode)
    # LSL (vectors)
    sveBinInst('lsl', 'LslPred', 'SimdAluOp', unsignedTypes, lslCode,
               PredType.MERGE, True)
    # LSL (wide elements, predicated)
    sveBinWideElemInst('lsl', 'LslWidePred', 'SimdAluOp', unsignedTypes,
                       lslCode, PredType.MERGE)
    # LSL (wide elements, unpredicated)
    sveBinWideElemInst('lsl', 'LslWideUnpred', 'SimdAluOp', unsignedTypes,
                       lslCode)
    # LSLR
    lslrCode = '''
            if (srcElem1 == 0) {
                destElem = srcElem2;
            } else if (srcElem1 >= sizeof(Element) * 8) {
                destElem = 0;
            } else {
                destElem = srcElem2 << srcElem1;
            }
    '''
    sveBinInst('lslr', 'Lslr', 'SimdAluOp', unsignedTypes, lslrCode,
               PredType.MERGE, True)
    # LSR (immediate, predicated)
    lsrCode = '''
            if (srcElem2 >= sizeof(Element) * 8) {
                destElem = 0;
            } else {
                destElem = srcElem1 >> srcElem2;
            }
    '''
    sveBinImmInst('lsr', 'LsrImmPred', 'SimdAluOp', unsignedTypes, lsrCode,
                  PredType.MERGE)
    # LSR (immediate, unpredicated)
    sveBinImmInst('lsr', 'LsrImmUnpred', 'SimdAluOp', unsignedTypes, lsrCode)
    # LSR (vectors)
    sveBinInst('lsr', 'LsrPred', 'SimdAluOp', unsignedTypes, lsrCode,
               PredType.MERGE, True)
    # LSR (wide elements, predicated)
    sveBinWideElemInst('lsr', 'LsrWidePred', 'SimdAluOp', unsignedTypes,
                        lsrCode, PredType.MERGE)
    # LSR (wide elements, unpredicated)
    sveBinWideElemInst('lsr', 'LsrWideUnpred', 'SimdAluOp', unsignedTypes,
                        lsrCode)
    # LSRR
    lsrrCode = '''
            if (srcElem1 >= sizeof(Element) * 8) {
                destElem = 0;
            } else {
                destElem = srcElem2 >> srcElem1;
            }
    '''
    sveBinInst('lsrr', 'Lsrr', 'SimdAluOp', unsignedTypes, lsrrCode,
               PredType.MERGE, True)
    # MAD
    madCode = 'destElem = srcElem1 + destElem * srcElem2;'
    sveTerInst('mad', 'Mad', 'SimdMultAccOp', signedTypes, madCode,
               PredType.MERGE)
    # MATCH
    sveMatchInst('match', 'Match', 'SimdAluOp', ('uint8_t', 'uint16_t'))
    # MLA (indexed)
    mlaCode = 'destElem += srcElem1 * srcElem2;'
    sveTerIdxInst('mla', '2Mlai', 'SimdMultAccOp', signedTypes, mlaCode)
    # MLA (vectors)
    sveTerInst('mla', 'Mla', 'SimdMultAccOp', signedTypes, mlaCode,
               PredType.MERGE)
    # MLS (indexed)
    mlsCode = 'destElem -= srcElem1 * srcElem2;'
    sveTerIdxInst('mls', '2Mlsi', 'SimdMultAccOp', signedTypes, mlsCode)
    # MLS (vectors)
    sveTerInst('mls', 'Mls', 'SimdMultAccOp', signedTypes, mlsCode,
               PredType.MERGE)
    # MOVPRFX (predicated)
    movCode = 'destElem = srcElem1;'
    sveUnaryInst('movprfx', 'MovprfxPredM', 'SimdMiscOp', unsignedTypes,
                 movCode, PredType.MERGE)
    sveUnaryInst('movprfx', 'MovprfxPredZ', 'SimdMiscOp', unsignedTypes,
                 movCode, PredType.ZERO)
    # MOVPRFX (unpredicated)
    sveUnaryInst('movprfx', 'MovprfxUnpred', 'SimdMiscOp', ('uint64_t',),
                 movCode)
    # MSB
    msbCode = 'destElem = srcElem1 - destElem * srcElem2;'
    sveTerInst('msb', 'Msb', 'SimdMultAccOp', signedTypes, msbCode,
               PredType.MERGE)
    # MUL (immediate)
    mulCode = 'destElem = srcElem1 * srcElem2;'
    sveWideImmInst('mul', 'MulImm', 'SimdMultOp', unsignedTypes, mulCode)
    # MUL (indexed)
    sveBinIdxInst('mul', 'MulIdx', 'SimdMultOp', bigUnsignedTypes, mulCode)
    # MUL (vectors, predicted)
    sveBinInst('mul', 'Mul', 'SimdMultOp', unsignedTypes, mulCode,
               PredType.MERGE, True)
    # MUL (vectors, unpredicated)
    sveBinInst('mul', 'MulUnpred', 'SimdMultOp', unsignedTypes, mulCode)
    # NAND, NANDS
    nandCode = 'destElem = !(srcElem1 & srcElem2);';
    svePredLogicalInst('nand', 'PredNand', 'SimdPredAluOp', ('uint8_t',),
                       nandCode)
    svePredLogicalInst('nands', 'PredNands', 'SimdPredAluOp', ('uint8_t',),
                       nandCode, isFlagSetting=True)
    # NBSL
    nbslCode = 'destElem = ~((destElem & srcElem2) | (srcElem1 & ~srcElem2));'
    sveBinInst('nbsl', 'Nbsl', 'SimdAluOp', ('uint64_t',), nbslCode,
                isDestructive=True)
    # NEG
    negCode = 'destElem = -srcElem1;'
    sveUnaryInst('neg', 'Neg', 'SimdAluOp', signedTypes, negCode,
                 PredType.MERGE)
    # NMATCH
    sveMatchInst('nmatch', 'Nmatch', 'SimdAluOp', ('uint8_t', 'uint16_t'),
                 isNeg=True)
    # NOR
    norCode = 'destElem = !(srcElem1 | srcElem2);';
    svePredLogicalInst('nor', 'PredNor', 'SimdPredAluOp', ('uint8_t',),
                       norCode)
    # NORS
    svePredLogicalInst('nors', 'PredNors', 'SimdPredAluOp', ('uint8_t',),
                       norCode, isFlagSetting=True)
    # NOT (vector)
    notCode = 'destElem = ~srcElem1;'
    sveUnaryInst('not', 'Not', 'SimdAluOp', unsignedTypes, notCode,
                 PredType.MERGE)
    # ORN (predicates)
    ornCode = 'destElem = srcElem1 | !srcElem2;';
    svePredLogicalInst('orn', 'PredOrn', 'SimdPredAluOp', ('uint8_t',),
                       ornCode)
    # ORNS (predicates)
    svePredLogicalInst('orns', 'PredOrns', 'SimdPredAluOp', ('uint8_t',),
                       ornCode, isFlagSetting=True)
    # ORQV
    orvCode = 'destElem |= srcElem1;'
    sveAssocReducInst('orqv', 'Orqv', 'SimdReduceAluOp', unsignedTypes,
                      orvCode, '0', isHvla=True)
    # ORR (immediate)
    orCode = 'destElem = srcElem1 | srcElem2;'
    sveWideImmInst('orr', 'OrrImm', 'SimdAluOp', ('uint64_t',), orCode)
    # ORR (predicates)
    svePredLogicalInst('orr', 'PredOrr', 'SimdPredAluOp', ('uint8_t',), orCode)
    # ORR (vectors, predicated)
    sveBinInst('orr', 'OrrPred', 'SimdAluOp', unsignedTypes, orCode,
               PredType.MERGE, True)
    # ORR (vectors, unpredicated)
    sveBinInst('orr', 'OrrUnpred', 'SimdAluOp', ('uint64_t',), orCode)
    # ORRS (predicates)
    svePredLogicalInst('orrs', 'PredOrrs', 'SimdPredAluOp', ('uint8_t',),
                       orCode, isFlagSetting=True)
    # ORV
    sveAssocReducInst('orv', 'Orv', 'SimdReduceAluOp', unsignedTypes,
                      orvCode, '0')
    # PEXT (predicate pair)
    svePextInst('pext', 'PextPair', 'SimdPredAluOp', unsignedTypes,
                isPair=True)
    # PEXT (predicate)
    svePextInst('pext', 'Pext', 'SimdPredAluOp', unsignedTypes)
    # PFALSE
    pfalseCode = '''
        PDest_ub[0] = 0;
        destPred.reset();
    '''
    svePredUnaryWImplicitSrcInst('pfalse', 'Pfalse', 'SimdPredAluOp',
                                 pfalseCode)
    # PFIRST
    svePFirstInst('pfirst', 'Pfirst', 'SimdPredAluOp')
    # PMOV (to predicate)
    svePredMovToPredInst('pmove', 'PmovPred', 'SimdPredAluOp', unsignedTypes)
    # PMOV (to vector)
    svePredMovToVectorInst('pmove', 'PmovVec', 'SimdPredAluOp', unsignedTypes)
    # PMUL
    exec_output += '''
    __uint128_t poly_mul(uint64_t srcElem1, uint64_t srcElem2)
    {
        __uint128_t destElem = 0;
        __uint128_t extendedElem2 = srcElem2;
        int i;
        for (i=0; i < 64; i++) {
            if (((srcElem1 >> i) & 0x1) == 0x1) {
                destElem ^= (extendedElem2 << i);
            }
        }
        return destElem;
    }'''
    pmulCode = 'destElem = (uint8_t)poly_mul(srcElem1, srcElem2);'
    sveBinInst('pmul', 'Pmul', 'SimdAluOp', ('uint8_t',), pmulCode)
    # PMULLB
    pmullCode = '''
            __uint128_t res = poly_mul(srcElem1, srcElem2);
            destElem = res;
    '''
    sveBinLongInst('pmullb', 'Pmullb', 'SimdAluOp', ('uint8_t','uint32_t'),
                   pmullCode)
    sveBinLongInst('pmullb', 'Pmullb128', 'SimdAluOp', ('uint64_t',),
                   pmullCode)
    # PMULLT
    sveBinLongInst('pmullt', 'Pmullt', 'SimdAluOp', ('uint8_t','uint32_t'),
                    pmullCode, uptTop = True)
    sveBinLongInst('pmullt', 'Pmullt128', 'SimdAluOp', ('uint64_t',),
                    pmullCode, uptTop = True)
    # PNEXT
    svePNextInst('pnext', 'Pnext', 'SimdPredAluOp', unsignedTypes)
    # PSEL
    svePselInst('psel', 'Psel', 'SimdPredAluOp', unsignedTypes)
    # PTEST
    svePredTestInst('ptest', 'Ptest', 'SimdPredAluOp')
    # PTRUE (predicate as counter)
    svePtrueInst('ptrue', 'PtruePng', 'SimdPredAluOp', unsignedTypes, False,
                 isPng=True)
    # PTRUE (predicate)
    svePtrueInst('ptrue', 'Ptrue', 'SimdPredAluOp', unsignedTypes, False)
    # PTRUES
    svePtrueInst('ptrues', 'Ptrues', 'SimdPredAluOp', unsignedTypes, True)
    # PUNPKHI
    sveUnpackInst('punpkhi', 'Punpkhi', 'SimdPredAluOp', unsignedWideSDTypes,
                  unpackHalf = Unpack.High, regType = SrcRegType.Predicate)
    # PUNPKLO
    sveUnpackInst('punpklo', 'Punpklo', 'SimdPredAluOp', unsignedWideSDTypes,
                  unpackHalf = Unpack.Low, regType = SrcRegType.Predicate)
    # RADDHNB
    raddhnCode = '''
            destElem = ((BigElement)srcElem1 + (BigElement)srcElem2 +
                        ((BigElement)1 << (sizeof(Element) * 8 - 1))) >>
                       (sizeof(Element) * 8);
    '''
    sveBinNarrowInst('raddhnb', 'Raddhnb', 'SimdAddOp',
                     smallUnsignedTypes, raddhnCode)
    # RADDHNT
    sveBinNarrowInst('raddhnt', 'Raddhnt', 'SimdAddOp',
                     smallUnsignedTypes, raddhnCode, uptTop = True)
    # RAX1
    rax1Code = 'destElem = srcElem1 ^ ((srcElem2 << 1) | (srcElem2 >> 63));'
    sveBinInst('rax', 'Rax1', 'SimdAluOp', ('uint64_t',), rax1Code)
    # RBIT
    rbitCode = '''
        destElem = reverseBits(srcElem1);'''
    sveUnaryInst('rbit', 'Rbit', 'SimdAluOp', unsignedTypes, rbitCode,
                 predType=PredType.MERGE, srcRegType=SrcRegType.Vector)
    # RDFFR (unpredicated)
    rdffrUnpredCode = '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<uint8_t>(
                xc->tcBase());
        for (unsigned i = 0; i < eCount; i++) {
            PDest_ub[i] = Ffr_ub[i];
        }'''
    svePredUnaryWImplicitSrcInst('rdffr', 'RdffrUnpred', 'SimdPredAluOp',
                                 rdffrUnpredCode)
    # RDFFR (predicated)
    rdffrPredCode = '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<uint8_t>(
                xc->tcBase());
        for (unsigned i = 0; i < eCount; i++) {
            if (GpOp_ub[i]) {
                PDest_ub[i] = Ffr_ub[i];
            } else {
                PDest_ub[i] = false;
            }
        }'''
    svePredUnaryWImplicitSrcInst('rdffr', 'RdffrPred', 'SimdPredAluOp',
                                 rdffrPredCode, PredType.ZERO, False)
    # RDFFRS
    svePredUnaryWImplicitSrcInst('rdffrs', 'RdffrsPred', 'SimdPredAluOp',
                                 rdffrPredCode, PredType.ZERO, True)
    # RDVL
    rdvlCode = sveEnabledCheckCode + '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<uint8_t>(
                xc->tcBase());
        XDest = eCount * (int64_t) imm;
    '''
    rdvlIop = ArmInstObjParams('rdvl', 'SveRdvl', 'RegImmOp', rdvlCode, [])
    header_output += RegImmOpDeclare.subst(rdvlIop)
    decoder_output += RegImmOpConstructor.subst(rdvlIop)
    exec_output += BasicExecute.subst(rdvlIop)
    # REV (predicate)
    sveReverseElementsInst('rev', 'Revp', 'SimdPredAluOp', unsignedTypes,
                           srcType = SrcRegType.Predicate)
    # REV (vector)
    sveReverseElementsInst('rev', 'Revv', 'SimdAluOp', unsignedTypes,
                           srcType = SrcRegType.Vector)
    # REVB
    revCode = '''
        %(revtype)s* srcPtr = reinterpret_cast<%(revtype)s*>(&srcElem1);
        %(revtype)s* dstPtr = reinterpret_cast<%(revtype)s*>(&destElem);
        uint8_t subelements = sizeof(Element) / sizeof(%(revtype)s);
        for(int i = 0; i < subelements; ++i) {
            dstPtr[subelements - i - 1] = srcPtr[i];
        }'''
    sveUnaryInst('revb', 'Revb', 'SimdAluOp',
                 ['uint16_t', 'uint32_t', 'uint64_t'],
                 revCode % {'revtype' : 'uint8_t'}, predType=PredType.MERGE,
                 srcRegType=SrcRegType.Vector, decoder='Generic')
    # REVD
    sveUnaryInst('revd', 'Revd', 'SimdAluOp', ['__uint128_t'],
                 revCode % {'revtype' : 'uint64_t'}, predType=PredType.MERGE,
                 srcRegType=SrcRegType.Vector, decoder='Generic')
    # REVH
    sveUnaryInst('revh', 'Revh', 'SimdAluOp', ['uint32_t', 'uint64_t'],
                 revCode % {'revtype' : 'uint16_t'}, predType=PredType.MERGE,
                 srcRegType=SrcRegType.Vector, decoder='Generic')
    # REVW
    sveUnaryInst('revw', 'Revw', 'SimdAluOp', ['uint64_t'],
                 revCode % {'revtype' : 'uint32_t'}, predType=PredType.MERGE,
                 srcRegType=SrcRegType.Vector, decoder='Generic')
    # RSHRNB
    rshrnCode = '''
            if (imm > sizeof(srcElem1) * 8) {
                destElem = 0;
            } else if (imm) {
                Element rBit = bits(srcElem1, imm - 1);
                destElem = ((srcElem1 >> (imm - 1)) >> 1) + rBit;
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinNarrowInst('rshrnb', 'Rshrnb', 'SimdAluOp',
                     smallUnsignedTypes, rshrnCode, isImm=True)
    # RSHRNT
    sveBinNarrowInst('rshrnt', 'Rshrnt', 'SimdAluOp',
                     smallUnsignedTypes, rshrnCode, isImm=True, uptTop=True)
    # RSUBHNB
    rsubhnCode = '''
            destElem = ((BigElement)srcElem1 - (BigElement)srcElem2 +
                        ((BigElement)1 << (sizeof(Element) * 8 - 1))) >>
                       (sizeof(Element) * 8);
    '''
    sveBinNarrowInst('rsubhnb', 'Rsubhnb', 'SimdAddOp',
                     smallUnsignedTypes, rsubhnCode)
    # RSUBHNT
    sveBinNarrowInst('rsubhnt', 'Rsubhnt', 'SimdAddOp',
                     smallUnsignedTypes, rsubhnCode, uptTop=True)
    # SABA
    abaCode = '''
            destElem += (srcElem1 > srcElem2) ? (srcElem1 - srcElem2) :
                                                (srcElem2 - srcElem1);
    '''
    sveTerInst('saba', 'Saba', 'SimdAluOp', signedTypes, abaCode)
    # SABALB
    abalCode = '''
            destElem += (srcElem1 > srcElem2) ?
                ((BigElement)srcElem1 - (BigElement)srcElem2) :
                ((BigElement)srcElem2 - (BigElement)srcElem1);
    '''
    sveTerLongInst('sabalb', 'Sabalb', 'SimdAluOp', smallSignedTypes,
                    abalCode)
    # SABALT
    sveTerLongInst('sabalt', 'Sabalt', 'SimdAluOp', smallSignedTypes,
                    abalCode, uptTop=True)
    # SABD
    abdCode = '''
            destElem = (srcElem1 > srcElem2) ? (srcElem1 - srcElem2) :
                                               (srcElem2 - srcElem1);
    '''
    sveBinInst('sabd', 'Sabd', 'SimdAluOp', signedTypes, abdCode,
               PredType.MERGE, True)
    # SABDLB
    abdlCode = '''
            destElem = (srcElem1 > srcElem2) ?
                ((BigElement)srcElem1 - (BigElement)srcElem2) :
                ((BigElement)srcElem2 - (BigElement)srcElem1);
    '''
    sveBinLongInst('sabdlb', 'Sabdlb', 'SimdAluOp', smallSignedTypes,
                   abdlCode)
    # SABDLT
    sveBinLongInst('sabdlt', 'Sabdlt', 'SimdAluOp', smallSignedTypes,
                   abdlCode, uptTop = True)
    # SADALP
    adalpCode = "destElem += (BigElement)srcElem1 + (BigElement)srcElem2;"
    sveBinPairLongInst('sadalp', 'Sadalp', 'SimdAluOp', smallSignedTypes,
                       adalpCode)
    # SADDLB
    addlCode = 'destElem = (BigElement)srcElem1 + (BigElement)srcElem2;'
    sveBinLongInst('saddlb', 'Saddlb', 'SimdAddOp', smallSignedTypes,
                   addlCode)
    # SADDLBT
    sveBinLongInst('saddlbt', 'Saddlbt', 'SimdAddOp', smallSignedTypes,
                   addlCode, bt = True)
    # SADDLT
    sveBinLongInst('saddlt', 'Saddlt', 'SimdAddOp', smallSignedTypes,
                   addlCode, uptTop = True)
    # SADDV
    sveWideningAssocReducInst('saddv', 'Saddv', 'SimdReduceAddOp',
            ['int8_t, int64_t', 'int16_t, int64_t', 'int32_t, int64_t'],
            addvCode, '0')
    # SADDWB
    addwCode = 'destElem = srcElem1 + (BigElement)srcElem2;'
    sveBinWidenInst('saddwb', 'Saddwb', 'SimdAddOp', smallSignedTypes,
                    addwCode)
    # SADDWT
    sveBinWidenInst('saddwt', 'Saddwt', 'SimdAddOp', smallSignedTypes,
                    addwCode, uptTop=True)
    # SBCLB
    sveLongCarryInst('sbclb', 'Sbclb', 'SimdAluOp', subtract = True)
    # SBCLT
    sveLongCarryInst('sbclt', 'Sbclt', 'SimdAluOp', uptTop = True,
                     subtract = True)
    # SCLAMP
    sveClampInst('sclamp', 'Sclamp', 'SimdCmpOp', signedTypes)
    # SCVTF
    scvtfCode = fpOp % ('fplibFixedToFP<DElement>('
                        'sext<sizeof(SElement) * 8>(srcElem1), 0,'
                        ' false, FPCRRounding(fpscr), fpscr, fpcr)')
    sveCvtInst('scvtf', 'ScvtfNarrow', 'SimdCvtOp',
               ('uint16_t, uint16_t',
                'uint32_t, uint16_t',
                'uint64_t, uint16_t',
                'uint32_t, uint32_t',
                'uint64_t, uint32_t',
                'uint64_t, uint64_t'),
               scvtfCode, CvtDir.Narrow)
    sveCvtInst('scvtf', 'ScvtfWiden', 'SimdCvtOp', ('uint32_t, uint64_t',),
               scvtfCode, CvtDir.Widen)
    # SDIV
    sdivCode = '''
        constexpr Element ELEM_MIN = std::numeric_limits<Element>::min();
        destElem = (srcElem2 == 0) ? 0 :
            (srcElem2 == -1 && srcElem1 == ELEM_MIN) ? ELEM_MIN :
                (srcElem1 / srcElem2);
    '''
    sveBinInst('sdiv', 'Sdiv', 'SimdDivOp', signedTypes, sdivCode,
               PredType.MERGE, True)
    # SDIVR
    sdivrCode = '''
        constexpr Element ELEM_MIN = std::numeric_limits<Element>::min();
        destElem = (srcElem1 == 0) ? 0 :
            (srcElem1 == -1 && srcElem2 == ELEM_MIN) ? ELEM_MIN :
                (srcElem2 / srcElem1);
    '''
    sveBinInst('sdivr', 'Sdivr', 'SimdDivOp', signedTypes, sdivrCode,
               PredType.MERGE, True)
    # SDOT (2-way, indexed)
    sveDotInst('sdot', 'Sdot2wayi', 'SimdMultAccOp',
               ['int16_t, int16_t, int32_t'],
               isIndexed = True)
    # SDOT (2-way, vectors)
    sveDotInst('sdot', 'Sdot2wayv', 'SimdMultAccOp',
               ['int16_t, int16_t, int32_t'],
               isIndexed = False)
    # SDOT (4-way, indexed)
    sveDotInst('sdot', 'Sdoti', 'SimdMultAccOp',
               ['int8_t, int8_t, int32_t', 'int16_t, int16_t, int64_t'],
               isIndexed = True)
    # SDOT (4-way, vectors)
    sveDotInst('sdot', 'Sdotv', 'SimdMultAccOp',
               ['int8_t, int8_t, int32_t', 'int16_t, int16_t, int64_t'],
               isIndexed = False)
    # SEL (predicates)
    selCode = 'destElem = srcElem1;'
    svePredLogicalInst('sel', 'PredSel', 'SimdPredAluOp', ('uint8_t',),
                       selCode, PredType.SELECT)
    # SEL (vectors)
    sveBinInst('sel', 'Sel', 'SimdAluOp', unsignedTypes, selCode,
               PredType.SELECT, False)
    # SETFFR
    setffrCode = '''
        Ffr_ub[0] = true;
        destPred.set();'''
    svePredWriteFfrInst('setffr', 'Setffr', 'SimdPredAluOp', setffrCode, True)
    # SHADD
    haddCode = '''
            Element carryBit =
                (((unsigned)srcElem1 & 0x1) +
                 ((unsigned)srcElem2 & 0x1)) >> 1;
            // Use division instead of a shift to ensure the sign extension
            // works right. The compiler will figure out if it can be a shift.
            // Mask the inputs so they get truncated correctly.
            destElem = (((srcElem1 & ~(Element)1) / 2) +
                        ((srcElem2 & ~(Element)1) / 2)) + carryBit;
    '''
    sveBinInst('shadd', 'Shadd', 'SimdAddOp', signedTypes, haddCode,
               PredType.MERGE, True)
    # SHRNB
    shrnCode = '''
            if (imm >= sizeof(srcElem1) * 8) {
                destElem = 0;
            } else {
                destElem = srcElem1 >> imm;
            }
    '''
    sveBinNarrowInst('shrnb', 'Shrnb', 'SimdShiftOp',
                     smallUnsignedTypes, shrnCode, isImm=True)
    # SHRNT
    sveBinNarrowInst('shrnt', 'Shrnt', 'SimdShiftOp',
                     smallUnsignedTypes, shrnCode, isImm=True, uptTop=True)
    # SHSUB
    hsubCode = '''
            Element borrowBit =
                (((srcElem1 & 0x1) - (srcElem2 & 0x1)) >> 1) & 0x1;
            // Use division instead of a shift to ensure the sign extension
            // works right. The compiler will figure out if it can be a shift.
            // Mask the inputs so they get truncated correctly.
            destElem = (((srcElem1 & ~(Element)1) / 2) -
                        ((srcElem2 & ~(Element)1) / 2)) - borrowBit;
    '''
    sveBinInst('shsub', 'Shsub', 'SimdAddOp', signedTypes, hsubCode,
               PredType.MERGE, True)
    # SHSUBR
    hsubrCode = '''
            Element borrowBit =
                (((srcElem2 & 0x1) - (srcElem1 & 0x1)) >> 1) & 0x1;
            // Use division instead of a shift to ensure the sign extension
            // works right. The compiler will figure out if it can be a shift.
            // Mask the inputs so they get truncated correctly.
            destElem = (((srcElem2 & ~(Element)1) / 2) -
                        ((srcElem1 & ~(Element)1) / 2)) - borrowBit;
    '''
    sveBinInst('shsubr', 'Shsubr', 'SimdAddOp', signedTypes, hsubrCode,
               PredType.MERGE, True)
    # SLI
    sliCode = '''
            if (srcElem3 >= sizeof(Element) * 8)
                destElem = destElem;
            else
                destElem = (srcElem2 << srcElem3) |
                            (destElem & mask(srcElem3));
    '''
    sveTerImmInst('sli', 'Sli', 'SimdShiftOp', unsignedTypes, sliCode)
    # SMAX (immediate)
    maxCode = 'destElem = (srcElem1 > srcElem2) ? srcElem1 : srcElem2;'
    sveWideImmInst('smax', 'SmaxImm', 'SimdCmpOp', signedTypes, maxCode)
    # SMAX (vectors)
    sveBinInst('smax', 'Smax', 'SimdCmpOp', signedTypes, maxCode,
               PredType.MERGE, True)
    # SMAXP
    sveBinPairInst('smaxp', 'Smaxp', 'SimdCmpOp', signedTypes, maxCode)
    # SMAXQV
    maxvCode = '''
            if (srcElem1 > destElem)
                destElem = srcElem1;
    '''
    sveAssocReducInst('smaxqv', 'Smaxqv', 'SimdReduceAddOp', signedTypes,
                      maxvCode, 'std::numeric_limits<Element>::min()',
                      isHvla = True)
    # SMAXV
    sveAssocReducInst('smaxv', 'Smaxv', 'SimdReduceCmpOp', signedTypes,
                      maxvCode, 'std::numeric_limits<Element>::min()')
    # SMIN (immediate)
    minCode = 'destElem = (srcElem1 < srcElem2) ? srcElem1 : srcElem2;'
    sveWideImmInst('smin', 'SminImm', 'SimdCmpOp', signedTypes, minCode)
    # SMIN (vectors)
    sveBinInst('smin', 'Smin', 'SimdCmpOp', signedTypes, minCode,
               PredType.MERGE, True)
    # SMINP
    sveBinPairInst('sminp', 'Sminp', 'SimdCmpOp', signedTypes, minCode)
    # SMINQV
    minvCode = '''
            if (srcElem1 < destElem)
                destElem = srcElem1;
    '''
    sveAssocReducInst('sminqv', 'Sminqv', 'SimdReduceCmpOp', signedTypes,
                      minvCode, 'std::numeric_limits<Element>::max()',
                      isHvla = True)
    # SMINV
    sveAssocReducInst('sminv', 'Sminv', 'SimdReduceCmpOp', signedTypes,
                      minvCode, 'std::numeric_limits<Element>::max()')
    # SMLALB (indexed)
    mlalCode = "destElem += (BigElement)srcElem1 * (BigElement)srcElem2;"
    sveTerLongInst('smlalb', 'SmlalbIdx', 'SimdMultAccOp',
                   ('int16_t', 'int32_t'), mlalCode, isIndexed=True)
    # SMLALB (vectors)
    sveTerLongInst('smlalb', 'Smlalb', 'SimdMultAccOp',
                   smallSignedTypes, mlalCode)
    # SMLALT (indexed)
    sveTerLongInst('smlalt', 'SmlaltIdx', 'SimdMultAccOp',
                   ('int16_t', 'int32_t'), mlalCode, isIndexed=True,
                   uptTop=True)
    # SMLALT (vectors)
    sveTerLongInst('smlalt', 'Smlalt', 'SimdMultAccOp',
                   smallSignedTypes, mlalCode, uptTop=True)
    # SMLSLB (indexed)
    mlslCode = "destElem -= (BigElement)srcElem1 * (BigElement)srcElem2;"
    sveTerLongInst('smlslb', 'SmlslbIdx', 'SimdMultAccOp',
                   ('int16_t', 'int32_t'), mlslCode, isIndexed=True)
    # SMLSLB (vectors)
    sveTerLongInst('smlslb', 'Smlslb', 'SimdMultAccOp',
                   smallSignedTypes, mlslCode)
    # SMLSLT (indexed)
    sveTerLongInst('smlslt', 'SmlsltIdx', 'SimdMultAccOp',
                   ('int16_t', 'int32_t'), mlslCode, isIndexed=True,
                   uptTop=True)
    # SMLSLT (vectors)
    sveTerLongInst('smlslt', 'Smlslt', 'SimdMultAccOp',
                   smallSignedTypes, mlslCode, uptTop=True)
    # SMMLA (vectors)
    mmlaCode = ('destElem += srcElemA * srcElemB')
    sveMatMulInst('smmla', 'Smmla', 'SimdMatMultAccOp',
                  (('int32_t', 'int8_t', 'int8_t'),),
                  numDestRows=2, numDestCols=2, K=8, elt_mul_op=mmlaCode)
    # SMULH (predicated)
    exec_output += '''
    template <class T>
    T do_mulh(T srcElem1, T srcElem2)
    {
        return ((int64_t)srcElem1 * (int64_t)srcElem2) >> sizeof(T) * 8;
    }

    int64_t do_mulh(int64_t srcElem1, int64_t srcElem2)
    {
        uint64_t x = (uint64_t) llabs(srcElem1);
        uint64_t y = (uint64_t) llabs(srcElem2);

        uint64_t a = x >> 32;
        uint64_t b = x & 0xFFFFFFFF;
        uint64_t c = y >> 32;
        uint64_t d = y & 0xFFFFFFFF;

        uint64_t hi = a * c;
        uint64_t lo = b * d;

        hi += (a * d) >> 32;
        uint64_t tmp = lo;
        lo += ((a * d) & 0xFFFFFFFF) << 32;
        if (lo < tmp)
            hi++;

        hi += (b * c) >> 32;
        tmp = lo;
        lo += ((b * c) & 0xFFFFFFFF) << 32;
        if (lo < tmp)
            hi++;

        uint64_t destElem = hi;
        if ((srcElem1 < 0) ^ (srcElem2 < 0)) {
            uint64_t tmp = lo = ~lo;
            destElem = ~hi;
            if (++lo < tmp)
                destElem++;
        }

        return destElem;
    }

    uint64_t do_mulh(uint64_t srcElem1, uint64_t srcElem2)
    {
        uint64_t x = srcElem1;
        uint64_t y = srcElem2;

        uint64_t a = x >> 32;
        uint64_t b = x & 0xFFFFFFFF;
        uint64_t c = y >> 32;
        uint64_t d = y & 0xFFFFFFFF;

        uint64_t hi = a * c;
        uint64_t lo = b * d;

        hi += (a * d) >> 32;
        uint64_t tmp = lo;
        lo += ((a * d) & 0xFFFFFFFF) << 32;
        if (lo < tmp)
            hi++;

        hi += (b * c) >> 32;
        tmp = lo;
        lo += ((b * c) & 0xFFFFFFFF) << 32;
        if (lo < tmp)
            hi++;

        return hi;
    }'''
    mulhCode = 'destElem = do_mulh(srcElem1, srcElem2);'
    sveBinInst('smulh', 'Smulh', 'SimdMultOp', signedTypes, mulhCode,
               PredType.MERGE, True)
    # SMULH (unpredicated)
    sveBinInst('smulh', 'SmulhUnpred', 'SimdMultOp', signedTypes, mulhCode)
    # SMULLB (indexed)
    mullCode = "destElem = (BigElement)srcElem1 * (BigElement)srcElem2;"
    sveBinLongInst('smullb', 'SmullbIdx', 'SimdMultOp',
                   ('int16_t','int32_t',), mullCode, isIndexed = True)
    # SMULLB (vectors)
    sveBinLongInst('smullb', 'Smullb', 'SimdMultOp',
                   ('int8_t','int16_t','int32_t',), mullCode)
    # SMULLT (indexed)
    sveBinLongInst('smullt', 'SmulltIdx', 'SimdMultOp',
                   ('int16_t','int32_t',), mullCode, isIndexed = True,
                   uptTop = True)
    # SMULLT (vectors)
    sveBinLongInst('smullt', 'Smullt', 'SimdMultOp',
                   ('int8_t','int16_t','int32_t',), mullCode, uptTop = True)
    # SPLICE
    sveSpliceInst('splice', 'SpliceConst', 'SimdAluOp', unsignedTypes)
    sveSpliceInst('splice', 'SpliceDestr', 'SimdAluOp', unsignedTypes)
    # SQABS
    sqabsCode = '''
        if (srcElem1 == (Element)(std::numeric_limits<Element>::min())) {
            destElem = ~srcElem1;
        } else if (srcElem1 < 0) {
            destElem = -srcElem1;
        } else {
            destElem = srcElem1;
        }
    '''
    sveUnaryInst('sqabs', 'Sqabs', 'SimdAluOp', signedTypes, sqabsCode,
                 PredType.MERGE)
    # SQADD (immediate)
    sqaddImmCode =  '''
            if (sizeof(Element) <= 2) {
                int64_t srcElem1_wide = srcElem1;
                int64_t destElem_wide = srcElem1_wide + imm;
                if (destElem_wide > std::numeric_limits<Element>::max()) {
                    destElem = std::numeric_limits<Element>::max();
                } else {
                    destElem = destElem_wide;
                }
            } else {
                destElem = srcElem1 + srcElem2;
                bool negDest = (destElem < 0);
                bool negSrc1 = (srcElem1 < 0);
                bool negSrc2 = (srcElem2 < 0);
                if ((negDest != negSrc1) && (negSrc1 == negSrc2)) {
                    destElem = std::numeric_limits<Element>::min();
                    if (negDest)
                        destElem -= 1;
                }
            }
    '''
    sveWideImmInst('sqadd', 'SqaddImm', 'SimdAddOp', signedTypes, sqaddImmCode)
    # SQADD (vectors, predicated)
    sqaddCode = '''
            destElem = srcElem1 + srcElem2;
            bool negDest = (destElem < 0);
            bool negSrc1 = (srcElem1 < 0);
            bool negSrc2 = (srcElem2 < 0);
            if ((negDest != negSrc1) && (negSrc1 == negSrc2)) {
                destElem = std::numeric_limits<Element>::min();
                if (negDest)
                    destElem -= 1;
            }
    '''
    sveBinInst('sqadd', 'SqaddPred', 'SimdAddOp', signedTypes, sqaddCode,
               predType=PredType.MERGE, isDestructive=True)
    # SQADD (vectors, unpredicated)
    sveBinInst('sqadd', 'Sqadd', 'SimdAddOp', signedTypes, sqaddCode)
    # SQCADD
    sveComplexAddInst('sqcadd','Sqcadd', 'SimdAddOp', signedTypes,
                      predType=PredType.NONE, isInt = True, isSq = True)
    # SQCVTN
    sqcvtnCode = '''
            if (srcElem1 > std::numeric_limits<Element>::max()) {
                destElem = std::numeric_limits<Element>::max();
            } else if (srcElem1 < std::numeric_limits<Element>::min()) {
                destElem = std::numeric_limits<Element>::min();
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinNarrowMultiInst('sqcvtn', 'Sqcvtn', 'SimdCvtOp', ('int16_t',),
                          sqcvtnCode)
    # SQCVTUN
    sqcvtunCode = '''
            if (srcElem1 < 0) {
                destElem = 0;
            } else if ((srcElem1 >> (8 * sizeof(Element))) > 0) {
                destElem = -1;
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinNarrowMultiInst('sqcvtun', 'Sqcvtun', 'SimdCvtOp', ('int16_t',),
                          sqcvtunCode)
    # SQDECB, SQDECH, SQDECW, SQDECD (scalar, 32-bit)
    sqdecCode = '''
        destElem = srcElem1 - (count * imm);
        bool negDest = (destElem < 0);
        bool negSrc = (srcElem1 < 0);
        if (!negDest && negSrc) {
            destElem = static_cast<%(dstType)s>(
                (%(dstType)s)1 << (sizeof(%(dstType)s) * 8 - 1)
                );
        }
    '''
    sveElemCountInst('sqdec', 'Sqdec32', 'SimdAluOp', signedTypes,
            sqdecCode%{'dstType':'int32_t'}, destType = DestType.Scalar,
            dstIs32b = True)
    # SQDECB, SQDECH, SQDECW, SQDECD (scalar, 64-bit)
    sveElemCountInst('sqdec', 'Sqdec', 'SimdAluOp', signedTypes,
            sqdecCode%{'dstType':'int64_t'}, destType = DestType.Scalar,
            dstIs32b = False)
    # SQDECH, SQDECW, SQDECD (vector)
    sveElemCountInst('sqdec', 'Sqdecv', 'SimdAluOp', bigSignedTypes,
            sqdecCode%{'dstType':'Element'}, destType = DestType.Vector,
            dstIs32b = False)
    # SQDECP (scalar, 32-bit)
    sqdecpCode = '''
        destElem = srcElem - count;
        bool negDest = (destElem < 0);
        bool negSrc = (srcElem < 0);
        bool posCount = (count >= 0);
        if ((negDest != negSrc) && (negSrc == posCount)) {
            destElem = std::numeric_limits<%s>::min();
            if (negDest)
                destElem -= 1;
        }
    '''
    sqdecp32Code = '''
        int32_t srcElem = WDest;
        int32_t destElem;''' + (sqdecpCode % 'int32_t') + '''
        if (destElem < 0) {
            XDest = static_cast<uint32_t>(destElem) | ~mask(32);
        } else {
            XDest = destElem;
        }
    '''
    svePredCountInst('sqdecp', 'Sqdecp32', 'SimdAluOp', signedTypes,
                     sqdecp32Code, DestType.Scalar, SrcSize.Src32bit)
    # SQDECP (scalar, 64-bit)
    sqdecp64Code = '''
        int64_t srcElem = XDest;
        int64_t destElem;''' + (sqdecpCode % 'int64_t') + '''
        XDest = destElem;
    '''
    svePredCountInst('sqdecp', 'Sqdecp64', 'SimdAluOp', signedTypes,
                     sqdecp64Code, DestType.Scalar, SrcSize.Src64bit)
    # SQDECP (vector)
    svePredCountInst('sqdecp', 'Sqdecpv', 'SimdAluOp', signedTypes,
                     sqdecpCode % 'Element', DestType.Vector)
    # SQDMLALB (indexed)
    sqdmlalCode = '''
        BigElement midElem = (2 * (int64_t)srcElem1 * (int64_t)srcElem2);
        if (srcElem1 == srcElem2 &&
                srcElem1 == (Element)((Element)1 <<
                    (sizeof(Element) * 8 - 1))) {
            midElem = ~((BigElement)srcElem1 << (sizeof(Element) * 8));
        }
        bool negPreDest = ltz(destElem);
        destElem += midElem;
        bool negDest = ltz(destElem);
        bool negMid = ltz(midElem);
        if (negPreDest == negMid && negMid != negDest) {
            destElem = mask(sizeof(BigElement) * 8 - 1);
            if (negPreDest)
                destElem = ~destElem;
        }
    '''
    sveTerLongInst('sqdmlalb', 'SqdmlalbIdx', 'SimdMultAccOp',
                    ('int16_t', 'int32_t'), sqdmlalCode, isIndexed = True)
    # SQDMLALB (vectors)
    sveTerLongInst('sqdmlalb', 'Sqdmlalb', 'SimdMultAccOp',
                    smallSignedTypes, sqdmlalCode)
    # SQDMLALBT (vectors)
    sveTerLongInst('sqdmlalbt', 'Sqdmlalbt', 'SimdMultAccOp',
                    smallSignedTypes, sqdmlalCode, interleaving = True)
    # SQDMLALT (indexed)
    sveTerLongInst('sqdmlalt', 'SqdmlaltIdx', 'SimdMultAccOp',
                    ('int16_t', 'int32_t'), sqdmlalCode, isIndexed = True,
                    uptTop = True)
    # SQDMLALT (vectors)
    sveTerLongInst('sqdmlalt', 'Sqdmlalt', 'SimdMultAccOp',
                    smallSignedTypes, sqdmlalCode, uptTop = True)
    # SQDMLSLB (indexed)
    sqdmlslCode = '''
        BigElement midElem = (2 * (int64_t)srcElem1 * (int64_t)srcElem2);
        if (srcElem1 == srcElem2 &&
                srcElem1 == (Element)((Element)1 <<
                    (sizeof(Element) * 8 - 1))) {
            midElem = ~((BigElement)srcElem1 << (sizeof(Element) * 8));
        }
        bool negPreDest = ltz(destElem);
        destElem -= midElem;
        bool negDest = ltz(destElem);
        bool posMid = ltz((BigElement)-midElem);
        if (negPreDest == posMid && posMid != negDest) {
            destElem = mask(sizeof(BigElement) * 8 - 1);
            if (negPreDest)
                destElem = ~destElem;
        }
    '''
    sveTerLongInst('sqdmlslb', 'SqdmlslbIdx', 'SimdMultAccOp',
                    ('int16_t', 'int32_t'), sqdmlslCode, isIndexed = True)
    # SQDMLSLB (vectors)
    sveTerLongInst('sqdmlslb', 'Sqdmlslb', 'SimdMultAccOp',
                    smallSignedTypes, sqdmlslCode)
    # SQDMLSLBT (vectors)
    sveTerLongInst('sqdmlslbt', 'Sqdmlslbt', 'SimdMultAccOp',
                    smallSignedTypes, sqdmlslCode, interleaving = True)
    # SQDMLSLT (indexed)
    sveTerLongInst('sqdmlslt', 'SqdmlsltIdx', 'SimdMultAccOp',
                    ('int16_t', 'int32_t'), sqdmlslCode, isIndexed = True,
                    uptTop = True)
    # SQDMLSLT (vectors)
    sveTerLongInst('sqdmlslt', 'Sqdmlslt', 'SimdMultAccOp',
                    smallSignedTypes, sqdmlslCode, uptTop = True)
    # SQDMULH (vectors)
    sqdmulhCode = '''
            destElem = (2 * (__int128_t)srcElem1 * (__int128_t)srcElem2) >>
                       (sizeof(Element) * 8);
            if (srcElem1 == srcElem2 &&
                    srcElem1 == (Element)((Element)1 <<
                        (sizeof(Element) * 8 - 1))) {
                destElem = ~srcElem1;
            }
    '''
    sveBinInst('sqdmulh', 'Sqdmulh', 'SimdMultOp', signedTypes, sqdmulhCode)
    # SQDMULH (indexed)
    sveBinIdxInst('sqdmulh', 'SqdmulhIdx', 'SimdMultOp', bigSignedTypes,
                  sqdmulhCode)
    # SQDMULLB (indexed)
    sqdmullCode = '''
        destElem = (2 * (int64_t)srcElem1 * (int64_t)srcElem2);
        if (srcElem1 == srcElem2 &&
                srcElem1 == (Element)((Element)1 <<
                    (Element)(sizeof(Element) * 8 - 1))) {
            destElem = ~((BigElement)srcElem1 << (sizeof(Element) * 8));
        }
    '''
    sveBinLongInst('sqdmullb', 'SqdmullbIdx', 'SimdMultOp',
                   ('int16_t','int32_t',), sqdmullCode, isIndexed = True)
    # SQDMULLB (vectors)
    sveBinLongInst('sqdmullb', 'Sqdmullb', 'SimdMultOp',
                   ('int8_t','int16_t','int32_t',), sqdmullCode)
    # SQDMULLT (indexed)
    sveBinLongInst('sqdmullt', 'SqdmulltIdx', 'SimdMultOp',
                   ('int16_t','int32_t',), sqdmullCode, isIndexed = True,
                   uptTop = True)
    # SQDMULLT (vectors)
    sveBinLongInst('sqdmullt', 'Sqdmullt', 'SimdMultOp',
                   ('int8_t','int16_t','int32_t',), sqdmullCode, uptTop = True)
    # SQINCB, SQINCH, SQINCW, SQINCD (scalar, 32-bit)
    sqincCode = '''
        destElem = srcElem1 + (count * imm);
        bool negDest = (destElem < 0);
        bool negSrc = (srcElem1 < 0);
        if (negDest && !negSrc) {
            destElem = static_cast<%(dstType)s>(
                (%(dstType)s)1 << (sizeof(%(dstType)s) * 8 - 1)
                );
            destElem -= 1;
        }
    '''
    sveElemCountInst('sqinc', 'Sqinc32', 'SimdAluOp', signedTypes,
                     sqincCode%{'dstType':'int32_t'},
                     destType = DestType.Scalar, dstIs32b = True)
    # SQINCB, SQINCH, SQINCW, SQINCD (scalar, 64-bit)
    sveElemCountInst('sqinc', 'Sqinc', 'SimdAluOp', signedTypes,
                     sqincCode%{'dstType':'int64_t'},
                     destType = DestType.Scalar, dstIs32b = False)
    # SQINCH, SQINCW, SQINCD (vector)
    sveElemCountInst('sqinc', 'Sqincv', 'SimdAluOp', bigSignedTypes,
                     sqincCode%{'dstType':'Element'},
                     destType = DestType.Vector, dstIs32b = False)
    # SQINCP (scalar, 32-bit)
    sqincpCode = '''
        destElem = srcElem + count;
        bool negDest = (destElem < 0);
        bool negSrc = (srcElem < 0);
        bool negCount = (count < 0);
        if ((negDest != negSrc) && (negSrc == negCount)) {
            destElem = std::numeric_limits<%s>::min();
            if (negDest)
                destElem -= 1;
        }
    '''
    sqincp32Code = '''
        int32_t srcElem = WDest;
        int32_t destElem;''' + (sqincpCode % 'int32_t') + '''
        if (destElem < 0) {
            XDest = static_cast<uint32_t>(destElem) | ~mask(32);
        } else {
            XDest = destElem;
        }
    '''
    svePredCountInst('sqincp', 'Sqincp32', 'SimdAluOp', signedTypes,
                     sqincp32Code, DestType.Scalar, SrcSize.Src32bit)
    # SQINCP (scalar, 64-bit)
    sqincp64Code = '''
        int64_t srcElem = XDest;
        int64_t destElem;''' + (sqincpCode % 'int64_t') + '''
        XDest = destElem;
    '''
    svePredCountInst('sqincp', 'Sqincp64', 'SimdAluOp', signedTypes,
                     sqincp64Code, DestType.Scalar, SrcSize.Src64bit)
    # SQINCP (vector)
    svePredCountInst('sqincp', 'Sqincpv', 'SimdAluOp', signedTypes,
                     sqincpCode % 'Element', DestType.Vector)
    # SQNEG
    sqnegCode = '''
        if (srcElem1 == (Element)(std::numeric_limits<Element>::min())) {
            destElem = ~srcElem1;
        } else {
            destElem = -srcElem1;
        }
    '''
    sveUnaryInst('sqneg', 'Sqneg', 'SimdAluOp', signedTypes, sqnegCode,
                 PredType.MERGE)
    # SQRDCMLAH (index)
    sveComplexMulAddInst('sqrdcmlah', 'Sqrdcmlahi', 'SimdMultAccOp',
                         ['int16_t', 'int32_t'],
                         predType = PredType.NONE, isIntHigh = True,
                         isIndexed = True)
    # SQRDCMLAH (vector)
    sveComplexMulAddInst('sqrdcmlah', 'Sqrdcmlahv', 'SimdMultAccOp',
                         signedTypes,
                         predType = PredType.NONE, isIntHigh = True)
    # SQRDMLAH (indexed)
    sqrdmlahCode = '''
          int nbits = sizeof(Element)*8;

          auto val_max = std::numeric_limits<Element>::max();
          auto val_min = std::numeric_limits<Element>::min();
          __int128_t unsat_value = (__int128_t)srcElem1 * (__int128_t)srcElem2;
          unsat_value = unsat_value >> (nbits - 2);
          unsat_value = ((__int128_t)destElem << 1) + unsat_value;
          unsat_value = (unsat_value + 1) >> 1;

          if (unsat_value > val_max) {
              destElem = val_max;
          } else if (unsat_value < val_min) {
              destElem = val_min;
          } else {
              destElem = unsat_value;
          }
    '''
    sveTerIdxInst('sqrdmlah', 'SqrdmlahIdx', 'SimdMultAccOp', bigSignedTypes,
                  sqrdmlahCode)
    # SQRDMLAH (vectors)
    sveTerInst('sqrdmlah', 'Sqrdmlah', 'SimdMultAccOp', signedTypes,
               sqrdmlahCode)
    # SQRDMLSH (indexed)
    sqrdmlshCode = '''
          int nbits = sizeof(Element)*8;

          auto val_max = std::numeric_limits<Element>::max();
          auto val_min = std::numeric_limits<Element>::min();
          __int128_t unsat_value = (__int128_t)srcElem1 * (__int128_t)srcElem2;
          unsat_value = ~unsat_value + 1;
          unsat_value = unsat_value >> (nbits - 2);
          unsat_value = ((__int128_t)destElem << 1) + unsat_value;
          unsat_value = (unsat_value + 1) >> 1;

          if (unsat_value > val_max) {
              destElem = val_max;
          } else if (unsat_value < val_min) {
              destElem = val_min;
          } else {
              destElem = unsat_value;
          }
    '''
    sveTerIdxInst('sqrdmlsh', 'SqrdmlshIdx', 'SimdMultAccOp', bigSignedTypes,
                  sqrdmlshCode)
    # SQRDMLSH (vectors)
    sveTerInst('sqrdmlsh', 'Sqrdmlsh', 'SimdMultAccOp', signedTypes,
               sqrdmlshCode)
    # SQRDMULH (indexed)
    sqrdmulhCode = '''
            destElem = (2 * (__int128_t)srcElem1 * (__int128_t)srcElem2 +
                        ((__int128_t)1 << (sizeof(Element) * 8 - 1))) >>
                       (sizeof(Element) * 8);
            if (srcElem1 == srcElem2 &&
                    srcElem1 == (Element)((Element)1 <<
                        (sizeof(Element) * 8 - 1))) {
                destElem = ~srcElem1;
            }
    '''
    sveBinIdxInst('sqrdmulh', 'SqrdmulhIdx', 'SimdMultOp', bigSignedTypes,
                  sqrdmulhCode)
    # SQRDMULH (vectors)
    sveBinInst('sqrdmulh', 'Sqrdmulh', 'SimdMultOp', signedTypes, sqrdmulhCode)
    # SQRSHL
    sqrshlCode = '''
            Element shiftAmt = srcElem2;
            if (shiftAmt < 0) {
                shiftAmt = -shiftAmt;
                Element rBit = 0;
                if (shiftAmt <= sizeof(Element) * 8)
                    rBit = bits(srcElem1, shiftAmt - 1);
                if (shiftAmt > sizeof(Element) * 8 && srcElem1 < 0)
                    rBit = 1;
                if (shiftAmt >= sizeof(Element) * 8) {
                    shiftAmt = sizeof(Element) * 8 - 1;
                    destElem = 0;
                } else {
                    destElem = (srcElem1 >> shiftAmt);
                }
                // Make sure the right shift sign extended when it should.
                if (srcElem1 < 0 && destElem >= 0) {
                    destElem |= -((Element)1 << (sizeof(Element) * 8 -
                                                 1 - shiftAmt));
                }
                destElem += rBit;
            } else if (shiftAmt > 0) {
                bool sat = false;
                if (shiftAmt >= sizeof(Element) * 8) {
                    if (srcElem1 != 0)
                        sat = true;
                    else
                        destElem = 0;
                } else {
                    if (bits((uint64_t) srcElem1, sizeof(Element) * 8 - 1,
                                sizeof(Element) * 8 - 1 - shiftAmt) !=
                            ((srcElem1 < 0) ? mask(shiftAmt + 1) : 0)) {
                        sat = true;
                    } else {
                        destElem = srcElem1 << shiftAmt;
                    }
                }
                if (sat) {
                    destElem = mask(sizeof(Element) * 8 - 1);
                    if (srcElem1 < 0)
                        destElem = ~destElem;
                }
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinInst('sqrshl', 'Sqrshl', 'SimdShiftOp', signedTypes, sqrshlCode,
               predType=PredType.MERGE, isDestructive=True)
    # SQRSHLR
    sqrshlrCode = '''
            Element shiftAmt = srcElem1;
            if (shiftAmt < 0) {
                shiftAmt = -shiftAmt;
                Element rBit = 0;
                if (shiftAmt <= sizeof(Element) * 8)
                    rBit = bits(srcElem2, shiftAmt - 1);
                if (shiftAmt > sizeof(Element) * 8 && srcElem2 < 0)
                    rBit = 1;
                if (shiftAmt >= sizeof(Element) * 8) {
                    shiftAmt = sizeof(Element) * 8 - 1;
                    destElem = 0;
                } else {
                    destElem = (srcElem2 >> shiftAmt);
                }
                // Make sure the right shift sign extended when it should.
                if (srcElem2 < 0 && destElem >= 0) {
                    destElem |= -((Element)1 << (sizeof(Element) * 8 -
                                                 1 - shiftAmt));
                }
                destElem += rBit;
            } else if (shiftAmt > 0) {
                bool sat = false;
                if (shiftAmt >= sizeof(Element) * 8) {
                    if (srcElem2 != 0)
                        sat = true;
                    else
                        destElem = 0;
                } else {
                    if (bits((uint64_t) srcElem2, sizeof(Element) * 8 - 1,
                                sizeof(Element) * 8 - 1 - shiftAmt) !=
                            ((srcElem2 < 0) ? mask(shiftAmt + 1) : 0)) {
                        sat = true;
                    } else {
                        destElem = srcElem2 << shiftAmt;
                    }
                }
                if (sat) {
                    destElem = mask(sizeof(Element) * 8 - 1);
                    if (srcElem2 < 0)
                        destElem = ~destElem;
                }
            } else {
                destElem = srcElem2;
            }
    '''
    sveBinInst('sqrshlr', 'Sqrshlr', 'SimdShiftOp', signedTypes, sqrshlrCode,
               predType=PredType.MERGE, isDestructive=True)
    # SQRSHRN
    sqrshrnCode = '''
            if (imm > sizeof(srcElem1) * 8) {
                destElem = 0;
            } else if (imm) {
                BigElement mid = (srcElem1 >> (imm - 1));
                uint64_t rBit = mid & 0x1;
                mid >>= 1;
                mid |= -(mid & ((BigElement)1 <<
                            (sizeof(BigElement) * 8 - 1 - imm)));
                mid += rBit;
                if (mid != (Element)mid) {
                    destElem = mask(sizeof(Element) * 8 - 1);
                    if (srcElem1 < 0)
                        destElem = ~destElem;
                } else {
                    destElem = mid;
                }
            } else {
                if (srcElem1 != (Element)srcElem1) {
                    destElem = mask(sizeof(Element) * 8 - 1);
                    if (srcElem1 < 0)
                        destElem = ~destElem;
                } else {
                    destElem = srcElem1;
                }
            }
    '''
    sveBinNarrowMultiInst('sqrshrn', 'Sqrshrn', 'SimdShiftOp', ('int16_t',),
                          sqrshrnCode, hasImm=True)
    # SQRSHRNB
    sveBinNarrowInst('sqrshrnb', 'Sqrshrnb', 'SimdShiftOp',
                     smallSignedTypes, sqrshrnCode, isImm=True)
    # SQRSHRNT
    sveBinNarrowInst('sqrshrnt', 'Sqrshrnt', 'SimdShiftOp',
                     smallSignedTypes, sqrshrnCode, isImm=True, uptTop=True)
    # SQRSHRUN
    sqrshrunCode = '''
            if (imm > sizeof(srcElem1) * 8) {
                destElem = 0;
            } else if (imm) {
                BigElement mid = (srcElem1 >> (imm - 1));
                uint64_t rBit = mid & 0x1;
                mid >>= 1;
                mid |= -(mid & ((BigElement)1 <<
                                (sizeof(BigElement) * 8 - 1 - imm)));
                mid += rBit;
                if (bits(mid, sizeof(BigElement) * 8 - 1,
                              sizeof(Element) * 8) != 0) {
                    if (srcElem1 < 0) {
                        destElem = 0;
                    } else {
                        destElem = mask(sizeof(Element) * 8);
                    }
                } else {
                    destElem = mid;
                }
            } else {
                if (srcElem1 < 0) {
                    destElem = 0;
                } else {
                    destElem = srcElem1;
                }
            }
    '''
    sveBinNarrowMultiInst('sqrshrun', 'Sqrshrun', 'SimdShiftOp', ('int16_t',),
                          sqrshrunCode, hasImm=True)
    # SQRSHRUNB
    sveBinNarrowInst('sqrshrunb', 'Sqrshrunb', 'SimdShiftOp',
                     smallSignedTypes, sqrshrunCode, isImm=True)
    # SQRSHRUNT
    sveBinNarrowInst('sqrshrunt', 'Sqrshrunt', 'SimdShiftOp',
                     smallSignedTypes, sqrshrunCode, isImm=True, uptTop=True)
    # SQSHL (immediate)
    sqshlImmCode = '''
            if (srcElem2 >= sizeof(Element) * 8) {
                if (srcElem1 != 0) {
                    destElem = std::numeric_limits<Element>::min();
                    if (srcElem1 > 0)
                        destElem = ~destElem;
                } else {
                    destElem = 0;
                }
            } else if (srcElem2) {
                destElem = (srcElem1 << srcElem2);
                uint64_t topBits = bits((uint64_t)srcElem1,
                                        sizeof(Element) * 8 - 1,
                                        sizeof(Element) * 8 - 1 - srcElem2);
                if (topBits != 0 && topBits != mask(srcElem2 + 1)) {
                    destElem = std::numeric_limits<Element>::min();
                    if (srcElem1 > 0)
                        destElem = ~destElem;
                }
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinImmInst('sqshl', 'SqshlImm', 'SimdShiftOp', signedTypes,
                  sqshlImmCode, PredType.MERGE)
    # SQSHL (vectors)
    sqshlCode = '''
            Element shiftAmt = srcElem2;
            if (shiftAmt < 0) {
                shiftAmt = -shiftAmt;
                if (shiftAmt >= sizeof(Element) * 8) {
                    shiftAmt = sizeof(Element) * 8 - 1;
                    destElem = 0;
                } else {
                    destElem = (srcElem1 >> shiftAmt);
                }
                // Make sure the right shift sign extended when it should.
                if (srcElem1 < 0 && destElem >= 0) {
                    destElem |= -((Element)1 << (sizeof(Element) * 8 -
                                                 1 - shiftAmt));
                }
            } else if (shiftAmt > 0) {
                bool sat = false;
                if (shiftAmt >= sizeof(Element) * 8) {
                    if (srcElem1 != 0)
                        sat = true;
                    else
                        destElem = 0;
                } else {
                    if (bits((uint64_t) srcElem1, sizeof(Element) * 8 - 1,
                                sizeof(Element) * 8 - 1 - shiftAmt) !=
                            ((srcElem1 < 0) ? mask(shiftAmt + 1) : 0)) {
                        sat = true;
                    } else {
                        destElem = srcElem1 << shiftAmt;
                    }
                }
                if (sat) {
                    destElem = mask(sizeof(Element) * 8 - 1);
                    if (srcElem1 < 0)
                        destElem = ~destElem;
                }
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinInst('sqshl', 'Sqshl', 'SimdShiftOp', signedTypes, sqshlCode,
               predType=PredType.MERGE, isDestructive=True)
    # SQSHLR
    sqshlrCode = '''
            Element shiftAmt = srcElem1;
            if (shiftAmt < 0) {
                shiftAmt = -shiftAmt;
                if (shiftAmt >= sizeof(Element) * 8) {
                    shiftAmt = sizeof(Element) * 8 - 1;
                    destElem = 0;
                } else {
                    destElem = (srcElem2 >> shiftAmt);
                }
                // Make sure the right shift sign extended when it should.
                if (srcElem2 < 0 && destElem >= 0) {
                    destElem |= -((Element)1 << (sizeof(Element) * 8 -
                                                 1 - shiftAmt));
                }
            } else if (shiftAmt > 0) {
                bool sat = false;
                if (shiftAmt >= sizeof(Element) * 8) {
                    if (srcElem2 != 0)
                        sat = true;
                    else
                        destElem = 0;
                } else {
                    if (bits((uint64_t) srcElem2, sizeof(Element) * 8 - 1,
                                sizeof(Element) * 8 - 1 - shiftAmt) !=
                            ((srcElem2 < 0) ? mask(shiftAmt + 1) : 0)) {
                        sat = true;
                    } else {
                        destElem = srcElem2 << shiftAmt;
                    }
                }
                if (sat) {
                    destElem = mask(sizeof(Element) * 8 - 1);
                    if (srcElem2 < 0)
                        destElem = ~destElem;
                }
            } else {
                destElem = srcElem2;
            }
    '''
    sveBinInst('sqshlr', 'Sqshlr', 'SimdShiftOp', signedTypes, sqshlrCode,
               predType=PredType.MERGE, isDestructive=True)
    # SQSHLU
    sqshluCode = '''
            if (srcElem2 >= sizeof(Element) * 8) {
                if (srcElem1 < 0) {
                    destElem = 0;
                } else if (srcElem1 > 0) {
                    destElem = mask(sizeof(Element) * 8);
                } else {
                    destElem = 0;
                }
            } else if (srcElem2) {
                destElem = (srcElem1 << srcElem2);
                uint64_t topBits = bits((uint64_t)srcElem1,
                                        sizeof(Element) * 8 - 1,
                                        sizeof(Element) * 8 - srcElem2);
                if (srcElem1 < 0) {
                    destElem = 0;
                } else if (topBits != 0) {
                    destElem = mask(sizeof(Element) * 8);
                }
            } else {
                if (srcElem1 < 0) {
                    destElem = 0;
                } else {
                    destElem = srcElem1;
                }
            }
    '''
    sveBinImmInst('sqshlu', 'Sqshlu', 'SimdShiftOp', signedTypes, sqshluCode,
                  PredType.MERGE)
    # SQSHRNB
    sqshrnCode = '''
        if (imm > sizeof(srcElem1) * 8) {
            destElem = 0;
        } else if (imm) {
            BigElement mid = ((srcElem1 >> (imm - 1)) >> 1);
            mid |= -(mid & ((BigElement)1 <<
                        (sizeof(BigElement) * 8 - 1 - imm)));
            if (mid != (Element)mid) {
                destElem = mask(sizeof(Element) * 8 - 1);
                if (srcElem1 < 0)
                    destElem = ~destElem;
            } else {
                destElem = mid;
            }
        } else {
            destElem = srcElem1;
        }
    '''
    sveBinNarrowInst('sqshrnb', 'Sqshrnb', 'SimdShiftOp',
                     smallSignedTypes, sqshrnCode, isImm=True)
    # SQSHRNT
    sveBinNarrowInst('sqshrnt', 'Sqshrnt', 'SimdShiftOp',
                     smallSignedTypes, sqshrnCode, isImm=True, uptTop=True)
    # SQSHRUNB
    sqshrunCode = '''
            if (imm > sizeof(srcElem1) * 8) {
                destElem = 0;
            } else if (imm) {
                BigElement mid = ((srcElem1 >> (imm - 1)) >> 1);
                if (bits(mid, sizeof(BigElement) * 8 - 1,
                              sizeof(Element) * 8) != 0) {
                    if (srcElem1 < 0) {
                        destElem = 0;
                    } else {
                        destElem = mask(sizeof(Element) * 8);
                    }
                } else {
                    destElem = mid;
                }
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinNarrowInst('sqshrunb', 'Sqshrunb', 'SimdShiftOp',
                     smallSignedTypes, sqshrunCode, isImm=True)
    # SQSHRUNT
    sveBinNarrowInst('sqshrunt', 'Sqshrunt', 'SimdShiftOp',
                     smallSignedTypes, sqshrunCode, isImm=True, uptTop=True)
    # SQSUB (immediate)
    sqsubImmCode =  '''
            if (sizeof(Element) <= 2) {
                int64_t srcElem1_wide = srcElem1;
                int64_t destElem_wide = srcElem1_wide - imm;
                if (destElem_wide < std::numeric_limits<Element>::min()) {
                    destElem = std::numeric_limits<Element>::min();
                } else {
                    destElem = destElem_wide;
                }
            } else {
                destElem = srcElem1 - srcElem2;
                bool negDest = (destElem < 0);
                bool negSrc1 = (srcElem1 < 0);
                bool posSrc2 = (srcElem2 >= 0);
                if ((negDest != negSrc1) && (negSrc1 == posSrc2)) {
                    destElem = std::numeric_limits<Element>::min();
                    if (negDest)
                        destElem -= 1;
                }
            }
    '''
    sveWideImmInst('sqsub', 'SqsubImm', 'SimdAddOp', signedTypes, sqsubImmCode)
    # SQSUB (vectors, predicated)
    sqsubCode = '''
            destElem = srcElem1 - srcElem2;
            bool negDest = (destElem < 0);
            bool negSrc1 = (srcElem1 < 0);
            bool posSrc2 = (srcElem2 >= 0);
            if ((negDest != negSrc1) && (negSrc1 == posSrc2)) {
                destElem = std::numeric_limits<Element>::min();
                if (negDest)
                    destElem -= 1;
            }
    '''
    sveBinInst('sqsub', 'SqsubPred', 'SimdAddOp', signedTypes, sqsubCode,
               predType=PredType.MERGE, isDestructive=True)
    # SQSUB (vectors, unpredicated)
    sveBinInst('sqsub', 'Sqsub', 'SimdAddOp', signedTypes, sqsubCode)
    # SQSUBR
    sqsubrCode = '''
            destElem = srcElem2 - srcElem1;
            bool negDest = (destElem < 0);
            bool negSrc1 = (srcElem2 < 0);
            bool posSrc2 = (srcElem1 >= 0);
            if ((negDest != negSrc1) && (negSrc1 == posSrc2)) {
                destElem = std::numeric_limits<Element>::min();
                if (negDest)
                    destElem -= 1;
            }
    '''
    sveBinInst('sqsubr', 'SqsubrPred', 'SimdAddOp', signedTypes, sqsubrCode,
               predType=PredType.MERGE, isDestructive=True)
    # SQXTNB
    sqxtnCode = '''
            destElem = srcElem1;
            if ((BigElement)destElem != srcElem1) {
                destElem = mask(sizeof(Element) * 8 - 1);
                if (srcElem1 < 0)
                    destElem = ~destElem;
            }
    '''
    sveUnaryNarrowInst('sqxtnb', 'Sqxtnb', 'SimdAluOp', smallSignedTypes,
                       sqxtnCode)
    # SQXTNT
    sveUnaryNarrowInst('sqxtnt', 'Sqxtnt', 'SimdAluOp', smallSignedTypes,
                       sqxtnCode, uptTop=True)
    # SQXTUNB
    sqxtunCode = '''
            destElem = srcElem1;
            if (srcElem1 < 0 ||
                    ((BigElement)destElem & mask(sizeof(Element) * 8))
                     != srcElem1) {
                destElem = mask(sizeof(Element) * 8);
                if (srcElem1 < 0)
                    destElem = ~destElem;
            }
    '''
    sveUnaryNarrowInst('sqxtunb', 'Sqxtunb', 'SimdAluOp', smallSignedTypes,
                       sqxtunCode)
    # SQXTUNT
    sveUnaryNarrowInst('sqxtunt', 'Sqxtunt', 'SimdAluOp', smallSignedTypes,
                       sqxtunCode, uptTop=True)
    # SRHADD
    rhaddCode = '''
            Element carryBit =
                (((unsigned)srcElem1 & 0x1) +
                 ((unsigned)srcElem2 & 0x1) + 1) >> 1;
            // Use division instead of a shift to ensure the sign extension
            // works right. The compiler will figure out if it can be a shift.
            // Mask the inputs so they get truncated correctly.
            destElem = (((srcElem1 & ~(Element)1) / 2) +
                        ((srcElem2 & ~(Element)1) / 2)) + carryBit;
    '''
    sveBinInst('srhadd', 'Srhadd', 'SimdAddOp', signedTypes, rhaddCode,
               PredType.MERGE, True)
    # SRI
    sriCode = '''
            if (srcElem3 >= sizeof(Element) * 8)
                destElem = destElem;
            else
                destElem = (srcElem2 >> srcElem3) |
                    (destElem & ~mask(sizeof(Element) * 8 - srcElem3));
    '''
    sveTerImmInst('sri', 'Sri', 'SimdShiftOp', unsignedTypes, sriCode)
    # SRSHL
    srshlCode = '''
            Element shiftAmt = srcElem2;
            if (shiftAmt < 0) {
                shiftAmt = -shiftAmt;
                Element rBit = 0;
                if (shiftAmt <= sizeof(Element) * 8)
                    rBit = bits(srcElem1, shiftAmt - 1);
                if (shiftAmt > sizeof(Element) * 8 && ltz(srcElem1))
                    rBit = 1;
                if (shiftAmt >= sizeof(Element) * 8) {
                    shiftAmt = sizeof(Element) * 8 - 1;
                    destElem = 0;
                } else {
                    destElem = (srcElem1 >> shiftAmt);
                }
                // Make sure the right shift sign extended when it should.
                if (ltz(srcElem1) && !ltz(destElem)) {
                    destElem |= -((Element)1 << (sizeof(Element) * 8 -
                                                 1 - shiftAmt));
                }
                destElem += rBit;
            } else if (shiftAmt > 0) {
                if (shiftAmt >= sizeof(Element) * 8) {
                    destElem = 0;
                } else {
                    destElem = srcElem1 << shiftAmt;
                }
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinInst('srshl', 'Srshl', 'SimdShiftOp', signedTypes, srshlCode,
               predType=PredType.MERGE, isDestructive=True)
    # SRSHLR
    srshlrCode = '''
            Element shiftAmt = srcElem1;
            if (shiftAmt < 0) {
                shiftAmt = -shiftAmt;
                Element rBit = 0;
                if (shiftAmt <= sizeof(Element) * 8)
                    rBit = bits(srcElem2, shiftAmt - 1);
                if (shiftAmt > sizeof(Element) * 8 && ltz(srcElem2))
                    rBit = 1;
                if (shiftAmt >= sizeof(Element) * 8) {
                    shiftAmt = sizeof(Element) * 8 - 1;
                    destElem = 0;
                } else {
                    destElem = (srcElem2 >> shiftAmt);
                }
                // Make sure the right shift sign extended when it should.
                if (ltz(srcElem2) && !ltz(destElem)) {
                    destElem |= -((Element)1 << (sizeof(Element) * 8 -
                                                 1 - shiftAmt));
                }
                destElem += rBit;
            } else if (shiftAmt > 0) {
                if (shiftAmt >= sizeof(Element) * 8) {
                    destElem = 0;
                } else {
                    destElem = srcElem2 << shiftAmt;
                }
            } else {
                destElem = srcElem2;
            }
    '''
    sveBinInst('srshlr', 'Srshlr', 'SimdShiftOp', signedTypes, srshlrCode,
               predType=PredType.MERGE, isDestructive=True)
    # SRSHR
    rshrCode = '''
            if (srcElem2 > sizeof(srcElem1) * 8) {
                destElem = 0;
            } else if (srcElem2) {
                Element rBit = bits(srcElem1, srcElem2 - 1);
                destElem = ((srcElem1 >> (srcElem2 - 1)) >> 1) + rBit;
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinImmInst('srshr', 'Srshr', 'SimdShiftOp', signedTypes, rshrCode,
                  PredType.MERGE)
    # SRSRA
    rsraCode = '''
            if (srcElem3 > sizeof(srcElem2) * 8) {
                destElem += 0;
            } else if (srcElem3) {
                Element rBit = bits(srcElem2, srcElem3 - 1);
                destElem += ((srcElem2 >> (srcElem3 - 1)) >> 1) + rBit;
            } else {
                destElem += srcElem2;
            }
    '''
    sveTerImmInst('srsra', 'Srsra', 'SimdShiftOp', signedTypes, rsraCode)
    # SSHLLB
    shllCode = '''
            if (srcElem2 >= sizeof(destElem) * 8) {
                destElem = 0;
            } else {
                destElem = (BigElement)srcElem1 << srcElem2;
            }
    '''
    sveBinLongInst('sshllb', 'Sshllb', 'SimdShiftOp',
                   ('int8_t','int16_t','int32_t',), shllCode, isImm=True)
    # SSHLLT
    sveBinLongInst('sshllt', 'Sshllt', 'SimdShiftOp',
                   ('int8_t','int16_t','int32_t',), shllCode, isImm=True,
                   uptTop = True)
    # SSRA
    sraCode = '''
            Element mid;;
            if (srcElem3 >= sizeof(srcElem2) * 8) {
                mid = ltz(srcElem2) ? -1 : 0;
            } else {
                mid = srcElem2 >> srcElem3;
                if (ltz(srcElem2) && !ltz(mid)) {
                    mid |= -(mid & ((Element)1 <<
                                    (sizeof(Element) * 8 - 1 - srcElem3)));
                }
            }
            destElem += mid;
    '''
    sveTerImmInst('ssra', 'Ssra', 'SimdShiftOp', signedTypes, sraCode)
    # SSUBLB
    sublCode = 'destElem = (BigElement)srcElem1 - (BigElement)srcElem2;'
    sveBinLongInst('ssublb', 'Ssublb', 'SimdAddOp', smallSignedTypes,
                   sublCode)
    # SSUBLBT
    sveBinLongInst('ssublbt', 'Ssublbt', 'SimdAddOp', smallSignedTypes,
                   sublCode, bt = True)
    # SSUBLT
    sveBinLongInst('ssublt', 'Ssublt', 'SimdAddOp', smallSignedTypes,
                   sublCode, uptTop = True)
    # SSUBLTB
    sveBinLongInst('ssubltb', 'Ssubltb', 'SimdAddOp', smallSignedTypes,
                   sublCode, tb = True)
    # SSUBWB
    subwCode = 'destElem = srcElem1 - (BigElement)srcElem2;'
    sveBinWidenInst('ssubwb', 'Ssubwb', 'SimdAddOp', smallSignedTypes,
                    subwCode)
    # SSUBWT
    sveBinWidenInst('ssubwt', 'Ssubwt', 'SimdAddOp', smallSignedTypes,
                    subwCode, uptTop=True)
    # SUB (immediate)
    subCode = 'destElem = srcElem1 - srcElem2;'
    sveWideImmInst('sub', 'SubImm', 'SimdAddOp', unsignedTypes, subCode)
    # SUB (vectors, predicated)
    sveBinInst('sub', 'SubPred', 'SimdAddOp', unsignedTypes, subCode,
               PredType.MERGE, True)
    # SUB (vectors, unpredicated)
    sveBinInst('sub', 'SubUnpred', 'SimdAddOp', unsignedTypes, subCode)
    # SUBHNB
    subhnCode = '''
            destElem = ((BigElement)srcElem1 - (BigElement)srcElem2) >>
                        (sizeof(Element) * 8);
    '''
    sveBinNarrowInst('subhnb', 'Subhnb', 'SimdAddOp',
                     smallUnsignedTypes, subhnCode)
    # SUBHNT
    sveBinNarrowInst('subhnt', 'Subhnt', 'SimdAddOp',
                     smallUnsignedTypes, subhnCode, uptTop=True)
    # SUBR (immediate)
    subrCode = 'destElem = srcElem2 - srcElem1;'
    sveWideImmInst('subr', 'SubrImm', 'SimdAddOp', unsignedTypes, subrCode)
    # SUBR (vectors)
    sveBinInst('subr', 'Subr', 'SimdAddOp', unsignedTypes, subrCode,
               PredType.MERGE, True)
    # SUDOT (indexed)
    sveDotInst('sudot', 'Sudoti', 'SimdMultAccOp',
               ['int8_t, uint8_t, int32_t'],
               isIndexed = True)
    # SUNPKHI
    sveUnpackInst('sunpkhi', 'Sunpkhi', 'SimdAluOp', signedWideSDTypes,
                  unpackHalf = Unpack.High, regType = SrcRegType.Vector)
    # SUNPKLO
    sveUnpackInst('sunpklo', 'Sunpklo', 'SimdAluOp', signedWideSDTypes,
                  unpackHalf = Unpack.Low, regType = SrcRegType.Vector)
    # SUQADD
    suqaddCode = '''
            Element tmp = srcElem1 + srcElem2;
            if (bits(srcElem1, sizeof(Element) * 8 - 1) == 0) {
                if (bits(tmp, sizeof(Element) * 8 - 1) == 1 ||
                        tmp < srcElem2 || tmp < srcElem1) {
                    destElem = (((Element) 1) << (sizeof(Element) * 8 - 1))
                               - 1;
                } else {
                    destElem = tmp;
                }
            } else {
                Element abssrcElem1 = (~srcElem1) + 1;
                if (abssrcElem1 < srcElem2) {
                    // Still check for positive sat., no need to check for
                    // negative sat.
                    if (bits(tmp, sizeof(Element) * 8 - 1) == 1) {
                        destElem = (((Element) 1) << (sizeof(Element) * 8 - 1))
                               - 1;
                    } else {
                        destElem = tmp;
                    }
                } else {
                    destElem = tmp;
                }
            }
    '''
    sveBinInst('suqadd', 'SuqaddPred', 'SimdAddOp', unsignedTypes, suqaddCode,
               predType=PredType.MERGE, isDestructive=True)
    # SXTB
    sxtCode = 'destElem = sext<8 * sizeof(SElement)>(srcElem1);'
    sveWidenUnaryInst('sxtb', 'Sxtb', 'SimdAluOp',
            ['uint8_t, uint16_t', 'uint8_t, uint32_t', 'uint8_t, uint64_t'],
            sxtCode, PredType.MERGE)
    # SXTH
    sveWidenUnaryInst('sxth', 'Sxth', 'SimdAluOp',
            ['uint16_t, uint32_t', 'uint16_t, uint64_t'],
            sxtCode, PredType.MERGE)
    # SXTW
    sveWidenUnaryInst('sxtw', 'Sxtw', 'SimdAluOp',
            ['uint32_t, uint64_t'],
            sxtCode, PredType.MERGE)
    # TBL
    sveTblInst('tbl', 'Tbl', 'SimdAluOp')
    # TBL
    sveTblInst('tbl', 'TblDouble', 'SimdAluOp', doubleTable=True)
    # TBLQ
    sveTblInst('tblq', 'Tblq', 'SimdAluOp', isSeg=True)
    # TBX
    sveTblInst('tbx', 'Tbx', 'SimdAluOp', merging=True)
    # TBXQ
    sveTblInst('tbxq', 'Tbxq', 'SimdAluOp', merging=True, isSeg=True)
    # TRN1, TRN2 (predicates)
    trnPredIterCode = '''
        constexpr unsigned sz = sizeof(Element);
        int s;
        int part = %d;
        ArmISA::VecPredRegContainer tmpPredC;
        auto auxPDest = tmpPredC.as<uint8_t>();
        for (unsigned i = 0; i < eCount / 2; i++) {
            s = 2 * i + part;
            for (unsigned j = 0; j < sz; j++) {
                auxPDest[(2 * i) * sz + j] = POp1_pb[s * sz + j];
                auxPDest[(2 * i + 1) * sz + j] = POp2_pb[s * sz + j];
            }
        }
        for (unsigned i = 0; i < eCount * sz; i++) {
            PDest_pb[i] = auxPDest[i];
        }
    '''
    svePredBinPermInst('trn1', 'Trn1Pred', 'SimdPredAluOp', unsignedTypes,
                       trnPredIterCode % 0)
    svePredBinPermInst('trn2', 'Trn2Pred', 'SimdPredAluOp', unsignedTypes,
                       trnPredIterCode % 1)
    # TRN1, TRN2 (vectors)
    trnIterCode = '''
        // SVE F64MM support requires that there are at least two elements
        // in the vector.
        if (eCount < 2) {
            return std::make_shared<UndefinedInstruction>(machInst, false,
                                                          "%(mnemonic)s");
        }
        int s;
        int part = %(part)d;
        ArmISA::VecRegContainer tmpVecC;
        auto auxDest = tmpVecC.as<Element>();
        const unsigned eltPairsCount = eCount / 2;
        const unsigned eltsInPairsCount = eltPairsCount * 2;
        for (unsigned i = 0; i < eltPairsCount; i++) {
            s = 2 * i + part;
            auxDest[2 * i] = AA64FpOp1_x[s];
            auxDest[2 * i + 1] = AA64FpOp2_x[s];
        }
        // Fill output vector with pairs of elements
        for (unsigned i = 0; i < eltsInPairsCount; i++) {
            AA64FpDest_x[i] = auxDest[i];
        }
        // Fill any trailing non-full pairs with zeros
        for (unsigned i = eltsInPairsCount; i < eCount; i++) {
            AA64FpDest_x[i] = 0;
        }
    '''
    sveBinInst('trn1', 'Trn1', 'SimdAluOp', unsignedTypes, '',
               customIterCode=trnIterCode % dict(mnemonic='trn1', part=0))
    sveBinInst('trn2', 'Trn2', 'SimdAluOp', unsignedTypes, '',
               customIterCode=trnIterCode % dict(mnemonic='trn2', part=1))
    sveBinInst('trn1', 'Trn1Q', 'SimdAluOp', ['__uint128_t'], '',
               customIterCode=trnIterCode % dict(mnemonic='trn1', part=0))
    sveBinInst('trn2', 'Trn2Q', 'SimdAluOp', ['__uint128_t'], '',
               customIterCode=trnIterCode % dict(mnemonic='trn2', part=1))
    # UABA
    sveTerInst('uaba', 'Uaba', 'SimdAluOp', unsignedTypes, abaCode)
    # UABALB
    sveTerLongInst('uabalb', 'Uabalb', 'SimdAluOp', smallUnsignedTypes,
                    abalCode)
    # UABALT
    sveTerLongInst('uabalt', 'Uabalt', 'SimdAluOp', smallUnsignedTypes,
                    abalCode, uptTop=True)
    # UABD
    sveBinInst('uabd', 'Uabd', 'SimdAddOp', unsignedTypes, abdCode,
               PredType.MERGE, True)
    # UABDLB
    sveBinLongInst('uabdlb', 'Uabdlb', 'SimdAluOp', smallUnsignedTypes,
                   abdlCode)
    # UABDLT
    sveBinLongInst('uabdlt', 'Uabdlt', 'SimdAluOp', smallUnsignedTypes,
                   abdlCode, uptTop = True)
    # UADALP
    sveBinPairLongInst('uadalp', 'Uadalp', 'SimdAluOp', smallUnsignedTypes,
                       adalpCode)
    # UADDLB
    sveBinLongInst('uaddlb', 'Uaddlb', 'SimdAddOp', smallUnsignedTypes,
                   addlCode)
    # UADDLT
    sveBinLongInst('uaddlt', 'Uaddlt', 'SimdAddOp', smallUnsignedTypes,
                   addlCode, uptTop = True)
    # UADDV
    sveWideningAssocReducInst('uaddv', 'Uaddv', 'SimdReduceAddOp',
            ['uint8_t, uint64_t', 'uint16_t, uint64_t', 'uint32_t, uint64_t',
             'uint64_t, uint64_t'],
            addvCode, '0')
    # UADDWB
    sveBinWidenInst('uaddwb', 'Uaddwb', 'SimdAddOp', smallUnsignedTypes,
                    addwCode)
    # UADDWT
    sveBinWidenInst('uaddwt', 'Uaddwt', 'SimdAddOp', smallUnsignedTypes,
                    addwCode, uptTop=True)
    # UCLAMP
    sveClampInst('uclamp', 'Uclamp', 'SimdCmpOp', unsignedTypes)
    # UCVTF
    ucvtfCode = fpOp % ('fplibFixedToFP<DElement>(srcElem1, 0, true,'
                        ' FPCRRounding(fpscr), fpscr, fpcr)')
    sveCvtInst('ucvtf', 'UcvtfNarrow', 'SimdCvtOp',
               ('uint16_t, uint16_t',
                'uint32_t, uint16_t',
                'uint64_t, uint16_t',
                'uint32_t, uint32_t',
                'uint64_t, uint32_t',
                'uint64_t, uint64_t'),
               ucvtfCode, CvtDir.Narrow)
    sveCvtInst('ucvtf', 'UcvtfWiden', 'SimdCvtOp', ('uint32_t, uint64_t',),
               ucvtfCode, CvtDir.Widen)
    # UDIV
    udivCode = 'destElem = (srcElem2 == 0) ? 0 : (srcElem1 / srcElem2);'
    sveBinInst('udiv', 'Udiv', 'SimdDivOp', unsignedTypes, udivCode,
               PredType.MERGE, True)
    # UDIVR
    udivrCode = 'destElem = (srcElem1 == 0) ? 0 : (srcElem2 / srcElem1);'
    sveBinInst('udivr', 'Udivr', 'SimdDivOp', unsignedTypes, udivrCode,
               PredType.MERGE, True)
    # UDOT (2-way, indexed)
    sveDotInst('udot', 'Udot2wayi', 'SimdMultAccOp',
               ['uint16_t, uint16_t, uint32_t'], isIndexed = True)
    # UDOT (2-way, vectors)
    sveDotInst('udot', 'Udot2wayv', 'SimdMultAccOp',
               ['uint16_t, uint16_t, uint32_t'], isIndexed = False)
    # UDOT (4-way, indexed)
    sveDotInst('udot', 'Udoti', 'SimdMultAccOp',
               ['uint8_t, uint8_t, uint32_t', 'uint16_t, uint16_t, uint64_t'],
               isIndexed = True)
    # UDOT (4-way, vectors)
    sveDotInst('udot', 'Udotv', 'SimdMultAccOp',
               ['uint8_t, uint8_t, uint32_t', 'uint16_t, uint16_t, uint64_t'],
               isIndexed = False)
    # UHADD
    sveBinInst('uhadd', 'Uhadd', 'SimdAddOp', unsignedTypes, haddCode,
               PredType.MERGE, True)
    # UHSUB
    sveBinInst('uhsub', 'Uhsub', 'SimdAddOp', unsignedTypes, hsubCode,
               PredType.MERGE, True)
    # UHSUBR
    sveBinInst('uhsubr', 'Uhsubr', 'SimdAddOp', unsignedTypes, hsubrCode,
               PredType.MERGE, True)
    # UMAX (immediate)
    sveWideImmInst('umax', 'UmaxImm', 'SimdCmpOp', unsignedTypes, maxCode)
    # UMAX (vectors)
    sveBinInst('umax', 'Umax', 'SimdCmpOp', unsignedTypes, maxCode,
               PredType.MERGE, True)
    # UMAXP
    sveBinPairInst('umaxp', 'Umaxp', 'SimdCmpOp', unsignedTypes, maxCode)
    # UMAXQV
    sveAssocReducInst('umaxqv', 'Umaxqv', 'SimdReduceCmpOp', unsignedTypes,
                      maxvCode, 'std::numeric_limits<Element>::min()',
                      isHvla = True)
    # UMAXV
    sveAssocReducInst('umaxv', 'Umaxv', 'SimdReduceCmpOp', unsignedTypes,
                      maxvCode, 'std::numeric_limits<Element>::min()')
    # UMIN (immediate)
    sveWideImmInst('umin', 'UminImm', 'SimdCmpOp', unsignedTypes, minCode)
    # UMIN (vectors)
    sveBinInst('umin', 'Umin', 'SimdCmpOp', unsignedTypes, minCode,
               PredType.MERGE, True)
    # UMINP
    sveBinPairInst('uminp', 'Uminp', 'SimdCmpOp', unsignedTypes, minCode)
    # UMINQV
    sveAssocReducInst('uminqv', 'Uminqv', 'SimdReduceCmpOp', unsignedTypes,
                      minvCode, 'std::numeric_limits<Element>::max()',
                      isHvla = True)
    # UMINV
    sveAssocReducInst('uminv', 'Uminv', 'SimdReduceCmpOp', unsignedTypes,
                      minvCode, 'std::numeric_limits<Element>::max()')
    # UMLALB (indexed)
    sveTerLongInst('umlalb', 'UmlalbIdx', 'SimdMultAccOp',
                   ('uint16_t', 'uint32_t'), mlalCode, isIndexed=True)
    # UMLALB (vectors)
    sveTerLongInst('umlalb', 'Umlalb', 'SimdMultAccOp',
                   smallUnsignedTypes, mlalCode)
    # UMLALT (indexed)
    sveTerLongInst('umlalt', 'UmlaltIdx', 'SimdMultAccOp',
                   ('uint16_t', 'uint32_t'), mlalCode, isIndexed=True,
                   uptTop=True)
    # UMLALT (vectors)
    sveTerLongInst('umlalt', 'Umlalt', 'SimdMultAccOp',
                   smallUnsignedTypes, mlalCode, uptTop=True)
    # UMLSLB (indexed)
    sveTerLongInst('umlslb', 'UmlslbIdx', 'SimdMultAccOp',
                   ('uint16_t', 'uint32_t'), mlslCode, isIndexed=True)
    # UMLSLB (vectors)
    sveTerLongInst('umlslb', 'Umlslb', 'SimdMultAccOp',
                   smallUnsignedTypes, mlslCode)
    # UMLSLT (indexed)
    sveTerLongInst('umlslt', 'UmlsltIdx', 'SimdMultAccOp',
                   ('uint16_t', 'uint32_t'), mlslCode, isIndexed=True,
                   uptTop=True)
    # UMLSLT (vectors)
    sveTerLongInst('umlslt', 'Umlslt', 'SimdMultAccOp',
                   smallUnsignedTypes, mlslCode, uptTop=True)
    # UMMLA (vectors)
    sveMatMulInst('ummla', 'Ummla', 'SimdMatMultAccOp',
                  (('uint32_t', 'uint8_t', 'uint8_t'),),
                  numDestRows=2, numDestCols=2, K=8, elt_mul_op=mmlaCode)
    # UMULH (predicated)
    sveBinInst('umulh', 'Umulh', 'SimdMultOp', unsignedTypes, mulhCode,
               PredType.MERGE, True)
    # UMULH (unpredicated)
    sveBinInst('umulh', 'UmulhUnpred', 'SimdMultOp', unsignedTypes, mulhCode)
    # UMULLB (indexed)
    sveBinLongInst('umullb', 'UmullbIdx', 'SimdMultOp',
                   ('uint16_t','uint32_t',), mullCode, isIndexed = True)
    # UMULLB (vectors)
    sveBinLongInst('umullb', 'Umullb', 'SimdMultOp',
                   ('uint8_t','uint16_t','uint32_t',), mullCode)
    # UMULLT (indexed)
    sveBinLongInst('umullt', 'UmulltIdx', 'SimdMultOp',
                   ('uint16_t','uint32_t',), mullCode, isIndexed = True,
                   uptTop = True)
    # UMULLT (vectors)
    sveBinLongInst('umullt', 'Umullt', 'SimdMultOp',
                   ('uint8_t','uint16_t','uint32_t',), mullCode,
                    uptTop = True)
    # UQADD (immediate)
    uqaddCode = '''
            destElem = srcElem1 + srcElem2;
            if (destElem < srcElem1 || destElem < srcElem2) {
                destElem = (Element)(-1);
            }
    '''
    sveWideImmInst('uqadd', 'UqaddImm', 'SimdAddOp', unsignedTypes, uqaddCode)
    # UQADD (vectors, predicated)
    sveBinInst('uqadd', 'UqaddPred', 'SimdAddOp', unsignedTypes, uqaddCode,
               predType=PredType.MERGE, isDestructive=True)
    # UQADD (vectors, unpredicated)
    sveBinInst('uqadd', 'Uqadd', 'SimdAddOp', unsignedTypes, uqaddCode)
    # UQCVTN
    uqcvtnCode = '''
            if (srcElem1 > std::numeric_limits<Element>::max()) {
                destElem = std::numeric_limits<Element>::max();
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinNarrowMultiInst('uqcvtn', 'Uqcvtn', 'SimdCvtOp', ('uint16_t',),
                          uqcvtnCode)
    # UQDECB, UQDECH, UQDECW, UQDECD (scalar, 32-bit)
    uqdecCode = '''
        destElem = srcElem1 - (imm * count);
        if (destElem > srcElem1) {
            destElem = 0;
        }
    '''
    sveElemCountInst('uqdec', 'Uqdec32', 'SimdAluOp', unsignedTypes,
                     uqdecCode, destType = DestType.Scalar, dstIs32b = True)
    # UQDECB, UQDECH, UQDECW, UQDECD (scalar, 64-bit)
    sveElemCountInst('uqdec', 'Uqdec', 'SimdAluOp', unsignedTypes,
                     uqdecCode, destType = DestType.Scalar, dstIs32b = False)
    # UQDECH, UQDECW, UQDECD (vector)
    sveElemCountInst('uqdec', 'Uqdecv', 'SimdAluOp', bigUnsignedTypes,
                     uqdecCode, destType = DestType.Vector, dstIs32b = False)
    # UQDECP (scalar, 32-bit)
    uqdecpCode = '''
        destElem = srcElem - count;
        if (destElem > srcElem) {
            destElem = 0;
        }
    '''
    uqdecp32Code = '''
        uint32_t srcElem = WDest;
        uint32_t destElem;''' + uqdecpCode + '''
        WDest = destElem;
    '''
    svePredCountInst('uqdecp', 'Uqdecp32', 'SimdAluOp', unsignedTypes,
                     uqdecp32Code, DestType.Scalar, SrcSize.Src32bit)
    # UQDECP (scalar, 64-bit)
    uqdecp64Code = '''
        uint64_t srcElem = XDest;
        uint64_t destElem;''' + uqdecpCode + '''
        XDest = destElem;
    '''
    svePredCountInst('uqdecp', 'Uqdecp64', 'SimdAluOp', unsignedTypes,
                     uqdecp64Code, DestType.Scalar, SrcSize.Src64bit)
    # UQDECP (vector)
    svePredCountInst('uqdecp', 'Uqdecpv', 'SimdAluOp', unsignedTypes,
                     uqdecpCode, DestType.Vector)
    # UQINCB, UQINCH, UQINCW, UQINCD (scalar, 32-bit)
    uqincCode = '''
        destElem = srcElem1 + (imm * count);
        if (destElem < srcElem1 || destElem < (imm * count)) {
            destElem = static_cast<%(destType)s>(-1);
        }
    '''
    sveElemCountInst('uqinc', 'Uqinc32', 'SimdAluOp', unsignedTypes,
                     uqincCode%{'destType': 'uint32_t'},
                     destType = DestType.Scalar, dstIs32b = True)
    # UQINCB, UQINCH, UQINCW, UQINCD (scalar, 64-bit)
    sveElemCountInst('uqinc', 'Uqinc', 'SimdAluOp', unsignedTypes,
                     uqincCode%{'destType': 'uint64_t'},
                     destType = DestType.Scalar, dstIs32b = False)
    # UQINCH, UQINCW, UQINCD (vector)
    sveElemCountInst('uqinc', 'Uqincv', 'SimdAluOp', bigUnsignedTypes,
                     uqincCode%{'destType': 'Element'},
                     destType = DestType.Vector, dstIs32b = False)
    # UQINCP (scalar, 32-bit)
    uqincpCode = '''
        destElem = srcElem + count;
        if (destElem < srcElem || destElem < count) {
            destElem = std::numeric_limits<%s>::max();
        }
    '''
    uqincp32Code = '''
        uint32_t srcElem = WDest;
        uint32_t destElem;''' + (uqincpCode % 'uint32_t') + '''
        XDest = destElem;
    '''
    svePredCountInst('uqincp', 'Uqincp32', 'SimdAluOp', unsignedTypes,
                     uqincp32Code, DestType.Scalar, SrcSize.Src32bit)
    # UQINCP (scalar, 64-bit)
    uqincp64Code = '''
        uint64_t srcElem = XDest;
        uint64_t destElem;''' + (uqincpCode % 'uint64_t') + '''
        XDest = destElem;
    '''
    svePredCountInst('uqincp', 'Uqincp64', 'SimdAluOp', unsignedTypes,
                     uqincp64Code, DestType.Scalar, SrcSize.Src64bit)
    # UQINCP (vector)
    svePredCountInst('uqincp', 'Uqincpv', 'SimdAluOp', unsignedTypes,
                     uqincpCode % 'Element', DestType.Vector)
    # UQRSHL
    uqrshlCode = '''
            auto shiftAmt =
                static_cast<std::make_signed_t<Element> >(srcElem2);
            if (shiftAmt < 0) {
                shiftAmt = -shiftAmt;
                Element rBit = 0;
                if (shiftAmt <= sizeof(Element) * 8)
                    rBit = bits(srcElem1, shiftAmt - 1);
                if (shiftAmt >= sizeof(Element) * 8) {
                    shiftAmt = sizeof(Element) * 8 - 1;
                    destElem = 0;
                } else {
                    destElem = (srcElem1 >> shiftAmt);
                }
                destElem += rBit;
            } else if (shiftAmt > 0) {
                if (shiftAmt >= sizeof(Element) * 8) {
                    if (srcElem1 != 0) {
                        destElem = mask(sizeof(Element) * 8);
                    } else {
                        destElem = 0;
                    }
                } else {
                    if (shiftAmt != 0 &&
                            bits(srcElem1, sizeof(Element) * 8 - 1,
                                           sizeof(Element) * 8 - shiftAmt)) {
                        destElem = mask(sizeof(Element) * 8);
                    } else {
                        destElem = srcElem1 << shiftAmt;
                    }
                }
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinInst('uqrshl', 'Uqrshl', 'SimdShiftOp', unsignedTypes, uqrshlCode,
               predType=PredType.MERGE, isDestructive=True)
    # UQRSHLR
    uqrshlrCode = '''
            auto shiftAmt =
                static_cast<std::make_signed_t<Element> >(srcElem1);
            if (shiftAmt < 0) {
                shiftAmt = -shiftAmt;
                Element rBit = 0;
                if (shiftAmt <= sizeof(Element) * 8)
                    rBit = bits(srcElem2, shiftAmt - 1);
                if (shiftAmt >= sizeof(Element) * 8) {
                    shiftAmt = sizeof(Element) * 8 - 1;
                    destElem = 0;
                } else {
                    destElem = (srcElem2 >> shiftAmt);
                }
                destElem += rBit;
            } else if (shiftAmt > 0) {
                if (shiftAmt >= sizeof(Element) * 8) {
                    if (srcElem2 != 0) {
                        destElem = mask(sizeof(Element) * 8);
                    } else {
                        destElem = 0;
                    }
                } else {
                    if (shiftAmt != 0 &&
                            bits(srcElem2, sizeof(Element) * 8 - 1,
                                           sizeof(Element) * 8 - shiftAmt)) {
                        destElem = mask(sizeof(Element) * 8);
                    } else {
                        destElem = srcElem2 << shiftAmt;
                    }
                }
            } else {
                destElem = srcElem2;
            }
    '''
    sveBinInst('uqrshlr', 'Uqrshlr', 'SimdShiftOp', unsignedTypes, uqrshlrCode,
               predType=PredType.MERGE, isDestructive=True)
    # UQRSHRN
    uqrshrnCode = '''
            if (imm > sizeof(srcElem1) * 8) {
                destElem = 0;
            } else if (imm) {
                BigElement mid = (srcElem1 >> (imm - 1));
                uint64_t rBit = mid & 0x1;
                mid >>= 1;
                mid += rBit;
                if (mid != (Element)mid) {
                    destElem = mask(sizeof(Element) * 8);
                } else {
                    destElem = mid;
                }
            } else {
                if (srcElem1 != (Element)srcElem1) {
                    destElem = mask(sizeof(Element) * 8 - 1);
                } else {
                    destElem = srcElem1;
                }
            }
    '''
    sveBinNarrowMultiInst('uqrshrn', 'Uqrshrn', 'SimdShiftOp', ('uint16_t',),
                          uqrshrnCode, hasImm=True)
    # UQRSHRNB
    sveBinNarrowInst('uqrshrnb', 'Uqrshrnb', 'SimdShiftOp',
                     smallUnsignedTypes, uqrshrnCode, isImm=True)
    # UQRSHRNT
    sveBinNarrowInst('uqrshrnt', 'Uqrshrnt', 'SimdShiftOp',
                     smallUnsignedTypes, uqrshrnCode, isImm=True, uptTop=True)
    # UQSHL (immediate)
    uqshlCode = '''
            if (srcElem2 >= sizeof(Element) * 8) {
                if (srcElem1 != 0) {
                    destElem = mask(sizeof(Element) * 8);
                } else {
                    destElem = 0;
                }
            } else if (srcElem2) {
                destElem = (srcElem1 << srcElem2);
                uint64_t topBits = bits((uint64_t)srcElem1,
                                        sizeof(Element) * 8 - 1,
                                        sizeof(Element) * 8 - srcElem2);
                if (topBits != 0) {
                    destElem = mask(sizeof(Element) * 8);
                }
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinImmInst('uqshl', 'UqshlImm', 'SimdShiftOp', unsignedTypes, uqshlCode,
                  PredType.MERGE)
    # UQSHL (vectors)
    uqshlCode = '''
            auto shiftAmt =
                static_cast<std::make_signed_t<Element> >(srcElem2);
            if (shiftAmt < 0) {
                shiftAmt = -shiftAmt;
                if (shiftAmt >= sizeof(Element) * 8) {
                    shiftAmt = sizeof(Element) * 8 - 1;
                    destElem = 0;
                } else {
                    destElem = (srcElem1 >> shiftAmt);
                }
            } else if (shiftAmt > 0) {
                if (shiftAmt >= sizeof(Element) * 8) {
                    if (srcElem1 != 0) {
                        destElem = mask(sizeof(Element) * 8);
                    } else {
                        destElem = 0;
                    }
                } else {
                    if (bits(srcElem1, sizeof(Element) * 8 - 1,
                                sizeof(Element) * 8 - shiftAmt)) {
                        destElem = mask(sizeof(Element) * 8);
                    } else {
                        destElem = srcElem1 << shiftAmt;
                    }
                }
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinInst('uqshl', 'Uqshl', 'SimdShiftOp', unsignedTypes, uqshlCode,
               predType=PredType.MERGE, isDestructive=True)
    # UQSHLR
    uqshlrCode = '''
            auto shiftAmt =
                static_cast<std::make_signed_t<Element> >(srcElem1);
            if (shiftAmt < 0) {
                shiftAmt = -shiftAmt;
                if (shiftAmt >= sizeof(Element) * 8) {
                    shiftAmt = sizeof(Element) * 8 - 1;
                    destElem = 0;
                } else {
                    destElem = (srcElem2 >> shiftAmt);
                }
            } else if (shiftAmt > 0) {
                if (shiftAmt >= sizeof(Element) * 8) {
                    if (srcElem2 != 0) {
                        destElem = mask(sizeof(Element) * 8);
                    } else {
                        destElem = 0;
                    }
                } else {
                    if (bits(srcElem2, sizeof(Element) * 8 - 1,
                                sizeof(Element) * 8 - shiftAmt)) {
                        destElem = mask(sizeof(Element) * 8);
                    } else {
                        destElem = srcElem2 << shiftAmt;
                    }
                }
            } else {
                destElem = srcElem2;
            }
    '''
    sveBinInst('uqshlr', 'Uqshlr', 'SimdShiftOp', unsignedTypes, uqshlrCode,
               predType=PredType.MERGE, isDestructive=True)
    # UQSHRNB
    uqshrnCode = '''
            if (imm > sizeof(srcElem1) * 8) {
                destElem = 0;
            } else if (imm) {
                BigElement mid = ((srcElem1 >> (imm - 1)) >> 1);
                if (mid != (Element)mid) {
                    destElem = mask(sizeof(Element) * 8);
                } else {
                    destElem = mid;
                }
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinNarrowInst('uqshrnb', 'Uqshrnb', 'SimdShiftOp',
                     smallUnsignedTypes, uqshrnCode, isImm=True)
    # UQSHRNT
    sveBinNarrowInst('uqshrnt', 'Uqshrnt', 'SimdShiftOp',
                     smallUnsignedTypes, uqshrnCode, isImm=True, uptTop=True)
    # UQSUB (immediate)
    uqsubCode = '''
            destElem = srcElem1 - srcElem2;
            if (destElem > srcElem1) {
                destElem = 0;
            }
    '''
    sveWideImmInst('uqsub', 'UqsubImm', 'SimdAddOp', unsignedTypes, uqsubCode)
    # UQSUB (vectors, predicated)
    sveBinInst('uqsub', 'UqsubPred', 'SimdAddOp', unsignedTypes, uqsubCode,
               predType=PredType.MERGE, isDestructive=True)
    # UQSUB (vectors, unpredicated)
    sveBinInst('uqsub', 'Uqsub', 'SimdAddOp', unsignedTypes, uqsubCode)
    # UQSUBR
    uqsubrCode = '''
            destElem = srcElem2 - srcElem1;
            if (destElem > srcElem2) {
                destElem = 0;
            }
    '''
    sveBinInst('uqsubr', 'UqsubrPred', 'SimdAddOp', unsignedTypes, uqsubrCode,
               predType=PredType.MERGE, isDestructive=True)
    # UQXTNB
    uqxtnCode = '''
            destElem = srcElem1;
            if ((BigElement)destElem != srcElem1) {
                destElem = mask(sizeof(Element) * 8);
            }
    '''
    sveUnaryNarrowInst('uqxtnb', 'Uqxtnb', 'SimdAluOp', smallUnsignedTypes,
                       uqxtnCode)
    # UQXTNT
    sveUnaryNarrowInst('uqxtnt', 'Uqxtnt', 'SimdAluOp', smallUnsignedTypes,
                       uqxtnCode, uptTop=True)
    # URECPE
    urecpeCode = "destElem = unsignedRecipEstimate(srcElem1);"
    sveUnaryInst("urecpe", "Urecpe", "SimdAluOp", ("uint32_t",),
                 urecpeCode, predType=PredType.MERGE)
    # URHADD
    sveBinInst('urhadd', 'Urhadd', 'SimdAddOp', unsignedTypes, rhaddCode,
               PredType.MERGE, True)
    # URSHL
    urshlCode = '''
            auto shiftAmt =
                static_cast<std::make_signed_t<Element> >(srcElem2);
            if (shiftAmt < 0) {
                shiftAmt = -shiftAmt;
                Element rBit = 0;
                if (shiftAmt <= sizeof(Element) * 8)
                    rBit = bits(srcElem1, shiftAmt - 1);
                if (shiftAmt > sizeof(Element) * 8 && ltz(srcElem1))
                    rBit = 1;
                if (shiftAmt >= sizeof(Element) * 8) {
                    shiftAmt = sizeof(Element) * 8 - 1;
                    destElem = 0;
                } else {
                    destElem = (srcElem1 >> shiftAmt);
                }
                // Make sure the right shift sign extended when it should.
                if (ltz(srcElem1) && !ltz(destElem)) {
                    destElem |= -((Element)1 << (sizeof(Element) * 8 -
                                                 1 - shiftAmt));
                }
                destElem += rBit;
            } else if (shiftAmt > 0) {
                if (shiftAmt >= sizeof(Element) * 8) {
                    destElem = 0;
                } else {
                    destElem = srcElem1 << shiftAmt;
                }
            } else {
                destElem = srcElem1;
            }
    '''
    sveBinInst('urshl', 'Urshl', 'SimdShiftOp', unsignedTypes, urshlCode,
               predType=PredType.MERGE, isDestructive=True)
    # URSHLR
    urshlrCode = '''
            auto shiftAmt =
                static_cast<std::make_signed_t<Element> >(srcElem1);
            if (shiftAmt < 0) {
                shiftAmt = -shiftAmt;
                Element rBit = 0;
                if (shiftAmt <= sizeof(Element) * 8)
                    rBit = bits(srcElem2, shiftAmt - 1);
                if (shiftAmt > sizeof(Element) * 8 && ltz(srcElem2))
                    rBit = 1;
                if (shiftAmt >= sizeof(Element) * 8) {
                    shiftAmt = sizeof(Element) * 8 - 1;
                    destElem = 0;
                } else {
                    destElem = (srcElem2 >> shiftAmt);
                }
                // Make sure the right shift sign extended when it should.
                if (ltz(srcElem2) && !ltz(destElem)) {
                    destElem |= -((Element)1 << (sizeof(Element) * 8 -
                                                 1 - shiftAmt));
                }
                destElem += rBit;
            } else if (shiftAmt > 0) {
                if (shiftAmt >= sizeof(Element) * 8) {
                    destElem = 0;
                } else {
                    destElem = srcElem2 << shiftAmt;
                }
            } else {
                destElem = srcElem2;
            }
    '''
    sveBinInst('urshlr', 'Urshlr', 'SimdShiftOp', unsignedTypes, urshlrCode,
               predType=PredType.MERGE, isDestructive=True)
    # URSHR
    sveBinImmInst('urshr', 'Urshr', 'SimdShiftOp', unsignedTypes, rshrCode,
                  PredType.MERGE)
    # URSQRTE
    ursqrteCode = "destElem = unsignedRSqrtEstimate(srcElem1);"
    sveUnaryInst("ursqrte", "Ursqrte", "SimdSqrtOp", ("uint32_t",),
                 ursqrteCode, predType=PredType.MERGE)
    # URSRA
    sveTerImmInst('ursra', 'Ursra', 'SimdShiftOp', unsignedTypes, rsraCode)
    # USDOT (indexed)
    sveDotInst('usdot', 'Usdoti', 'SimdMultAccOp',
               ['uint8_t, int8_t, int32_t'],
               isIndexed = True)
    # USDOT (vectors)
    sveDotInst('usdot', 'Usdotv', 'SimdMultAccOp',
               ['uint8_t, int8_t, int32_t'],
               isIndexed = False)
    # USHLLB
    sveBinLongInst('ushllb', 'Ushllb', 'SimdShiftOp',
                   ('uint8_t','uint16_t','uint32_t',), shllCode, isImm=True)
    # USHLLT
    sveBinLongInst('ushllt', 'Ushllt', 'SimdShiftOp',
                   ('uint8_t','uint16_t','uint32_t',), shllCode, isImm=True,
                   uptTop = True)
    # USMMLA (vectors)
    sveMatMulInst('usmmla', 'Usmmla', 'SimdMatMultAccOp',
                  (('int32_t', 'uint8_t', 'int8_t'),),
                  numDestRows=2, numDestCols=2, K=8, elt_mul_op=mmlaCode)
    # USQADD
    usqaddCode = '''
            destElem = srcElem1 + srcElem2;
            if (bits(srcElem2, sizeof(Element) * 8 - 1) == 0) {
                if (destElem < srcElem1 || destElem < srcElem2) {
                    destElem = (Element)(-1);
                }
            } else {
                Element absSrcElem2 = (~srcElem2) + 1;
                if (absSrcElem2 > srcElem1) {
                    destElem = 0;
                }
            }
    '''
    sveBinInst('usqadd', 'UsqaddPred', 'SimdAddOp', unsignedTypes, usqaddCode,
               predType=PredType.MERGE, isDestructive=True)
    # USRA
    sveTerImmInst('usra', 'Usra', 'SimdAluOp', unsignedTypes, sraCode)
    # USUBLB
    sveBinLongInst('usublb', 'Usublb', 'SimdAddOp', smallUnsignedTypes,
                   sublCode)
    # USUBLT
    sveBinLongInst('usublt', 'Usublt', 'SimdAddOp', smallUnsignedTypes,
                   sublCode, uptTop = True)
    # USUBWB
    sveBinWidenInst('usubwb', 'Usubwb', 'SimdAddOp', smallUnsignedTypes,
                    subwCode)
    # USUBWT
    sveBinWidenInst('usubwt', 'Usubwt', 'SimdAddOp', smallUnsignedTypes,
                    subwCode, uptTop=True)
    # UUNPKHI
    sveUnpackInst('uunpkhi', 'Uunpkhi', 'SimdAluOp', unsignedWideSDTypes,
                  unpackHalf = Unpack.High, regType = SrcRegType.Vector)
    # UUNPKLO
    sveUnpackInst('uunpklo', 'Uunpklo', 'SimdAluOp', unsignedWideSDTypes,
                  unpackHalf = Unpack.Low, regType = SrcRegType.Vector)
    # UXTB
    uxtCode = 'destElem = srcElem1;'
    sveWidenUnaryInst('uxtb', 'Uxtb', 'SimdAluOp',
                      ['uint8_t, uint16_t', 'uint8_t, uint32_t',
                       'uint8_t, uint64_t'], uxtCode, PredType.MERGE)
    # UXTH
    sveWidenUnaryInst('uxth', 'Uxth', 'SimdAluOp',
                      ['uint16_t, uint32_t', 'uint16_t, uint64_t'],
                      uxtCode, PredType.MERGE)
    # UXTW
    sveWidenUnaryInst('uxtw', 'Uxtw', 'SimdAluOp', ['uint32_t, uint64_t'],
                      uxtCode, PredType.MERGE)
    # UZP1, UZP2 (predicates)
    uzpPredIterCode = '''
        constexpr unsigned sz = sizeof(Element);
        int s;
        int part = %d;
        ArmISA::VecPredRegContainer tmpPredC;
        auto auxPDest = tmpPredC.as<uint8_t>();
        for (unsigned i = 0; i < eCount; i++) {
            s = 2 * i + part;
            for (unsigned j = 0; j < sz; j++) {
                if (s < eCount) {
                    auxPDest[i * sz + j] = POp1_pb[s * sz + j];
                } else {
                    auxPDest[i * sz + j] = POp2_pb[(s - eCount) * sz + j];
                }
            }
        }
        for (unsigned i = 0; i < eCount * sz; i++) {
            PDest_pb[i] = auxPDest[i];
        }
    '''
    svePredBinPermInst('uzp1', 'Uzp1Pred', 'SimdPredAluOp', unsignedTypes,
                       uzpPredIterCode % 0)
    svePredBinPermInst('uzp2', 'Uzp2Pred', 'SimdPredAluOp', unsignedTypes,
                       uzpPredIterCode % 1)
    # UZP1, UZP2 (vectors)
    uzpIterCode = '''
        // SVE F64MM support requires that there are at least two elements
        // in the vector.
        if (eCount < 2) {
            return std::make_shared<UndefinedInstruction>(machInst, false,
                                                          "%(mnemonic)s");
        }
        int s;
        int part = %(part)d;
        ArmISA::VecRegContainer tmpVecC;
        auto auxDest = tmpVecC.as<Element>();
        const unsigned eltPairsCount = eCount / 2;
        const unsigned eltsInPairsCount = eltPairsCount * 2;
        for (unsigned i = 0; i < eltsInPairsCount; i++) {
            s = 2 * i + part;
            if (s < eltsInPairsCount) {
                auxDest[i] = AA64FpOp1_x[s];
            } else {
                auxDest[i] = AA64FpOp2_x[s - eltsInPairsCount];
            }
        }
        // Fill output vector with pairs of elements
        for (unsigned i = 0; i < eltsInPairsCount; i++) {
            AA64FpDest_x[i] = auxDest[i];
        }
        // Fill any trailing non-full pairs with zeros
        for (unsigned i = eltsInPairsCount; i < eCount; i++) {
            AA64FpDest_x[i] = 0;
        }
    '''
    sveBinInst('uzp1', 'Uzp1', 'SimdAluOp', unsignedTypes, '',
               customIterCode=uzpIterCode % dict(mnemonic='uzp1', part=0))
    sveBinInst('uzp2', 'Uzp2', 'SimdAluOp', unsignedTypes, '',
               customIterCode=uzpIterCode % dict(mnemonic='uzp2', part=1))
    sveBinInst('uzp1', 'Uzp1Q', 'SimdAluOp', ['__uint128_t'], '',
               customIterCode=uzpIterCode % dict(mnemonic='uzp1', part=0))
    sveBinInst('uzp2', 'Uzp2Q', 'SimdAluOp', ['__uint128_t'], '',
               customIterCode=uzpIterCode % dict(mnemonic='uzp2', part=1))
    # UZPQ1, UZPQ2
    uzpqIterCode = '''
        unsigned ePerSegment = 16 / sizeof(Element);
        unsigned segment = eCount / ePerSegment;
        unsigned eltPairsCount = ePerSegment / 2;
        unsigned eltsInPairsCount = eltPairsCount * 2;
        int s;
        int part = %(part)d;
        ArmISA::VecRegContainer tmpVecC;
        auto auxDest = tmpVecC.as<Element>();
        for (unsigned seg = 0; seg < segment; seg ++) {
            unsigned segBase = seg * ePerSegment;
            for (unsigned i = 0; i < eltsInPairsCount; i++) {
                s = 2 * i + part;
                if (s < eltsInPairsCount) {
                    auxDest[segBase + i] = AA64FpOp1_x[segBase + s];
                } else {
                    auxDest[segBase + i] =
                        AA64FpOp2_x[segBase + s - eltsInPairsCount];
                }
            }
        }
        // Fill output vector with pairs of elements
        for (unsigned i = 0; i < segment * eltsInPairsCount; i++) {
            AA64FpDest_x[i] = auxDest[i];
        }
        // Fill any trailing non-full pairs with zeros
        for (unsigned i = segment * eltsInPairsCount; i < eCount; i++) {
            AA64FpDest_x[i] = 0;
        }
    '''
    sveBinInst('uzpq1', 'Uzpq1', 'SimdAluOp', unsignedTypes, '',
               customIterCode=uzpqIterCode % dict(part=0))
    sveBinInst('uzpq2', 'Uzpq2', 'SimdAluOp', unsignedTypes, '',
               customIterCode=uzpqIterCode % dict(part=1))
    # WHILEGE (predicate as counter)
    whileGECode = '''
            cond = srcElem1 >= srcElem2;
    '''
    sveWhilePngInst('whilege', 'WhilegePng', 'SimdCmpOp', signedTypes,
                    whileGECode, SrcSize.Src64bit, toDown = True)
    # WHILEGE (predicate pair)
    sveWhileInst('whilege', 'WhilegePair', 'SimdCmpOp', signedTypes,
                 whileGECode, SrcSize.Src64bit, toDown = True, isPair=True)
    # WHILEGE (predicate, 32-bit)
    sveWhileInst('whilege', 'Whilege32', 'SimdCmpOp', signedTypes,
                 whileGECode, SrcSize.Src32bit, toDown = True)
    # WHILEGE (predicate, 64-bit)
    sveWhileInst('whilege', 'Whilege64', 'SimdCmpOp', signedTypes,
                 whileGECode, SrcSize.Src64bit, toDown = True)
    # WHILEGT (predicate as counter)
    whileGTCode = '''
            cond = srcElem1 > srcElem2;
    '''
    sveWhilePngInst('whilegt', 'WhilegtPng', 'SimdCmpOp', signedTypes,
                    whileGTCode, SrcSize.Src64bit, toDown = True)
    # WHILEGT (predicate pair)
    sveWhileInst('whilegt', 'WhilegtPair', 'SimdCmpOp', signedTypes,
                 whileGTCode, SrcSize.Src64bit, toDown = True, isPair=True)
    # WHILEGT (predicate, 32-bit)
    sveWhileInst('whilegt', 'Whilegt32', 'SimdCmpOp', signedTypes,
                 whileGTCode, SrcSize.Src32bit, toDown = True)
    # WHILEGT (predicate, 64-bit)
    sveWhileInst('whilegt', 'Whilegt64', 'SimdCmpOp', signedTypes,
                 whileGTCode, SrcSize.Src64bit, toDown = True)
    # WHILEHI (predicate as counter)
    sveWhilePngInst('whilehi', 'WhilehiPng', 'SimdCmpOp', unsignedTypes,
                 whileGTCode, SrcSize.Src64bit, toDown = True)
    # WHILEHI (predicate pair)
    sveWhileInst('whilehi', 'WhilehiPair', 'SimdCmpOp', unsignedTypes,
                 whileGTCode, SrcSize.Src64bit, toDown = True, isPair=True)
    # WHILEHI (predicate, 32-bit)
    sveWhileInst('whilehi', 'Whilehi32', 'SimdCmpOp', unsignedTypes,
                 whileGTCode, SrcSize.Src32bit, toDown = True)
    # WHILEHI (predicate, 64-bit)
    sveWhileInst('whilehi', 'Whilehi64', 'SimdCmpOp', unsignedTypes,
                 whileGTCode, SrcSize.Src64bit, toDown = True)
    # WHILEHS (predicate as counter)
    sveWhilePngInst('whilehs', 'WhilehsPng', 'SimdCmpOp', unsignedTypes,
                    whileGECode, SrcSize.Src64bit, toDown = True)
    # WHILEHS (predicate pair)
    sveWhileInst('whilehs', 'WhilehsPair', 'SimdCmpOp', unsignedTypes,
                 whileGECode, SrcSize.Src64bit, toDown = True, isPair=True)
    # WHILEHS (predicate, 32-bit)
    sveWhileInst('whilehs', 'Whilehs32', 'SimdCmpOp', unsignedTypes,
                 whileGECode, SrcSize.Src32bit, toDown = True)
    # WHILEHS (predicate, 64-bit)
    sveWhileInst('whilehs', 'Whilehs64', 'SimdCmpOp', unsignedTypes,
                 whileGECode, SrcSize.Src64bit, toDown = True)
    # WHILELE (predicate as counter)
    whileLECode = '''
            cond = srcElem1 <= srcElem2;
    '''
    sveWhilePngInst('whilele', 'WhilelePng', 'SimdCmpOp', signedTypes,
                    whileLECode, SrcSize.Src64bit)
    # WHILELE (predicate pair)
    sveWhileInst('whilele', 'WhilelePair', 'SimdCmpOp', signedTypes,
                 whileLECode, SrcSize.Src64bit, isPair=True)
    # WHILELE (predicate, 32-bit)
    sveWhileInst('whilele', 'Whilele32', 'SimdCmpOp', signedTypes,
                 whileLECode, SrcSize.Src32bit)
    # WHILELE (predicate, 64-bit)
    sveWhileInst('whilele', 'Whilele64', 'SimdCmpOp', signedTypes,
                 whileLECode, SrcSize.Src64bit)
    # WHILELO (predicate as counter)
    whileLTCode = '''
            cond = srcElem1 < srcElem2;
    '''
    sveWhilePngInst('whilelo', 'WhileloPng', 'SimdCmpOp', unsignedTypes,
                    whileLTCode, SrcSize.Src64bit)
    # WHILELO (predicate pair)
    sveWhileInst('whilelo', 'WhileloPair', 'SimdCmpOp', unsignedTypes,
                 whileLTCode, SrcSize.Src64bit, isPair=True)
    # WHILELO (predicate, 32-bit)
    sveWhileInst('whilelo', 'Whilelo32', 'SimdCmpOp', unsignedTypes,
                 whileLTCode, SrcSize.Src32bit)
    # WHILELO (predicate, 64-bit)
    sveWhileInst('whilelo', 'Whilelo64', 'SimdCmpOp', unsignedTypes,
                 whileLTCode, SrcSize.Src64bit)
    # WHILELS (predicate as counter)
    sveWhilePngInst('whilels', 'WhilelsPng', 'SimdCmpOp', unsignedTypes,
                    whileLECode, SrcSize.Src64bit)
    # WHILELS (predicate pair)
    sveWhileInst('whilels', 'WhilelsPair', 'SimdCmpOp', unsignedTypes,
                 whileLECode, SrcSize.Src64bit, isPair=True)
    # WHILELS (predicate, 32-bit)
    sveWhileInst('whilels', 'Whilels32', 'SimdCmpOp', unsignedTypes,
                 whileLECode, SrcSize.Src32bit)
    # WHILELS (predicate, 64-bit)
    sveWhileInst('whilels', 'Whilels64', 'SimdCmpOp', unsignedTypes,
                 whileLECode, SrcSize.Src64bit)
    # WHILELT (predicate as counter)
    sveWhilePngInst('whilelt', 'WhileltPng', 'SimdCmpOp', signedTypes,
                    whileLTCode, SrcSize.Src64bit)
    # WHILELT (predicate pair)
    sveWhileInst('whilelt', 'WhileltPair', 'SimdCmpOp', signedTypes,
                 whileLTCode, SrcSize.Src64bit, isPair=True)
    # WHILELT (predicate, 32-bit)
    sveWhileInst('whilelt', 'Whilelt32', 'SimdCmpOp', signedTypes,
                 whileLTCode, SrcSize.Src32bit)
    # WHILELT (predicate, 64-bit)
    sveWhileInst('whilelt', 'Whilelt64', 'SimdCmpOp', signedTypes,
                 whileLTCode, SrcSize.Src64bit)
    # WHILERW
    sveWhileRWInst('whilerw', 'Whilerw', 'SimdCmpOp', unsignedTypes,
                    absdiff = True)
    # WHILEWR
    sveWhileRWInst('whilewr', 'Whilewr', 'SimdCmpOp', unsignedTypes)
    # WRFFR
    wrffrCode = '''
        unsigned eCount = ArmStaticInst::getCurSveVecLen<uint8_t>(
                xc->tcBase());
        for (unsigned i = 0; i < eCount; i++) {
            Ffr_ub[i] = POp1_ub[i];
        }'''
    svePredWriteFfrInst('wrffr', 'Wrffr', 'SimdPredAluOp', wrffrCode, False)
    # XAR
    xarCode = '''
            destElem = AA64FpDestMerge_x[i] ^ srcElem1;
            destElem = ((destElem >> srcElem2) |
                    (destElem << (sizeof(Element) * 8 - srcElem2)));
    '''
    sveBinImmInst('xar', 'Xar', 'SimdAluOp', unsignedTypes, xarCode)
    # ZIP1, ZIP2 (predicates)
    zipPredIterCode = '''
        constexpr unsigned sz = sizeof(Element);
        int s;
        int part = %d;
        ArmISA::VecPredRegContainer tmpPredC;
        auto auxPDest = tmpPredC.as<uint8_t>();
        for (unsigned i = 0; i < eCount / 2; i++) {
            s = i + (part * (eCount / 2));
            for (unsigned j = 0; j < sz; j++) {
                auxPDest[(2 * i) * sz + j] = POp1_pb[s * sz + j];
                auxPDest[(2 * i + 1) * sz + j] = POp2_pb[s * sz + j];
            }
        }
        for (unsigned i = 0; i < eCount * sz; i++) {
            PDest_pb[i] = auxPDest[i];
        }
    '''
    svePredBinPermInst('zip1', 'Zip1Pred', 'SimdPredAluOp', unsignedTypes,
                       zipPredIterCode % 0)
    svePredBinPermInst('zip2', 'Zip2Pred', 'SimdPredAluOp', unsignedTypes,
                       zipPredIterCode % 1)
    # ZIP1, ZIP2 (vectors)
    zipIterCode = '''
        // SVE F64MM support requires that there are at least two elements
        // in the vector.
        if (eCount < 2) {
            return std::make_shared<UndefinedInstruction>(machInst, false,
                                                          "%(mnemonic)s");
        }
        int s;
        int part = %(part)d;
        ArmISA::VecRegContainer tmpVecC;
        auto auxDest = tmpVecC.as<Element>();
        const unsigned eltPairsCount = eCount / 2;
        const unsigned eltsInPairsCount = eltPairsCount * 2;
        for (unsigned i = 0; i < eltPairsCount; i++) {
            s = i + (part * (eltsInPairsCount / 2));
            auxDest[2 * i] = AA64FpOp1_x[s];
            auxDest[2 * i + 1] = AA64FpOp2_x[s];
        }
        // Fill output vector with pairs of elements
        for (unsigned i = 0; i < eltsInPairsCount; i++) {
            AA64FpDest_x[i] = auxDest[i];
        }
        // Fill any trailing non-full pairs with zeros
        for (unsigned i = eltsInPairsCount; i < eCount; i++) {
            AA64FpDest_x[i] = 0;
        }
    '''
    sveBinInst('zip1', 'Zip1', 'SimdAluOp', unsignedTypes, '',
               customIterCode=zipIterCode % dict(mnemonic='zip1', part=0))
    sveBinInst('zip2', 'Zip2', 'SimdAluOp', unsignedTypes, '',
               customIterCode=zipIterCode % dict(mnemonic='zip2', part=1))
    sveBinInst('zip1', 'Zip1Q', 'SimdAluOp', ['__uint128_t'], '',
               customIterCode=zipIterCode % dict(mnemonic='zip1', part=0))
    sveBinInst('zip2', 'Zip2Q', 'SimdAluOp', ['__uint128_t'], '',
               customIterCode=zipIterCode % dict(mnemonic='zip2', part=1))
    # ZIPQ1, ZIPQ2
    zipqIterCode = '''
        unsigned ePerSegment = 16 / sizeof(Element);
        unsigned segment = eCount / ePerSegment;
        unsigned eltPairsCount = ePerSegment / 2;
        unsigned eltsInPairsCount = eltPairsCount * 2;
        int s;
        int part = %(part)d;
        ArmISA::VecRegContainer tmpVecC;
        auto auxDest = tmpVecC.as<Element>();
        for (unsigned seg = 0; seg < segment; seg ++) {
            unsigned segBase = seg * ePerSegment;
            for (unsigned i = 0; i < eltPairsCount; i++) {
                s = i + (part * (eltsInPairsCount / 2));
                auxDest[segBase + 2 * i + 0] = AA64FpOp1_x[segBase + s];
                auxDest[segBase + 2 * i + 1] = AA64FpOp2_x[segBase + s];
            }
        }
        // Fill output vector with pairs of elements
        for (unsigned i = 0; i < segment * eltsInPairsCount; i++) {
            AA64FpDest_x[i] = auxDest[i];
        }
        // Fill any trailing non-full pairs with zeros
        for (unsigned i = segment * eltsInPairsCount; i < eCount; i++) {
            AA64FpDest_x[i] = 0;
        }
    '''
    sveBinInst('zipq1', 'Zipq1', 'SimdAluOp', unsignedTypes, '',
               customIterCode=zipqIterCode % dict(part=0))
    sveBinInst('zipq2', 'Zipq2', 'SimdAluOp', unsignedTypes, '',
               customIterCode=zipqIterCode % dict(part=1))

    # ADCLT
    adcltCode = 'res = srcElem1 + srcElem2 + carryIn;'
    sveTerInstUnpred('adclt', 'Adclt', 'SimdAddOp', unsignedTypes,
                     adcltCode, isTop=True, isAdd=True)
    # ADCLB
    adclbCode = 'res = srcElem1 + srcElem2 + carryIn;'
    sveTerInstUnpred('adclb', 'Adclb', 'SimdAddOp', unsignedTypes,
                     adclbCode, isTop=False, isAdd=True)
    # SBCLT
    sbcltCode = 'res = srcElem1 + ~(srcElem2) + carryIn;'
    sveTerInstUnpred('sbclt', 'Sbclt', 'SimdAddOp', unsignedTypes,
                     sbcltCode, isTop=True, isAdd=False)
    # SBCLB
    sbclbCode = 'res = srcElem1 + ~(srcElem2) + carryIn;'
    sveTerInstUnpred('sbclb', 'Sbclb', 'SimdAddOp', unsignedTypes,
                     sbclbCode, isTop=False, isAdd=False)
}};
